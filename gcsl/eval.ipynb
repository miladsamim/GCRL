{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msmic\\Documents\\code\\rl\\carla\\rl_ad\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "dir_paths = ['dependencies']\n",
    "sys.path += [os.path.join(os.getcwd(), dir_path) for dir_path in dir_paths]\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import rlutil.torch.pytorch_util as ptu\n",
    "from collections import deque\n",
    "import einops\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gcsl.tools import dotdict\n",
    "from gcsl.algo.transformer_idm import DiscreteIDMPolicy\n",
    "from gcsl.algo.idm import S_DiscreteIDMPolicy\n",
    "from gcsl.algo.dec_idm import DiscreteDEC_IDMPolicy\n",
    "from gcsl.algo.masking import (generate_random_goal_mask, generate_k_ahead_goal_mask,\n",
    "                               generate_square_subsequent_mask,\n",
    "                               generate_restrictive_square_subsequent_mask)\n",
    "from rlutil.logging import log_utils, logger\n",
    "from gcsl import envs\n",
    "from gcsl.algo import buffer, gcsl, variants, networks\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_freq': 2000, 'eval_episodes': 50, 'max_trajectory_length': 50, 'max_timesteps': 2500, 'goal_threshold': 0.08}\n"
     ]
    }
   ],
   "source": [
    "env_name = 'lunar'\n",
    "env = envs.create_env(env_name)\n",
    "env_params = envs.get_env_params(env_name)\n",
    "env_params['max_timesteps'] = 2500\n",
    "print(env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = dotdict(\n",
    "            d_model=32,\n",
    "            nhead=1,\n",
    "            layers=1,\n",
    "            max_len=50,    \n",
    "            dropout=0.1,\n",
    "            device='cpu'\n",
    "        )\n",
    "idm_args = dotdict(\n",
    "        use_transformer = False,\n",
    "        # policy_class = DiscreteIDMPolicy,\n",
    "        # policy_class = DiscreteDEC_IDMPolicy,\n",
    "        restrictive_masking = True,\n",
    ")\n",
    "env, policy, replay_buffer, gcsl_kwargs = variants.get_params(env, env_params, \n",
    "                                            idm_args=idm_args,\n",
    "                                            model_args=model_args)\n",
    "policy = S_DiscreteIDMPolicy(env, model_args)\n",
    "gcsl_kwargs['log_tensorboard'] = True\n",
    "gcsl_kwargs['eval_freq'] = 1000\n",
    "algo = gcsl.GCSL(\n",
    "    env,\n",
    "    policy,\n",
    "    replay_buffer,\n",
    "    idm_args=idm_args,\n",
    "    **gcsl_kwargs\n",
    ")\n",
    "gcsl_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.random.rand(20000, 50)\n",
    "traj_idxss = np.random.randint(0,20000, (256))\n",
    "act_ts = np.arange(50)\n",
    "actions[traj_idxss].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m output_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/tmp\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m log_utils\u001b[39m.\u001b[39msetup_logger(exp_prefix\u001b[39m=\u001b[39mexp_prefix, log_base_dir\u001b[39m=\u001b[39moutput_dir):\n\u001b[0;32m      4\u001b[0m     \u001b[39m# pass\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     algo\u001b[39m.\u001b[39mtrain()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "exp_prefix = '%s/gcsl' % (env_name,)\n",
    "output_dir='/tmp'\n",
    "with log_utils.setup_logger(exp_prefix=exp_prefix, log_base_dir=output_dir):\n",
    "    # pass\n",
    "    algo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = np.load('tmp\\\\vicreg_idm_variants\\lunar\\gcsl_idm1l_gm_8\\\\2023_02_20_12_34_20\\\\buffer.pkl', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['internal_goals', 'states', 'actions', 'store_actions', 'desired_states'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3189, 50, 5), torch.Size([3189, 50, 5]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_goals = env.extract_goal(buffer['states'])\n",
    "states = torch.tensor(buffer['states'])\n",
    "th_goals = env.extract_goal(states)\n",
    "np_goals.shape, th_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.14372717,  0.        , -0.16093261, -0.47141062, -0.11364087,\n",
       "        -0.37922401,  0.        ,  0.        ]),\n",
       " array([-0.14372717,  0.        , -0.11364087,  0.        ,  0.        ]),\n",
       " tensor([-0.0916,  1.4905, -0.4571,  0.1920,  0.1342,  0.1492,  0.0000,  0.0000]),\n",
       " tensor([-0.0916,  1.4905,  0.1342,  0.0000,  0.0000]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_full = env.sample_goal()\n",
    "goal = env.extract_goal(goal_full)\n",
    "goal_full, goal, states[0,10], env.extract_goal(states[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.randint(0,50,(256,))\n",
    "X_s = torch.rand(256,50,8)\n",
    "X_s_c = X_s.clone()\n",
    "X_s_c = einops.rearrange(X_s_c, 'b t h -> t b h')\n",
    "X_g = torch.rand(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, gamma, beta = torch.rand(50, 32, 8), torch.rand(1, 32, 8), torch.rand(1, 32, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52181495,  0.        , -0.24763215, -0.39715649, -0.0305856 ,\n",
       "        0.0686049 ,  0.        ,  0.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "goal = env.sample_goal()\n",
    "goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(32,50,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow = []\n",
    "fast = env.extract_goal(X)\n",
    "for i in range(X.shape[0]):\n",
    "    slow.append(env.extract_goal(X[i]))\n",
    "(einops.rearrange(slow, 'b t h -> b t h') == fast).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0045,  1.4150,  0.0052,  0.0000,  0.0000], dtype=torch.float16),\n",
       " array([-0.00446033,  1.4151143 ,  0.00517525,  0.        ,  0.        ],\n",
       "       dtype=float32),\n",
       " False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_goals[0,0],np_goals[0,0],(th_goals.numpy() == np_goals).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptu.USE_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size, t = buffer['states'].shape[:2]\n",
    "buffer['states'].shape, buffer['actions'].shape, buffer['internal_goals'].shape, buffer['desired_states'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 50])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_size, t = 32, 50\n",
    "goal_mask, goal_idxs = generate_random_goal_mask(1, t)\n",
    "goal_mask = einops.rearrange(goal_mask, '() t1 t2 -> t1 t2')\n",
    "goal_mask.shape\n",
    "# need to repeat per nhead, for custom batch masking\n",
    "# goal_mask_repeated = einops.repeat(goal_mask, 'b t1 t2 -> (b nhead) t1 t2', nhead=8) \n",
    "# goal_mask_repeated.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 64\n",
    "state_pos_emb = nn.Embedding(50, d)\n",
    "act_pos_emb = nn.Embedding(50, d)\n",
    "global_pos_emb = nn.Embedding(50*2, d)\n",
    "S, A = torch.rand(32,50,d), torch.rand(32,50,d)\n",
    "state_pos = state_pos_emb(torch.arange(50))\n",
    "state_pos = einops.rearrange(state_pos, 't h -> () t h')\n",
    "act_pos = act_pos_emb(torch.arange(50))\n",
    "act_pos = einops.rearrange(act_pos, 't h -> () t h')\n",
    "global_pos = global_pos_emb(torch.arange(50*2))\n",
    "global_pos = einops.rearrange(global_pos, 't h -> () t h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = S + state_pos\n",
    "A = A + act_pos\n",
    "seq, ps = einops.pack((S,A), 'b t * h') \n",
    "seq = einops.rearrange(seq, 'b t type h -> b (t type) h')\n",
    "seq = seq + global_pos\n",
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[0,98] == S[0,-1] + global_pos_emb.weight[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_mask, goal_idxs = generate_random_goal_mask(1, t*2, even_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = generate_square_subsequent_mask(100)\n",
    "mask[:,-3:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einops.rearrange(np.array([0,1,2,3,4]), 't -> t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([4, 5, 6, 7]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(8).chunk(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_a = einops.rearrange(np.array([1,2,3]), 't -> () t')\n",
    "X_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 8]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einops.pack((X_a, np.array([8])), 'none *')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking that scatter goal masking works as expected\n",
    "# goal_mask_ = torch.clone(mask)\n",
    "# for i in range(b_size):\n",
    "#     for j in range(t):\n",
    "#         goal_idx = goal_idxs[i,j].item()\n",
    "#         goal_mask_[i,j,goal_idx] = False\n",
    "# goal_mask.shape, goal_mask_.shape, (goal_mask == goal_mask_).all(), (goal_mask == mask).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1145, 50, 8]),\n",
       " torch.Size([1145, 50]),\n",
       " torch.Size([50, 50]),\n",
       " torch.Size([1, 50, 1]),\n",
       " 1780740)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = dotdict(\n",
    "    d_model=128,\n",
    "    nhead=8,\n",
    "    layers=2,\n",
    "    max_len=50,    \n",
    "    dropout=0.5,\n",
    "    device='cpu',\n",
    ")\n",
    "# idm_policy = DiscreteDEC_IDMPolicy(env, args)\n",
    "idm_policy = DiscreteIDMPolicy(env, args)\n",
    "# simple masking, just use same for all in the batch\n",
    "X = torch.tensor(buffer['states'])\n",
    "actions = torch.tensor(buffer['actions'][-b_size:])\n",
    "goal_mask, goal_idxs = generate_random_goal_mask(1, t)\n",
    "goal_mask = einops.rearrange(goal_mask, '() t1 t2 -> t1 t2') \n",
    "X.shape, actions.shape, goal_mask.shape, goal_idxs.shape, sum([p.numel() for p in idm_policy.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple k ahead masking\n",
    "# k = 3\n",
    "# goal_mask, goal_idxs = generate_k_ahead_goal_mask(t, k)\n",
    "# goal_mask = generate_square_subsequent_mask(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_policy.load_state_dict(torch.load('tmp/lunar/2023_02_02_10_42_11/policy.pkl', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([57250, 4]), torch.Size([57250]), torch.Size([1145, 50]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_policy.train()\n",
    "opt = torch.optim.Adam(idm_policy.parameters())\n",
    "act_preds = idm_policy(X, mask=goal_mask,special_pe=False)\n",
    "act_preds = einops.rearrange(act_preds, 't b n_acts -> (t b) n_acts')\n",
    "acts = einops.rearrange(actions, 'b t -> (t b)')\n",
    "act_preds.shape, acts.shape, actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9391)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_preds = act_preds.argmax(dim=1)\n",
    "(a_preds == acts).sum() / len(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load policy below\n",
    "a_gcsl_preds = gcsl_policy(torch.tensor(buffer['states'][:,0,:]),\n",
    "torch.tensor(env.extract_goal(buffer['desired_states']))).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([386.,   0.,   0., 325.,   0.,   0.,   0.,   0.,   0., 434.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3) ,nrows=1, ncols=2)\n",
    "\n",
    "ax[0].hist(a_preds.numpy())\n",
    "ax[1].hist(a_gcsl_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n",
    "loss = idm_policy.nll(X,None,actions,mask=goal_mask)\n",
    "loss.mean()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.random.rand(1,8)\n",
    "g = np.random.rand(1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([], maxlen=50)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_policy.state_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([], maxlen=50)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_policy.reset_state_hist()\n",
    "idm_policy.state_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1\n",
      "[1] 2\n",
      "[1] 3\n",
      "[1] 4\n",
      "[1] 5\n"
     ]
    }
   ],
   "source": [
    "idm_policy.eval()\n",
    "for _ in range (5):\n",
    "    print(idm_policy.act_vectorized(s0,g,greedy=True), len(idm_policy.state_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 128])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = einops.rearrange(list(idm_policy.state_hist), 't h -> t h')\n",
    "hist_g, ps = einops.pack((hist, g), '* h')\n",
    "hist_g = torch.tensor(hist_g, dtype=torch.float32).unsqueeze(0)\n",
    "hist_g = einops.rearrange(hist_g, 'b t h -> t b h')\n",
    "hist_g = idm_policy.net.state_emb(hist_g)\n",
    "hist_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 128])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = idm_policy.net.positional_encoder.pe\n",
    "pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.randint(0,4, (50,3,1))\n",
    "targets = einops.rearrange(targets, 't b () -> (t b)')\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 4])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = idm_policy(torch.rand(3,50,8), mask=goal_mask, special_pe=True)\n",
    "logits = einops.rearrange(logits, 't b c_out -> (t b) c_out')\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.2365, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1145, 50, 8)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer['states'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 4])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_policy(torch.rand(3, 50, 8), goal_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 128]), [torch.Size([2]), torch.Size([])])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack, ps = einops.pack((torch.rand(2,128),torch.rand(128)), '* h')\n",
    "pack.shape, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einops.rearrange([torch.rand(10), torch.rand(10)], 't h -> t h').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00729027,  1.4046534 , -0.7384439 , -0.27854842,  0.00845441,\n",
       "        0.16726854,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    env.step(env.action_space.sample())\n",
    "    env.render(mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 50, 8), (1145,))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = np.random.rand(400,50,8)\n",
    "traj_idxs = np.random.choice(400, b_size)\n",
    "states.shape, traj_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int, device='cpu') -> torch.Tensor:\n",
    "    return torch.triu(torch.full((sz, sz), float('-inf'), device=device), diagonal=1)\n",
    "\n",
    "def random_goal_idxs(b_size, t):\n",
    "    \"\"\"Generates random goal idxs to use in masking s.t. that each goal state is sampled\n",
    "       from the upper triangular matrix, so that the goal state is a future state for each\n",
    "       timesteps t. \n",
    "       Except for last state as that would have no future state availble anyway -> so set to 0\"\"\"\n",
    "    goal_idxs = []\n",
    "    for i in range(t-1):\n",
    "        goal_idxs.append(torch.randint(i+1,t, (b_size, 1, 1)))\n",
    "    goal_idxs.append(torch.zeros((b_size,1,1), dtype=torch.int)) # last has no goal state anyway\n",
    "    return einops.rearrange(goal_idxs, 't b () () -> b t ()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size, device, sz = 1, 'cpu', 50\n",
    "mask = generate_square_subsequent_mask(sz, device=device).repeat(b_size,1,1)\n",
    "goal_idxs = random_goal_idxs(b_size, sz).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_mask = mask.scatter(2, goal_idxs, torch.zeros_like(goal_idxs, dtype=torch.float32, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 50]), torch.Size([1, 50, 1]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape, goal_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 50]), torch.Size([1, 50, 50]), tensor(True), tensor(False))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # checking that scatter goal masking works as expected\n",
    "goal_mask_ = torch.clone(mask)\n",
    "for i in range(b_size):\n",
    "    for j in range(sz):\n",
    "        goal_idx = goal_idxs[i,j].item()\n",
    "        goal_mask_[i,j,goal_idx] = 0\n",
    "goal_mask.shape, goal_mask_.shape, (goal_mask == goal_mask_).all(), (goal_mask == mask).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_mask, goal_idxs = generate_random_goal_mask(1, t, restrictive=True)\n",
    "goal_mask = einops.rearrange(goal_mask, '() t1 t2 -> t1 t2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [-inf, 0., 0.],\n",
       "        [-inf, -inf, 0.]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_square_subsequent_mask(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.TransformerDecoderLayer(args.d_model, args.nhead, dropout=args.dropout)\n",
    "gpt = nn.TransformerDecoder(encoder, args.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 50]), torch.Size([50, 50]))"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask = generate_restrictive_square_subsequent_mask(t)\n",
    "mem_mask, _ = generate_random_goal_mask(1, t, restrictive=True)\n",
    "mem_mask = einops.rearrange(mem_mask, '() t1 t2 -> t1 t2') \n",
    "tgt_mask.shape, mem_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 32, 128])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt(tgt=torch.rand(50,32,128),memory=torch.rand(50,32,128),\n",
    "    tgt_mask=tgt_mask,memory_mask=mem_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_mask.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 10, 128])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(torch.zeros(30,10, dtype=torch.int)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = torch.rand(32),torch.rand(32)\n",
    "x, ps = einops.pack((a,b), '* h')\n",
    "sa, ga = einops.unpack(x, ps, '* h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = einops.unpack(x.unsqueeze(1), ps, '* b h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32]), torch.Size([1, 32]))"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking policies by comparing actions towards goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: DeprecationWarning: invalid escape sequence \\l\n",
      "c:\\Users\\msmic\\Documents\\code\\rl\\PACT_CarRacing\\gcsl\\dependencies\\rlutil\\torch\\__init__.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return self.fn(*args, device=device, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiscreteStochasticGoalPolicy(\n",
       "  (net): StateGoalNetwork(\n",
       "    (state_embedding): Flatten()\n",
       "    (goal_embedding): Flatten()\n",
       "    (net): FCNetwork(\n",
       "      (network): Sequential(\n",
       "        (0): Linear(in_features=13, out_features=400, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=400, out_features=300, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=300, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_policy # loaded above\n",
    "# gcsl_policy = torch.load('tmp\\lunar\\gcsl\\\\2023_01_31_09_16_59\\params.pkl',  map_location=torch.device('cpu'))\n",
    "from gcsl.algo.networks import DiscreteStochasticGoalPolicy\n",
    "gcsl_policy = DiscreteStochasticGoalPolicy(\n",
    "                env,\n",
    "                state_embedding=None,\n",
    "                goal_embedding=None,\n",
    "                layers=[400, 300], #[400, 300], # TD3-size\n",
    "                max_horizon=None, # Do not pass in horizon.\n",
    "                # max_horizon=get_horizon(env_params), # Use this line if you want to include horizon into the policy\n",
    "                freeze_embeddings=True,\n",
    "                add_extra_conditioning=False,\n",
    "            )\n",
    "gcsl_policy.load_state_dict(torch.load('tmp\\lunar\\gcsl\\\\2023_01_31_09_16_59\\policy.pkl', map_location='cpu'))\n",
    "idm_policy.eval()\n",
    "gcsl_policy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "for i in range(100):\n",
    "    state = env.reset()\n",
    "    goal_state = env.sample_goal()\n",
    "    goal = env.extract_goal(goal_state)\n",
    "    idm_acts = []\n",
    "    acts = []\n",
    "    for i in range(50):\n",
    "        idm_acts.append(idm_policy.act_vectorized(state[None], goal_state[None],greedy=True)[0])\n",
    "        acts.append(gcsl_policy.act_vectorized(state[None], goal[None],greedy=True)[0])\n",
    "        state, _, _, _ = env.step(acts[-1])\n",
    "        # state, _, _, _ = env.step(idm_acts[-1])\n",
    "    dists.append(env.goal_distance(state, goal_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06277568033131098,\n",
       " 0.05698567590343996,\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1], dtype=int64),\n",
       " array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2,\n",
       "        3, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3], dtype=int64))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dists), np.std(dists), np.array(idm_acts), np.array(acts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that buffers work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcsl.algo.buffer import ReplayBuffer\n",
    "from gcsl.algo.buffer2 import ReplayBuffer2\n",
    "buffer_kwargs = dict(\n",
    "        env=env,\n",
    "        max_trajectory_length=50, \n",
    "        buffer_size=20000,\n",
    "    )\n",
    "b1 = ReplayBuffer(**buffer_kwargs)\n",
    "b2 = ReplayBuffer2(**buffer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    state_traj = np.random.rand(50,8)\n",
    "    act_traj = np.random.randint(0,4, (50,))\n",
    "    desired_state = np.random.rand(8)    \n",
    "    b1.add_trajectory(state_traj, act_traj, desired_state)\n",
    "    b2.add_trajectory(state_traj, act_traj, desired_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50, 8) (32, 50) (32,) (32,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32, 8), (32,), (32, 5), (32, 50, 8), (32, 50))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_obs, b1_acts, b1_goals, _,_,_ = b1.sample_batch(32)\n",
    "b2_obs, b2_acts, b2_goals, _,_,_ = b2.sample_batch(32)\n",
    "b1_obs.shape, b1_acts.shape, b1_goals.shape, b2_obs.shape, b2_acts.shape#, b2_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50, 8) (32, 50) (32,) (32,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32, 8), (32,), (32, 5), (32, 50, 8), (32, 50))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2, 8)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, ps = einops.pack((b1_obs,b1_obs),'b * h')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 8]),\n",
       " torch.Size([32, 11, 8]),\n",
       " torch.Size([32, 11, 8]),\n",
       " tensor(True))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 11 \n",
    "S, X_a = torch.rand(32,50,8), torch.rand(32,50,8)\n",
    "X_g = S[:,k]\n",
    "X_s = S[:,:k]\n",
    "X_a = X_a[:,:k]\n",
    "X_g.shape, X_s.shape, X_a.shape, (S[:,11]==X_g[:,:]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True),\n",
       " tensor(True),\n",
       " torch.Size([32, 11, 16]),\n",
       " torch.Size([11, 32, 16]),\n",
       " tensor(True))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq, ps = einops.pack((X_s, X_a), 'b t * h')  \n",
    "seq = einops.rearrange(seq, 'b t type h -> b (t type) h')\n",
    "seq_, ps = einops.pack((X_g, seq), 'b * h')\n",
    "seq_r = einops.rearrange(seq, 'b (t type) h -> b t (type h)', type=2)\n",
    "seq_swapped = einops.rearrange(seq, 'b t h -> t b h')\n",
    "seq_r_from_swapped = einops.rearrange(seq_swapped, '(t type) b h -> t b (type h)', type=2)\n",
    "seq_r_from_swapped_flip = einops.rearrange(seq_r_from_swapped, 't b h -> b t h')\n",
    "(seq_[:,1:]==seq).all(), (seq_[:,0] == X_g).all(), seq_r.shape, seq_r_from_swapped.shape, (seq_r == seq_r_from_swapped_flip).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(True))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(seq_r_from_swapped_flip[:,:,:8] == X_s).all(), (seq_r_from_swapped_flip[:,:,8:] == X_a).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))[:5],list(range(10))[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126400"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*400+400*300+300*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38112"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args = dotdict(\n",
    "            d_model=32,\n",
    "            nhead=1,\n",
    "            dim_f=128,\n",
    "            layers=2,\n",
    "            max_len=50,    \n",
    "            dropout=0.1,\n",
    "            device='cpu'\n",
    "        )\n",
    "args = model_args\n",
    "s_policy = S_DiscreteIDMPolicy(env, model_args).net\n",
    "sum((p.numel() for p in s_policy.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_policy.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16640"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma = nn.MultiheadAttention(args.d_model, args.nhead)\n",
    "sum((p.numel() for p in ma.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, aw = ma(torch.rand(1,32,128),torch.rand(1,32,128),torch.rand(1,32,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 128])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126400"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*400+400*300+300*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3657, 1.7177, 1.8693, 2.4041, 1.3371, 0.9556, 1.6673, 1.2903, 2.0574,\n",
       "        1.6739, 1.2806, 1.4536, 0.8917, 1.2737, 1.0060, 1.2225, 0.5449, 0.9643,\n",
       "        1.1325, 1.6127, 2.2741, 1.1900, 1.1374, 1.3841, 2.1147, 1.4831, 2.0867,\n",
       "        1.5123, 1.1319, 1.9590, 1.8525, 0.9262], grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_policy.nll(torch.rand(32,8), torch.rand(32,5), torch.randint(0,4,(32,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_policy.act_vectorized(torch.rand(1,8), torch.rand(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 13])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,_ = einops.pack((torch.rand(32,8),torch.rand(32,5)), 'b *')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,32,4)\n",
    "(x[0] == einops.rearrange(x, 't b c -> (b t) c')[::2]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, targets_noise = torch.randint(0,4,(32,)), torch.randint(0,4,(32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3469, 0.6528, 0.2868, 0.4447, 0.9027, 0.6168, 0.4720, 0.2059, 0.3292,\n",
       "        0.9294, 0.0844, 0.9928, 0.7013, 0.1143, 0.7775, 0.3418, 0.2710, 0.5755,\n",
       "        0.9710, 0.9418, 0.9512, 0.0286, 0.1239, 0.4795, 0.9390, 0.5312, 0.7936,\n",
       "        0.8235, 0.7924, 0.8579, 0.8005, 0.2204])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand(32)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1, 1, 3, 1, 1, 2, 2, 3, 0, 2, 0, 0, 1, 0,\n",
       "        0, 3, 0, 1, 3, 0, 0, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(32)\n",
    "targets[r.gt(0.5)] = targets_noise[r.gt(0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0,\n",
       "        3, 1, 2, 2, 1, 0, 3, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_to_targets(targets, noise_rate=0.5, l=0,h=4, device='cpu'):\n",
    "    targets = targets.clone()\n",
    "    r = torch.rand(*targets.shape, device=device)\n",
    "    targets_noise = torch.randint(l,h,targets.shape, device=device)\n",
    "    targets[r.gt(1-noise_rate)] = targets_noise[r.gt(1-noise_rate)]\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3, 0, 2, 1, 1, 3, 1, 0, 3, 1, 3, 3, 2, 2, 0, 3, 1, 2, 2, 0, 0, 3,\n",
       "        0, 2, 2, 2, 1, 0, 0, 2])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3, 0, 2, 1, 2, 3, 1, 0, 2, 1, 1, 3, 2, 2, 0, 2, 1, 2, 0, 0, 0, 3,\n",
       "        3, 2, 0, 2, 1, 0, 1, 3])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_to_targets(targets, noise_rate=0.4, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_traj_mask(b_size: int, sz: int, t1:np.array, t2:np.array,\n",
    "                       device='cpu', mask_type='base') -> torch.Tensor:\n",
    "    mask = torch.full((b_size,sz,sz),float('-inf'), device=device)\n",
    "    for i in range(b_size):\n",
    "        if mask_type == 'restrictive': # unmask s_k and g\n",
    "            mask[i][:,t1[i]] = 0\n",
    "            mask[i][:,t2[i]] = 0\n",
    "        elif mask_type == 'pre': # unmask s_0,...,s_k,...,s_g\n",
    "            mask[i][:,:t2[i]+1] = 0 # +1 to include s_g\n",
    "        elif mask_type == 'all': # unmask everything\n",
    "            mask = torch.zeros(b_size, 50, 50, device=device)\n",
    "        elif mask_type == 'base': # unmask s_k,...,s_g\n",
    "            mask[i][:,t1[i]:t2[i]+1] = 0 # +1 to include s_g\n",
    "        else:\n",
    "            raise Exception(f\"mask_type = {mask_type} is an invalid mask type!\")\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size=32\n",
    "t1 = np.random.randint(0,49, (b_size,))\n",
    "t2 = np.random.randint(0,50, (b_size,))\n",
    "t2[t1 == t2] += 1\n",
    "start_idx = np.minimum(t1, t2)\n",
    "end_idx = np.maximum(t1, t2)\n",
    "mask = generate_traj_mask(b_size,50+1,start_idx+1,end_idx+1,mask_type='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_state_pad_masks(b_size:int, sz:int, t1:np.array, t2:np.array, device='cpu') -> torch.Tensor: \n",
    "    src_key_padding_masks = []\n",
    "    sz = 50\n",
    "    for i in range(b_size):\n",
    "        src_key_padding_mask = [False] * (start_idx[i]+1)\n",
    "        src_key_padding_mask += [True] * (sz - (start_idx[i]+1))\n",
    "        src_key_padding_mask[end_idx[i]] = 0\n",
    "        src_key_padding_masks.append(src_key_padding_mask)\n",
    "    src_key_padding_masks = np.asarray(src_key_padding_masks)\n",
    "    return torch.tensor(src_key_padding_masks, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.zeros((8)) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = einops.rearrange([np.zeros(8) for i in range(4)],'t h -> t h')\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,ps = einops.pack((t, np.zeros(8)), '* h')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, dtype=torch.int32), torch.Size([32, 50]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pad_masks = make_state_pad_masks(b_size, 50, start_idx, end_idx,device='cpu')\n",
    "state_pad_masks[0][start_idx[0]], state_pad_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n",
      "tensor(True) tensor(True) tensor(True)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(32,50,64)\n",
    "X_old = X.clone()\n",
    "pe = nn.Embedding(50,64)\n",
    "\n",
    "def add_act_tokens(X:torch.tensor, t1:np.array, t2:np.array, device:str='cpu') -> torch.tensor:\n",
    "    b_size, t, h = X.size()\n",
    "    new_X = torch.zeros(b_size, t+1, h, dtype=X.dtype, device=device)\n",
    "    for i in range(b_size):\n",
    "        new_X[i,:t1[i]+1] = X[i,:t1[i]+1]\n",
    "        new_X[i, t1[i]+1:t2[i]+1] = pe.weight[t1[i]:t2[i]]\n",
    "        new_X[i, t2[i]+1:] = X[i,t2[i]:]\n",
    "    return new_X\n",
    "X = add_act_tokens(X, start_idx, end_idx)\n",
    "for k in range(b_size):\n",
    "    i = 0\n",
    "    s, e = start_idx[i], end_idx[i]\n",
    "    print((X_old[i, :s+1] == X[i,:s+1]).all(), (pe.weight[s:e] == X[i, s+1:e+1]).all(), (X_old[i, e:] == X[i,e+1:]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_tokens(b_size:int, sz:int, dim:int, t1:np.array, t2:np.array, device:str='cpu'):\n",
    "    Z = torch.zeros(b_size, sz, dim, device=device)\n",
    "    tgt_key_padding_mask = torch.zeros(b_size, sz, device=device, dtype=torch.bool)\n",
    "    for i in range(b_size):\n",
    "        diff = t2[i]-t1[i]\n",
    "        Z[i,:diff] = pe.weight[t1[i]:t2[i]]\n",
    "        tgt_key_padding_mask[i, diff:] = True\n",
    "    return Z, tgt_key_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z, tgt_key_padding_mask = get_act_tokens(32, 50, 64, start_idx, end_idx)\n",
    "Z[tgt_key_padding_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 64])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[:,:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1,2,32)[torch.arange(1),np.array([1])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[0], t2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[torch.arange(32),t1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 8]), (256,), tensor(True), torch.Size([256, 8]))"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(256,50,8)\n",
    "g = np.random.randint(0,50,(256,))\n",
    "X_g = X[torch.arange(256), g]\n",
    "X_g_ = X.take_along_dim(torch.LongTensor(g[...,None,None]), 1).squeeze(1)\n",
    "X_g.shape, g.shape, (X_g_ == X_g).all(), X_g_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12,  6, 39, 11, 11,  6, 29, 11,  7,  0, 28,  9,  1, 19, 22,  9,  1,\n",
       "        23,  9,  3, 14,  3, 18, 32,  3, 15,  8, 17, 12, 11, 11,  9]),\n",
       " array([20, 46, 40, 13, 13, 38, 49, 37,  9, 11, 41, 41, 42, 37, 28, 14, 17,\n",
       "        44, 34, 32, 32, 16, 20, 33,  9, 31, 44, 21, 24, 27, 13, 14]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx[:32], end_idx[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "         -inf, -inf, -inf]),\n",
       " tensor(-inf))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0][10], mask[0][21][41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 1, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_0, g = torch.rand(2, 1, 128)\n",
    "z = torch.zeros((50+1, 1, 128), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0] = s_0 \n",
    "z[49] = g \n",
    "z[50] = torch.rand(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acts = torch.rand(50, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_acts.argmax(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_acts.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = einops.repeat(torch.rand(1,32), '() h -> repeat h', repeat=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1590)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(torch.rand(32),torch.rand(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to(**kwargs):\n",
    "    for k,v in kwargs.items():\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 2\n",
      "hi 32\n"
     ]
    }
   ],
   "source": [
    "to(ok=2, hi=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [torch.rand(20,4),torch.rand(13,4),torch.rand(4,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([37, 4])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,_ = einops.pack(a, '* b')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([37])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [torch.rand(20),torch.rand(13),torch.rand(4)]\n",
    "einops.pack(b, '*')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zerofy(X, time_state_idxs, goal_state_idxs, device='cpu'):\n",
    "    b_size = X.shape[0]\n",
    "    Z = torch.zeros_like(X, device=device)\n",
    "    arange = torch.arange(b_size, device=device)\n",
    "    Z[[arange, time_state_idxs]] = X[[arange, time_state_idxs]]\n",
    "    Z[[arange, goal_state_idxs]] = X[[arange, goal_state_idxs]]\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(b_size,50,128)\n",
    "z = zerofy(x, start_idx, end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0][9] == x[0,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10, 16, 36, ..., 15, 36, 20]), array([23, 39, 44, ..., 23, 44, 47]))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = deque(maxlen=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([0.54167173, 0.79242663, 0.83581172, 0.38478615, 0.99685984]),\n",
       "       array([0.46690283, 0.13800223, 0.35384076, 0.64194863, 0.38338471]),\n",
       "       array([0.41691808, 0.19452532, 0.35572218, 0.71153525, 0.43183435])],\n",
       "      maxlen=3)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.append(np.random.rand(5))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54167173, 0.79242663, 0.83581172, 0.38478615, 0.99685984],\n",
       "       [0.46690283, 0.13800223, 0.35384076, 0.64194863, 0.38338471],\n",
       "       [0.41691808, 0.19452532, 0.35572218, 0.71153525, 0.43183435]])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einops.rearrange(list(a),'b h -> b h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einops.pack((torch.rand(32,8),torch.rand(32,8)),'b *')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3598,  0.9786, -0.0271,  0.1492, -0.1496,  0.0220, -0.7949, -0.3468],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(8,8)(torch.rand(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3986627130687832"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gcsl_org_acts = np.load('tmp\\lunar\\gcsl\\gcsl_org1\\\\2023_02_08_12_58_37\\\\stored_actions.npz', allow_pickle=True)['acts']\n",
    "gcsl_msa_s_acts = np.load('tmp\\lunar\\gcsl\\gcsl_msa_sbuf\\\\2023_02_07_21_50_54\\\\buffer.pkl', allow_pickle=True)['store_actions']\n",
    "gcsl_msa_l_acts = np.load('tmp\\lunar\\gcsl\\gcsl_msa_lbuf1\\\\2023_02_08_12_54_47\\\\stored_actions.npz')['acts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3189, 50), (1787, 50), (3179, 50))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcsl_msa_l_acts.shape, gcsl_msa_s_acts.shape, gcsl_org_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('stored_actions.npz', stored_actions=gcsl_org_buf['store_actions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['stored_actions'], (412, 50))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_acts = np.load('stored_actions.npz')\n",
    "stored_acts.files, stored_acts['stored_actions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mhist(gcsl_msa_l_acts\u001b[39m.\u001b[39mflatten())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(gcsl_msa_l_acts.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_actions = np.zeros(\n",
    "            (100, 50, *env.action_space.shape),\n",
    "            dtype=env.action_space.dtype\n",
    "        )\n",
    "\n",
    "_track_actions = np.zeros(\n",
    "    (201_000, 50, *env.action_space.shape),\n",
    "    dtype=env.action_space.dtype\n",
    ")\n",
    "\n",
    "_states = np.zeros(\n",
    "    (100, 50, *env.state_space.shape),\n",
    "    dtype=env.state_space.dtype\n",
    ")\n",
    "_desired_states = np.zeros(\n",
    "    (100, *env.state_space.shape),\n",
    "    dtype=env.state_space.dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_buffer_size=100\n",
    "track_pointer = 201_000\n",
    "d = dict(states=_states[:current_buffer_size])\n",
    "if True:\n",
    "    d.update(dict(\n",
    "        actions=_actions[:current_buffer_size],\n",
    "        store_actions=_track_actions[:track_pointer],\n",
    "        desired_states=_desired_states[:current_buffer_size],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test.pkl', 'wb') as fp:\n",
    "    pickle.dump(d, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl = np.load('test.pkl', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201000, 50)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl['store_actions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_drive",
   "language": "python",
   "name": "rl_drive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31ea8475bab12084b093fd61ff22284c904e8bf3f1a38ae79904317b89dedb26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
