{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msmic\\Documents\\code\\rl\\carla\\rl_ad\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18,  6]), tensor([4, 1]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sz = 28\n",
    "\n",
    "world = torch.zeros(grid_sz,grid_sz)\n",
    "pos_gen = lambda grid_sz : torch.tensor((torch.randint(0,grid_sz,(1,)),torch.randint(0,grid_sz,(1,))))\n",
    "start_pos = pos_gen(grid_sz)\n",
    "end_pos = pos_gen(grid_sz)\n",
    "start_pos, end_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate actions from start to end, action_space: 0:up, 1:down, 2:left, 3:right\n",
    "def get_actions(start_pos, end_pos):\n",
    "    actions = []\n",
    "    grid_positions = []\n",
    "    i_dif = end_pos[0] - start_pos[0]\n",
    "    j_dif = end_pos[1] - start_pos[1]\n",
    "\n",
    "    for i in range(abs(i_dif)+1):\n",
    "        if i_dif < 0:\n",
    "            actions.append(0)\n",
    "            grid_positions.append(torch.tensor((start_pos[0]-i,start_pos[1])))\n",
    "        elif i_dif > 0:\n",
    "            actions.append(1)\n",
    "            grid_positions.append(torch.tensor((start_pos[0]+i,start_pos[1])))\n",
    "    \n",
    "    for j in range(abs(j_dif)+1):\n",
    "        grid_i = grid_positions[-1][0] if len(grid_positions)>0 else start_pos[0]\n",
    "        if j_dif < 0:\n",
    "            actions.append(2)\n",
    "            grid_positions.append(torch.tensor((grid_i,start_pos[1]-j)))\n",
    "        elif j_dif > 0:\n",
    "            actions.append(3)\n",
    "            grid_positions.append(torch.tensor((grid_i,start_pos[1]+j)))\n",
    "    \n",
    "    return torch.tensor((actions)), torch.stack(grid_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18,  6]),\n",
       " tensor([4, 1]),\n",
       " tensor([[18,  6],\n",
       "         [17,  6],\n",
       "         [16,  6],\n",
       "         [15,  6],\n",
       "         [14,  6],\n",
       "         [13,  6],\n",
       "         [12,  6],\n",
       "         [11,  6],\n",
       "         [10,  6],\n",
       "         [ 9,  6],\n",
       "         [ 8,  6],\n",
       "         [ 7,  6],\n",
       "         [ 6,  6],\n",
       "         [ 5,  6],\n",
       "         [ 4,  6],\n",
       "         [ 4,  6],\n",
       "         [ 4,  5],\n",
       "         [ 4,  4],\n",
       "         [ 4,  3],\n",
       "         [ 4,  2],\n",
       "         [ 4,  1]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions, grid_positions = get_actions(start_pos.clone(), end_pos)\n",
    "start_pos, end_pos, grid_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batch of data \n",
    "def get_batch(grid_sz, batch_size):\n",
    "    acts, grid_pos = [], []\n",
    "    start_positions, end_positions = [], []\n",
    "    for i in range(batch_size):\n",
    "        start_pos = pos_gen(grid_sz)\n",
    "        end_pos = pos_gen(grid_sz)\n",
    "        # ensure start != end_pos\n",
    "        while start_pos[0] == end_pos[0] and start_pos[1] == end_pos[1]:\n",
    "            end_pos = pos_gen(grid_sz)\n",
    "        actions, grid_positions = get_actions(start_pos.clone(), end_pos)\n",
    "        acts.append(actions)\n",
    "        grid_pos.append(grid_positions)\n",
    "        start_positions.append(start_pos)\n",
    "        end_positions.append(end_pos)\n",
    "    \n",
    "    return torch.stack(start_positions), torch.stack(end_positions), acts, grid_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grids(start_positions, end_positions, grid_sz, b_sz):\n",
    "    grid = torch.zeros(b_sz, grid_sz, grid_sz)\n",
    "    b_idx = torch.arange(b_sz)\n",
    "    grid[b_idx, start_positions[:,0], start_positions[:,1]] = 0.5\n",
    "    grid[b_idx, end_positions[:,0], end_positions[:,1]] = 1.0\n",
    "    return grid\n",
    "\n",
    "def make_grid(positions, grid_sz, b_sz):\n",
    "    grid = torch.zeros(b_sz, grid_sz, grid_sz)\n",
    "    b_idx = torch.arange(b_sz)\n",
    "    grid[b_idx, positions[:,0], positions[:,1]] = 1.0\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_s_sn_act(grid_positions, actions, b_sz):\n",
    "    # sample state and next state and act along path toward end_pos \n",
    "    sampled_states, next_states, sampled_acts, end_positions = [], [], [], []\n",
    "    for i in range(b_sz):\n",
    "        if len(actions[i]) == 1:\n",
    "            continue \n",
    "        idx = torch.randint(0, len(actions[i])-1, (1,))\n",
    "        sampled_states.append(grid_positions[i][idx])\n",
    "        next_states.append(grid_positions[i][idx+1])\n",
    "        sampled_acts.append(actions[i][idx])\n",
    "        end_positions.append(grid_positions[i][-1])\n",
    "    sampled_states = torch.stack(sampled_states).squeeze(1)\n",
    "    next_states = torch.stack(next_states).squeeze(1)\n",
    "    sampled_acts = torch.stack(sampled_acts)\n",
    "    end_positions = torch.stack(end_positions)\n",
    "    return sampled_states, next_states, sampled_acts, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sz = 32\n",
    "start_positions, end_positions, actions, grid_positions = get_batch(grid_sz, b_sz)\n",
    "start_positions.shape, end_positions.shape, len(actions), len(grid_positions)\n",
    "sampled_states, next_states, sampled_acts, end_positions_ = sample_s_sn_act(grid_positions, actions, b_sz)\n",
    "sampled_states.shape, next_states.shape, sampled_acts.shape, end_positions.shape\n",
    "grids_input = make_grids(sampled_states, end_positions, grid_sz, b_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map grid pos to 1d index\n",
    "def grid_pos_to_idx(pos, grid_sz):\n",
    "    return pos[:,0]*grid_sz + pos[:,1]\n",
    "\n",
    "# map 1d index to grid pos\n",
    "def idx_to_grid_pos(idx, grid_sz):\n",
    "    return torch.stack((idx//grid_sz, idx%grid_sz)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate next state, when given a state and action \n",
    "def simulate_next_state(states, action, grid_sz):\n",
    "    # states: (b_sz, 2)\n",
    "    # action: (b_sz, 1)\n",
    "    # return: (b_sz, 2)\n",
    "        \n",
    "    # act_idx to 2d tensor 0: up, 1: down, 2: left, 3: right\n",
    "    action_2d = torch.zeros((action.shape[0], 2))\n",
    "    action_2d[action == 0, 0] = -1\n",
    "    action_2d[action == 1, 0] = 1\n",
    "    action_2d[action == 2, 1] = -1\n",
    "    action_2d[action == 3, 1] = 1\n",
    "    \n",
    "    print(action_2d.shape, states.shape)\n",
    "    next_states = states + action_2d\n",
    "    next_states = torch.clamp(next_states, 0, grid_sz-1)\n",
    "    return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(6))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = grid_pos_to_idx(next_states, grid_sz)\n",
    "next_states_ = idx_to_grid_pos(idxs, grid_sz)\n",
    "(next_states == next_states_).all(), idxs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 10, 10]), torch.Size([32]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_dim = 4\n",
    "grid_sz = 10\n",
    "# Train step \n",
    "sampled_states, next_states, sampled_acts, end_positions_ = sample_s_sn_act(grid_positions, actions, b_sz)\n",
    "grids_input = make_grids(sampled_states, end_positions_, grid_sz, b_sz).unsqueeze(1)\n",
    "targets = grid_pos_to_idx(next_states, grid_sz)\n",
    "grids_input.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 64\n",
    "state_embedding = nn.Embedding(grid_sz*grid_sz, dim)\n",
    "\n",
    "state_encoder = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(grid_sz*grid_sz, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, dim),\n",
    ")\n",
    "\n",
    "state_predictor = nn.Sequential(\n",
    "    nn.Linear(dim+dim, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, dim),\n",
    ")\n",
    "\n",
    "action_predictor = nn.Sequential(\n",
    "    nn.Linear(dim+dim, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, act_dim),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids_input = make_grid(sampled_states, grid_sz, b_sz)\n",
    "sg = state_encoder(grids_input)\n",
    "# s_next_start_idx_pred = state_predictor(sg)\n",
    "# # s_next_start preds to next state predictions \n",
    "# s_next_start_idx = torch.argmax(s_next_start_idx_pred, dim=1)\n",
    "# s_next_start = idx_to_grid_pos(s_next_start_idx, grid_sz)\n",
    "# s_next_grid = make_grids(s_next_start, end_positions_, grid_sz, b_sz).unsqueeze(1)\n",
    "# sg_next = state_goal_encoder(s_next_grid)\n",
    "\n",
    "# a = action_predictor(torch.cat((sg, sg_next), dim=1))\n",
    "sg.shape#, s_next_start_idx.shape, sg_next.shape, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 4.8872880935668945, Acc: 0.0\n",
      "Epoch: 1, Loss: 4.923231601715088, Acc: 0.0\n",
      "Epoch: 2, Loss: 4.7670135498046875, Acc: 0.03125\n",
      "Epoch: 3, Loss: 4.667690753936768, Acc: 0.03125\n",
      "Epoch: 4, Loss: 4.724980354309082, Acc: 0.0\n",
      "Epoch: 5, Loss: 4.738255023956299, Acc: 0.0\n",
      "Epoch: 6, Loss: 4.664534568786621, Acc: 0.0\n",
      "Epoch: 7, Loss: 4.786640167236328, Acc: 0.03125\n",
      "Epoch: 8, Loss: 4.672857284545898, Acc: 0.0\n",
      "Epoch: 9, Loss: 4.635302543640137, Acc: 0.03125\n",
      "Epoch: 10, Loss: 4.679807186126709, Acc: 0.0\n",
      "Epoch: 11, Loss: 4.508739948272705, Acc: 0.03125\n",
      "Epoch: 12, Loss: 4.64932918548584, Acc: 0.0\n",
      "Epoch: 13, Loss: 4.555769443511963, Acc: 0.0\n",
      "Epoch: 14, Loss: 4.496523857116699, Acc: 0.03125\n",
      "Epoch: 15, Loss: 4.536107063293457, Acc: 0.03125\n",
      "Epoch: 16, Loss: 4.781723499298096, Acc: 0.0\n",
      "Epoch: 17, Loss: 4.590867042541504, Acc: 0.0\n",
      "Epoch: 18, Loss: 4.653238296508789, Acc: 0.0\n",
      "Epoch: 19, Loss: 4.415218353271484, Acc: 0.03125\n",
      "Epoch: 20, Loss: 4.534533977508545, Acc: 0.0\n",
      "Epoch: 21, Loss: 4.4090070724487305, Acc: 0.09375\n",
      "Epoch: 22, Loss: 4.456427574157715, Acc: 0.0625\n",
      "Epoch: 23, Loss: 4.352357864379883, Acc: 0.03125\n",
      "Epoch: 24, Loss: 4.469334602355957, Acc: 0.0625\n",
      "Epoch: 25, Loss: 4.356474876403809, Acc: 0.125\n",
      "Epoch: 26, Loss: 4.47622537612915, Acc: 0.15625\n",
      "Epoch: 27, Loss: 4.286938190460205, Acc: 0.21875\n",
      "Epoch: 28, Loss: 4.418453693389893, Acc: 0.0625\n",
      "Epoch: 29, Loss: 4.423752307891846, Acc: 0.09375\n",
      "Epoch: 30, Loss: 4.369821548461914, Acc: 0.125\n",
      "Epoch: 31, Loss: 4.311779022216797, Acc: 0.25\n",
      "Epoch: 32, Loss: 4.368244647979736, Acc: 0.125\n",
      "Epoch: 33, Loss: 4.2304368019104, Acc: 0.21875\n",
      "Epoch: 34, Loss: 4.206405162811279, Acc: 0.1875\n",
      "Epoch: 35, Loss: 4.247109413146973, Acc: 0.21875\n",
      "Epoch: 36, Loss: 4.345427513122559, Acc: 0.09375\n",
      "Epoch: 37, Loss: 4.376068115234375, Acc: 0.125\n",
      "Epoch: 38, Loss: 4.385706424713135, Acc: 0.0625\n",
      "Epoch: 39, Loss: 4.264673233032227, Acc: 0.21875\n",
      "Epoch: 40, Loss: 4.192887783050537, Acc: 0.21875\n",
      "Epoch: 41, Loss: 4.136848449707031, Acc: 0.3125\n",
      "Epoch: 42, Loss: 4.203070163726807, Acc: 0.25\n",
      "Epoch: 43, Loss: 4.109684467315674, Acc: 0.375\n",
      "Epoch: 44, Loss: 4.043442249298096, Acc: 0.40625\n",
      "Epoch: 45, Loss: 4.145535469055176, Acc: 0.4375\n",
      "Epoch: 46, Loss: 4.093042373657227, Acc: 0.375\n",
      "Epoch: 47, Loss: 4.073894500732422, Acc: 0.34375\n",
      "Epoch: 48, Loss: 3.999620199203491, Acc: 0.5\n",
      "Epoch: 49, Loss: 4.094182968139648, Acc: 0.34375\n",
      "Epoch: 50, Loss: 4.009024620056152, Acc: 0.46875\n",
      "Epoch: 51, Loss: 3.9575936794281006, Acc: 0.40625\n",
      "Epoch: 52, Loss: 3.9721438884735107, Acc: 0.4375\n",
      "Epoch: 53, Loss: 3.910059690475464, Acc: 0.4375\n",
      "Epoch: 54, Loss: 3.8117620944976807, Acc: 0.5\n",
      "Epoch: 55, Loss: 3.7911319732666016, Acc: 0.5\n",
      "Epoch: 56, Loss: 3.808769464492798, Acc: 0.5\n",
      "Epoch: 57, Loss: 3.867462158203125, Acc: 0.40625\n",
      "Epoch: 58, Loss: 3.7269701957702637, Acc: 0.5625\n",
      "Epoch: 59, Loss: 3.792419672012329, Acc: 0.4375\n",
      "Epoch: 60, Loss: 3.50950288772583, Acc: 0.6875\n",
      "Epoch: 61, Loss: 3.854948043823242, Acc: 0.3125\n",
      "Epoch: 62, Loss: 3.597501039505005, Acc: 0.53125\n",
      "Epoch: 63, Loss: 3.6118621826171875, Acc: 0.5\n",
      "Epoch: 64, Loss: 3.5687007904052734, Acc: 0.5\n",
      "Epoch: 65, Loss: 3.5978610515594482, Acc: 0.40625\n",
      "Epoch: 66, Loss: 3.3706982135772705, Acc: 0.65625\n",
      "Epoch: 67, Loss: 3.4598588943481445, Acc: 0.59375\n",
      "Epoch: 68, Loss: 3.3549466133117676, Acc: 0.625\n",
      "Epoch: 69, Loss: 3.5535342693328857, Acc: 0.5625\n",
      "Epoch: 70, Loss: 3.283806562423706, Acc: 0.6875\n",
      "Epoch: 71, Loss: 3.421067953109741, Acc: 0.53125\n",
      "Epoch: 72, Loss: 3.3580386638641357, Acc: 0.71875\n",
      "Epoch: 73, Loss: 3.3871898651123047, Acc: 0.625\n",
      "Epoch: 74, Loss: 3.2873902320861816, Acc: 0.71875\n",
      "Epoch: 75, Loss: 3.0552103519439697, Acc: 0.75\n",
      "Epoch: 76, Loss: 3.0595059394836426, Acc: 0.78125\n",
      "Epoch: 77, Loss: 3.1926209926605225, Acc: 0.625\n",
      "Epoch: 78, Loss: 3.3552756309509277, Acc: 0.5625\n",
      "Epoch: 79, Loss: 2.7850210666656494, Acc: 0.875\n",
      "Epoch: 80, Loss: 3.016756057739258, Acc: 0.71875\n",
      "Epoch: 81, Loss: 3.0184240341186523, Acc: 0.6875\n",
      "Epoch: 82, Loss: 2.570523977279663, Acc: 0.84375\n",
      "Epoch: 83, Loss: 2.6401312351226807, Acc: 0.84375\n",
      "Epoch: 84, Loss: 2.682349920272827, Acc: 0.8125\n",
      "Epoch: 85, Loss: 2.7126126289367676, Acc: 0.6875\n",
      "Epoch: 86, Loss: 2.7587246894836426, Acc: 0.6875\n",
      "Epoch: 87, Loss: 2.834581136703491, Acc: 0.65625\n",
      "Epoch: 88, Loss: 2.6067728996276855, Acc: 0.75\n",
      "Epoch: 89, Loss: 2.430358648300171, Acc: 0.8125\n",
      "Epoch: 90, Loss: 2.40134334564209, Acc: 0.8125\n",
      "Epoch: 91, Loss: 2.3548943996429443, Acc: 0.65625\n",
      "Epoch: 92, Loss: 2.3397090435028076, Acc: 0.84375\n",
      "Epoch: 93, Loss: 2.43328595161438, Acc: 0.71875\n",
      "Epoch: 94, Loss: 2.3408162593841553, Acc: 0.75\n",
      "Epoch: 95, Loss: 2.2181084156036377, Acc: 0.75\n",
      "Epoch: 96, Loss: 2.453566551208496, Acc: 0.625\n",
      "Epoch: 97, Loss: 2.0813941955566406, Acc: 0.84375\n",
      "Epoch: 98, Loss: 2.0529839992523193, Acc: 0.84375\n",
      "Epoch: 99, Loss: 2.244558572769165, Acc: 0.6875\n",
      "Epoch: 100, Loss: 1.8991262912750244, Acc: 0.75\n",
      "Epoch: 101, Loss: 1.942945957183838, Acc: 0.875\n",
      "Epoch: 102, Loss: 1.9342265129089355, Acc: 0.875\n",
      "Epoch: 103, Loss: 1.7584645748138428, Acc: 0.8125\n",
      "Epoch: 104, Loss: 1.8432259559631348, Acc: 0.78125\n",
      "Epoch: 105, Loss: 1.2775535583496094, Acc: 0.96875\n",
      "Epoch: 106, Loss: 1.8055213689804077, Acc: 0.90625\n",
      "Epoch: 107, Loss: 1.2483313083648682, Acc: 0.875\n",
      "Epoch: 108, Loss: 1.6171832084655762, Acc: 0.8125\n",
      "Epoch: 109, Loss: 1.4379159212112427, Acc: 0.84375\n",
      "Epoch: 110, Loss: 1.4466485977172852, Acc: 0.90625\n",
      "Epoch: 111, Loss: 1.3540610074996948, Acc: 0.9375\n",
      "Epoch: 112, Loss: 1.7043126821517944, Acc: 0.84375\n",
      "Epoch: 113, Loss: 1.5448294878005981, Acc: 0.90625\n",
      "Epoch: 114, Loss: 1.1311322450637817, Acc: 0.90625\n",
      "Epoch: 115, Loss: 1.2258009910583496, Acc: 0.90625\n",
      "Epoch: 116, Loss: 1.0060142278671265, Acc: 0.9375\n",
      "Epoch: 117, Loss: 0.8720455765724182, Acc: 0.96875\n",
      "Epoch: 118, Loss: 1.2085269689559937, Acc: 0.875\n",
      "Epoch: 119, Loss: 0.8564965128898621, Acc: 0.96875\n",
      "Epoch: 120, Loss: 1.295312762260437, Acc: 0.875\n",
      "Epoch: 121, Loss: 1.0024031400680542, Acc: 1.0\n",
      "Epoch: 122, Loss: 0.8911274075508118, Acc: 0.9375\n",
      "Epoch: 123, Loss: 1.0160671472549438, Acc: 0.96875\n",
      "Epoch: 124, Loss: 0.9217391014099121, Acc: 0.90625\n",
      "Epoch: 125, Loss: 0.6456215977668762, Acc: 1.0\n",
      "Epoch: 126, Loss: 1.176529884338379, Acc: 0.96875\n",
      "Epoch: 127, Loss: 0.9265795350074768, Acc: 0.9375\n",
      "Epoch: 128, Loss: 0.8498632311820984, Acc: 0.96875\n",
      "Epoch: 129, Loss: 0.7328349351882935, Acc: 0.96875\n",
      "Epoch: 130, Loss: 0.8949698805809021, Acc: 0.96875\n",
      "Epoch: 131, Loss: 0.8904925584793091, Acc: 0.96875\n",
      "Epoch: 132, Loss: 0.5219477415084839, Acc: 1.0\n",
      "Epoch: 133, Loss: 0.6820476055145264, Acc: 1.0\n",
      "Epoch: 134, Loss: 0.35796502232551575, Acc: 1.0\n",
      "Epoch: 135, Loss: 0.6975159049034119, Acc: 1.0\n",
      "Epoch: 136, Loss: 0.4104197323322296, Acc: 1.0\n",
      "Epoch: 137, Loss: 0.6059900522232056, Acc: 1.0\n",
      "Epoch: 138, Loss: 0.5475845336914062, Acc: 1.0\n",
      "Epoch: 139, Loss: 0.42451411485671997, Acc: 1.0\n",
      "Epoch: 140, Loss: 0.5470039248466492, Acc: 1.0\n",
      "Epoch: 141, Loss: 0.4008767306804657, Acc: 1.0\n",
      "Epoch: 142, Loss: 0.3332173228263855, Acc: 1.0\n",
      "Epoch: 143, Loss: 0.45976513624191284, Acc: 1.0\n",
      "Epoch: 144, Loss: 0.2998787760734558, Acc: 1.0\n",
      "Epoch: 145, Loss: 0.4309238791465759, Acc: 1.0\n",
      "Epoch: 146, Loss: 0.33268460631370544, Acc: 1.0\n",
      "Epoch: 147, Loss: 0.3072073757648468, Acc: 1.0\n",
      "Epoch: 148, Loss: 0.26275384426116943, Acc: 1.0\n",
      "Epoch: 149, Loss: 0.2353426069021225, Acc: 1.0\n",
      "Epoch: 150, Loss: 0.1738414317369461, Acc: 1.0\n",
      "Epoch: 151, Loss: 0.30108535289764404, Acc: 1.0\n",
      "Epoch: 152, Loss: 0.381072461605072, Acc: 1.0\n",
      "Epoch: 153, Loss: 0.21889959275722504, Acc: 1.0\n",
      "Epoch: 154, Loss: 0.42539316415786743, Acc: 1.0\n",
      "Epoch: 155, Loss: 0.17146430909633636, Acc: 1.0\n",
      "Epoch: 156, Loss: 0.23585942387580872, Acc: 1.0\n",
      "Epoch: 157, Loss: 0.2529457211494446, Acc: 1.0\n",
      "Epoch: 158, Loss: 0.28002384305000305, Acc: 1.0\n",
      "Epoch: 159, Loss: 0.15428318083286285, Acc: 1.0\n",
      "Epoch: 160, Loss: 0.15992248058319092, Acc: 1.0\n",
      "Epoch: 161, Loss: 0.24420872330665588, Acc: 1.0\n",
      "Epoch: 162, Loss: 0.26805171370506287, Acc: 0.96875\n",
      "Epoch: 163, Loss: 0.12686356902122498, Acc: 1.0\n",
      "Epoch: 164, Loss: 0.1932152658700943, Acc: 1.0\n",
      "Epoch: 165, Loss: 0.1960570216178894, Acc: 1.0\n",
      "Epoch: 166, Loss: 0.15256735682487488, Acc: 1.0\n",
      "Epoch: 167, Loss: 0.19002294540405273, Acc: 1.0\n",
      "Epoch: 168, Loss: 0.19545213878154755, Acc: 1.0\n",
      "Epoch: 169, Loss: 0.2063131332397461, Acc: 1.0\n",
      "Epoch: 170, Loss: 0.16380003094673157, Acc: 1.0\n",
      "Epoch: 171, Loss: 0.12323364615440369, Acc: 1.0\n",
      "Epoch: 172, Loss: 0.19155777990818024, Acc: 1.0\n",
      "Epoch: 173, Loss: 0.11877039074897766, Acc: 1.0\n",
      "Epoch: 174, Loss: 0.08359000831842422, Acc: 1.0\n",
      "Epoch: 175, Loss: 0.11416680365800858, Acc: 1.0\n",
      "Epoch: 176, Loss: 0.15632614493370056, Acc: 1.0\n",
      "Epoch: 177, Loss: 0.14894618093967438, Acc: 0.96875\n",
      "Epoch: 178, Loss: 0.08650854229927063, Acc: 1.0\n",
      "Epoch: 179, Loss: 0.08835136145353317, Acc: 1.0\n",
      "Epoch: 180, Loss: 0.09645549952983856, Acc: 1.0\n",
      "Epoch: 181, Loss: 0.10282158851623535, Acc: 1.0\n",
      "Epoch: 182, Loss: 0.15736520290374756, Acc: 1.0\n",
      "Epoch: 183, Loss: 0.08872098475694656, Acc: 1.0\n",
      "Epoch: 184, Loss: 0.11216606944799423, Acc: 1.0\n",
      "Epoch: 185, Loss: 0.05801472067832947, Acc: 1.0\n",
      "Epoch: 186, Loss: 0.05185973271727562, Acc: 1.0\n",
      "Epoch: 187, Loss: 0.11243131011724472, Acc: 1.0\n",
      "Epoch: 188, Loss: 0.12059105932712555, Acc: 1.0\n",
      "Epoch: 189, Loss: 0.07060149312019348, Acc: 1.0\n",
      "Epoch: 190, Loss: 0.10135144740343094, Acc: 1.0\n",
      "Epoch: 191, Loss: 0.16576723754405975, Acc: 0.96875\n",
      "Epoch: 192, Loss: 0.0686410441994667, Acc: 1.0\n",
      "Epoch: 193, Loss: 0.1012745052576065, Acc: 1.0\n",
      "Epoch: 194, Loss: 0.07756984233856201, Acc: 1.0\n",
      "Epoch: 195, Loss: 0.0497625358402729, Acc: 1.0\n",
      "Epoch: 196, Loss: 0.0829077661037445, Acc: 1.0\n",
      "Epoch: 197, Loss: 0.05911373347043991, Acc: 1.0\n",
      "Epoch: 198, Loss: 0.0476406030356884, Acc: 1.0\n",
      "Epoch: 199, Loss: 0.0754709243774414, Acc: 1.0\n",
      "Epoch: 200, Loss: 0.04394236207008362, Acc: 1.0\n",
      "Epoch: 201, Loss: 0.07911888509988785, Acc: 1.0\n",
      "Epoch: 202, Loss: 0.05147161707282066, Acc: 1.0\n",
      "Epoch: 203, Loss: 0.06690342724323273, Acc: 1.0\n",
      "Epoch: 204, Loss: 0.06020647659897804, Acc: 1.0\n",
      "Epoch: 205, Loss: 0.03522674739360809, Acc: 1.0\n",
      "Epoch: 206, Loss: 0.03805288299918175, Acc: 1.0\n",
      "Epoch: 207, Loss: 0.08337395638227463, Acc: 1.0\n",
      "Epoch: 208, Loss: 0.03922627866268158, Acc: 1.0\n",
      "Epoch: 209, Loss: 0.05051456764340401, Acc: 1.0\n",
      "Epoch: 210, Loss: 0.037639468908309937, Acc: 1.0\n",
      "Epoch: 211, Loss: 0.1111932173371315, Acc: 0.96875\n",
      "Epoch: 212, Loss: 0.04961017891764641, Acc: 1.0\n",
      "Epoch: 213, Loss: 0.03075384348630905, Acc: 1.0\n",
      "Epoch: 214, Loss: 0.04159185290336609, Acc: 1.0\n",
      "Epoch: 215, Loss: 0.03755532577633858, Acc: 1.0\n",
      "Epoch: 216, Loss: 0.03897743672132492, Acc: 1.0\n",
      "Epoch: 217, Loss: 0.04216722026467323, Acc: 1.0\n",
      "Epoch: 218, Loss: 0.045444317162036896, Acc: 1.0\n",
      "Epoch: 219, Loss: 0.035550374537706375, Acc: 1.0\n",
      "Epoch: 220, Loss: 0.042867351323366165, Acc: 1.0\n",
      "Epoch: 221, Loss: 0.05996404215693474, Acc: 1.0\n",
      "Epoch: 222, Loss: 0.036167699843645096, Acc: 1.0\n",
      "Epoch: 223, Loss: 0.0874168798327446, Acc: 1.0\n",
      "Epoch: 224, Loss: 0.031738098710775375, Acc: 1.0\n",
      "Epoch: 225, Loss: 0.03338408097624779, Acc: 1.0\n",
      "Epoch: 226, Loss: 0.026672428473830223, Acc: 1.0\n",
      "Epoch: 227, Loss: 0.03817399963736534, Acc: 1.0\n",
      "Epoch: 228, Loss: 0.03942427411675453, Acc: 1.0\n",
      "Epoch: 229, Loss: 0.029911618679761887, Acc: 1.0\n",
      "Epoch: 230, Loss: 0.04358721151947975, Acc: 1.0\n",
      "Epoch: 231, Loss: 0.027303587645292282, Acc: 1.0\n",
      "Epoch: 232, Loss: 0.03122161515057087, Acc: 1.0\n",
      "Epoch: 233, Loss: 0.031715575605630875, Acc: 1.0\n",
      "Epoch: 234, Loss: 0.03692813962697983, Acc: 1.0\n",
      "Epoch: 235, Loss: 0.019632967188954353, Acc: 1.0\n",
      "Epoch: 236, Loss: 0.03194667771458626, Acc: 1.0\n",
      "Epoch: 237, Loss: 0.03776821121573448, Acc: 1.0\n",
      "Epoch: 238, Loss: 0.026039477437734604, Acc: 1.0\n",
      "Epoch: 239, Loss: 0.024335218593478203, Acc: 1.0\n",
      "Epoch: 240, Loss: 0.025314629077911377, Acc: 1.0\n",
      "Epoch: 241, Loss: 0.020959384739398956, Acc: 1.0\n",
      "Epoch: 242, Loss: 0.021679868921637535, Acc: 1.0\n",
      "Epoch: 243, Loss: 0.03402069956064224, Acc: 1.0\n",
      "Epoch: 244, Loss: 0.031650349497795105, Acc: 1.0\n",
      "Epoch: 245, Loss: 0.021661529317498207, Acc: 1.0\n",
      "Epoch: 246, Loss: 0.024021737277507782, Acc: 1.0\n",
      "Epoch: 247, Loss: 0.022394046187400818, Acc: 1.0\n",
      "Epoch: 248, Loss: 0.02078671008348465, Acc: 1.0\n",
      "Epoch: 249, Loss: 0.02893052063882351, Acc: 1.0\n",
      "Epoch: 250, Loss: 0.03577667102217674, Acc: 1.0\n",
      "Epoch: 251, Loss: 0.018864590674638748, Acc: 1.0\n",
      "Epoch: 252, Loss: 0.021390683948993683, Acc: 1.0\n",
      "Epoch: 253, Loss: 0.01871049590408802, Acc: 1.0\n",
      "Epoch: 254, Loss: 0.023664912208914757, Acc: 1.0\n",
      "Epoch: 255, Loss: 0.02118823677301407, Acc: 1.0\n",
      "Epoch: 256, Loss: 0.027143843472003937, Acc: 1.0\n",
      "Epoch: 257, Loss: 0.028508959338068962, Acc: 1.0\n",
      "Epoch: 258, Loss: 0.017574217170476913, Acc: 1.0\n",
      "Epoch: 259, Loss: 0.05364701896905899, Acc: 1.0\n",
      "Epoch: 260, Loss: 0.017674235627055168, Acc: 1.0\n",
      "Epoch: 261, Loss: 0.019758950918912888, Acc: 1.0\n",
      "Epoch: 262, Loss: 0.02162572368979454, Acc: 1.0\n",
      "Epoch: 263, Loss: 0.02406504563987255, Acc: 1.0\n",
      "Epoch: 264, Loss: 0.023848554119467735, Acc: 1.0\n",
      "Epoch: 265, Loss: 0.028964007273316383, Acc: 1.0\n",
      "Epoch: 266, Loss: 0.04533178731799126, Acc: 1.0\n",
      "Epoch: 267, Loss: 0.014496508054435253, Acc: 1.0\n",
      "Epoch: 268, Loss: 0.02198738418519497, Acc: 1.0\n",
      "Epoch: 269, Loss: 0.01793360337615013, Acc: 1.0\n",
      "Epoch: 270, Loss: 0.01927640289068222, Acc: 1.0\n",
      "Epoch: 271, Loss: 0.02805800549685955, Acc: 1.0\n",
      "Epoch: 272, Loss: 0.01349713560193777, Acc: 1.0\n",
      "Epoch: 273, Loss: 0.019943807274103165, Acc: 1.0\n",
      "Epoch: 274, Loss: 0.017852121964097023, Acc: 1.0\n",
      "Epoch: 275, Loss: 0.020117076113820076, Acc: 1.0\n",
      "Epoch: 276, Loss: 0.022983090952038765, Acc: 1.0\n",
      "Epoch: 277, Loss: 0.01774543523788452, Acc: 1.0\n",
      "Epoch: 278, Loss: 0.018901953473687172, Acc: 1.0\n",
      "Epoch: 279, Loss: 0.022331377491354942, Acc: 1.0\n",
      "Epoch: 280, Loss: 0.02023324742913246, Acc: 1.0\n",
      "Epoch: 281, Loss: 0.01349137257784605, Acc: 1.0\n",
      "Epoch: 282, Loss: 0.020791025832295418, Acc: 1.0\n",
      "Epoch: 283, Loss: 0.056883156299591064, Acc: 1.0\n",
      "Epoch: 284, Loss: 0.015471335500478745, Acc: 1.0\n",
      "Epoch: 285, Loss: 0.011198003776371479, Acc: 1.0\n",
      "Epoch: 286, Loss: 0.014345924369990826, Acc: 1.0\n",
      "Epoch: 287, Loss: 0.014506323263049126, Acc: 1.0\n",
      "Epoch: 288, Loss: 0.019444944337010384, Acc: 1.0\n",
      "Epoch: 289, Loss: 0.012728061527013779, Acc: 1.0\n",
      "Epoch: 290, Loss: 0.015540147200226784, Acc: 1.0\n",
      "Epoch: 291, Loss: 0.021558770909905434, Acc: 1.0\n",
      "Epoch: 292, Loss: 0.024813687428832054, Acc: 1.0\n",
      "Epoch: 293, Loss: 0.01587054878473282, Acc: 1.0\n",
      "Epoch: 294, Loss: 0.022681206464767456, Acc: 1.0\n",
      "Epoch: 295, Loss: 0.013603764586150646, Acc: 1.0\n",
      "Epoch: 296, Loss: 0.015451287850737572, Acc: 1.0\n",
      "Epoch: 297, Loss: 0.014561333693563938, Acc: 1.0\n",
      "Epoch: 298, Loss: 0.015217066742479801, Acc: 1.0\n",
      "Epoch: 299, Loss: 0.020151792094111443, Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train encoder decoder\n",
    "def train_encoder_decoder_step(encoder, state_embedding, optim, grid_sz, b_sz, epochs):\n",
    "    for e in epochs:\n",
    "        start_positions, end_positions, actions, grid_positions = get_batch(grid_sz, b_sz)\n",
    "        sampled_states, next_states, sampled_acts, end_positions_ = sample_s_sn_act(grid_positions, actions, b_sz)\n",
    "        grids_input = make_grid(sampled_states, grid_sz, b_sz).unsqueeze(1)\n",
    "        sampled_states_idx = grid_pos_to_idx(sampled_states, grid_sz)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        enc = encoder(grids_input)\n",
    "        logits = enc @ state_embedding.weight.T\n",
    "        \n",
    "        loss = F.cross_entropy(logits, sampled_states_idx)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        acc = (torch.argmax(logits, dim=1) == sampled_states_idx).float().mean()\n",
    "\n",
    "        print(f'Epoch: {e}, Loss: {loss.item()}, Acc: {acc.item()}')\n",
    "\n",
    "optim = torch.optim.Adam(list(state_encoder.parameters()) + list(state_embedding.parameters()), lr=1e-3)\n",
    "train_encoder_decoder_step(state_encoder, state_embedding, optim, grid_sz, b_sz, range(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save state_encoder \n",
    "torch.save(state_encoder.state_dict(), 'state_encoder.pt')\n",
    "torch.save(state_embedding.state_dict(), 'state_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = state_encoder(grids_input)\n",
    "logits = s @ state_embedding.weight.T\n",
    "pred_s = torch.argmax(logits, dim=1)\n",
    "sampled_states_idx = grid_pos_to_idx(sampled_states, grid_sz)\n",
    "(pred_s == sampled_states_idx).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 5.076756477355957, Acc: 0.0\n",
      "Epoch: 1, Loss: 4.919412612915039, Acc: 0.0\n",
      "Epoch: 2, Loss: 4.929455757141113, Acc: 0.03125\n",
      "Epoch: 3, Loss: 4.898471832275391, Acc: 0.0\n",
      "Epoch: 4, Loss: 4.580976963043213, Acc: 0.125\n",
      "Epoch: 5, Loss: 4.871441841125488, Acc: 0.03125\n",
      "Epoch: 6, Loss: 4.670561790466309, Acc: 0.03125\n",
      "Epoch: 7, Loss: 5.0955305099487305, Acc: 0.03125\n",
      "Epoch: 8, Loss: 4.646744728088379, Acc: 0.0\n",
      "Epoch: 9, Loss: 4.495335102081299, Acc: 0.0\n",
      "Epoch: 10, Loss: 4.7847771644592285, Acc: 0.03125\n",
      "Epoch: 11, Loss: 4.506476402282715, Acc: 0.03125\n",
      "Epoch: 12, Loss: 4.66901969909668, Acc: 0.03125\n",
      "Epoch: 13, Loss: 4.503342628479004, Acc: 0.0625\n",
      "Epoch: 14, Loss: 4.592710494995117, Acc: 0.03125\n",
      "Epoch: 15, Loss: 4.5716872215271, Acc: 0.0625\n",
      "Epoch: 16, Loss: 4.649235248565674, Acc: 0.09375\n",
      "Epoch: 17, Loss: 4.446005821228027, Acc: 0.0625\n",
      "Epoch: 18, Loss: 4.638891696929932, Acc: 0.03125\n",
      "Epoch: 19, Loss: 4.4446868896484375, Acc: 0.0625\n",
      "Epoch: 20, Loss: 4.3152289390563965, Acc: 0.0625\n",
      "Epoch: 21, Loss: 4.501145362854004, Acc: 0.03125\n",
      "Epoch: 22, Loss: 4.323843002319336, Acc: 0.0\n",
      "Epoch: 23, Loss: 4.464478492736816, Acc: 0.0\n",
      "Epoch: 24, Loss: 4.452999114990234, Acc: 0.0625\n",
      "Epoch: 25, Loss: 4.359040260314941, Acc: 0.125\n",
      "Epoch: 26, Loss: 4.391056537628174, Acc: 0.03125\n",
      "Epoch: 27, Loss: 4.42025899887085, Acc: 0.0625\n",
      "Epoch: 28, Loss: 4.282395839691162, Acc: 0.0625\n",
      "Epoch: 29, Loss: 4.3066487312316895, Acc: 0.09375\n",
      "Epoch: 30, Loss: 4.035318374633789, Acc: 0.125\n",
      "Epoch: 31, Loss: 4.234375953674316, Acc: 0.0\n",
      "Epoch: 32, Loss: 4.260169982910156, Acc: 0.15625\n",
      "Epoch: 33, Loss: 4.119524002075195, Acc: 0.15625\n",
      "Epoch: 34, Loss: 4.24945068359375, Acc: 0.09375\n",
      "Epoch: 35, Loss: 4.408270835876465, Acc: 0.03125\n",
      "Epoch: 36, Loss: 4.185068607330322, Acc: 0.15625\n",
      "Epoch: 37, Loss: 4.327946186065674, Acc: 0.0625\n",
      "Epoch: 38, Loss: 4.26582670211792, Acc: 0.09375\n",
      "Epoch: 39, Loss: 3.986656665802002, Acc: 0.09375\n",
      "Epoch: 40, Loss: 4.288242816925049, Acc: 0.125\n",
      "Epoch: 41, Loss: 4.430354118347168, Acc: 0.0\n",
      "Epoch: 42, Loss: 3.997622489929199, Acc: 0.09375\n",
      "Epoch: 43, Loss: 4.340575218200684, Acc: 0.1875\n",
      "Epoch: 44, Loss: 4.054020881652832, Acc: 0.15625\n",
      "Epoch: 45, Loss: 3.898665189743042, Acc: 0.125\n",
      "Epoch: 46, Loss: 4.133333206176758, Acc: 0.15625\n",
      "Epoch: 47, Loss: 4.3054022789001465, Acc: 0.125\n",
      "Epoch: 48, Loss: 4.090662956237793, Acc: 0.0625\n",
      "Epoch: 49, Loss: 3.981780529022217, Acc: 0.21875\n",
      "Epoch: 50, Loss: 4.248704433441162, Acc: 0.125\n",
      "Epoch: 51, Loss: 3.9237561225891113, Acc: 0.125\n",
      "Epoch: 52, Loss: 4.281522750854492, Acc: 0.0625\n",
      "Epoch: 53, Loss: 3.958120107650757, Acc: 0.15625\n",
      "Epoch: 54, Loss: 4.485631942749023, Acc: 0.03125\n",
      "Epoch: 55, Loss: 3.990610122680664, Acc: 0.15625\n",
      "Epoch: 56, Loss: 3.744523286819458, Acc: 0.1875\n",
      "Epoch: 57, Loss: 3.8797943592071533, Acc: 0.1875\n",
      "Epoch: 58, Loss: 4.124020099639893, Acc: 0.09375\n",
      "Epoch: 59, Loss: 4.225669860839844, Acc: 0.09375\n",
      "Epoch: 60, Loss: 3.6020872592926025, Acc: 0.25\n",
      "Epoch: 61, Loss: 3.769221782684326, Acc: 0.15625\n",
      "Epoch: 62, Loss: 3.7481601238250732, Acc: 0.25\n",
      "Epoch: 63, Loss: 4.226804733276367, Acc: 0.09375\n",
      "Epoch: 64, Loss: 3.959493637084961, Acc: 0.125\n",
      "Epoch: 65, Loss: 4.062142848968506, Acc: 0.15625\n",
      "Epoch: 66, Loss: 3.8034989833831787, Acc: 0.15625\n",
      "Epoch: 67, Loss: 3.805244207382202, Acc: 0.15625\n",
      "Epoch: 68, Loss: 3.7829091548919678, Acc: 0.21875\n",
      "Epoch: 69, Loss: 3.725487470626831, Acc: 0.1875\n",
      "Epoch: 70, Loss: 3.9325459003448486, Acc: 0.15625\n",
      "Epoch: 71, Loss: 3.8908162117004395, Acc: 0.15625\n",
      "Epoch: 72, Loss: 3.7365264892578125, Acc: 0.0625\n",
      "Epoch: 73, Loss: 4.032766819000244, Acc: 0.15625\n",
      "Epoch: 74, Loss: 3.8995983600616455, Acc: 0.15625\n",
      "Epoch: 75, Loss: 3.7326347827911377, Acc: 0.15625\n",
      "Epoch: 76, Loss: 3.5288314819335938, Acc: 0.3125\n",
      "Epoch: 77, Loss: 3.5418877601623535, Acc: 0.3125\n",
      "Epoch: 78, Loss: 3.965350389480591, Acc: 0.09375\n",
      "Epoch: 79, Loss: 3.9014344215393066, Acc: 0.09375\n",
      "Epoch: 80, Loss: 3.6934573650360107, Acc: 0.09375\n",
      "Epoch: 81, Loss: 3.625056505203247, Acc: 0.21875\n",
      "Epoch: 82, Loss: 3.9512667655944824, Acc: 0.1875\n",
      "Epoch: 83, Loss: 3.857914447784424, Acc: 0.15625\n",
      "Epoch: 84, Loss: 3.6759655475616455, Acc: 0.15625\n",
      "Epoch: 85, Loss: 3.3908286094665527, Acc: 0.21875\n",
      "Epoch: 86, Loss: 3.4871044158935547, Acc: 0.21875\n",
      "Epoch: 87, Loss: 3.7802188396453857, Acc: 0.28125\n",
      "Epoch: 88, Loss: 3.2187163829803467, Acc: 0.28125\n",
      "Epoch: 89, Loss: 3.4453227519989014, Acc: 0.21875\n",
      "Epoch: 90, Loss: 3.606257915496826, Acc: 0.28125\n",
      "Epoch: 91, Loss: 3.4767656326293945, Acc: 0.25\n",
      "Epoch: 92, Loss: 3.4884791374206543, Acc: 0.28125\n",
      "Epoch: 93, Loss: 3.851616859436035, Acc: 0.15625\n",
      "Epoch: 94, Loss: 3.427849531173706, Acc: 0.3125\n",
      "Epoch: 95, Loss: 3.4301483631134033, Acc: 0.28125\n",
      "Epoch: 96, Loss: 3.4526758193969727, Acc: 0.25\n",
      "Epoch: 97, Loss: 3.2569375038146973, Acc: 0.21875\n",
      "Epoch: 98, Loss: 3.691802740097046, Acc: 0.0625\n",
      "Epoch: 99, Loss: 3.5104639530181885, Acc: 0.375\n",
      "Epoch: 100, Loss: 3.6329410076141357, Acc: 0.21875\n",
      "Epoch: 101, Loss: 3.5520639419555664, Acc: 0.25\n",
      "Epoch: 102, Loss: 3.551241636276245, Acc: 0.125\n",
      "Epoch: 103, Loss: 3.386321783065796, Acc: 0.34375\n",
      "Epoch: 104, Loss: 3.62622332572937, Acc: 0.125\n",
      "Epoch: 105, Loss: 3.789884328842163, Acc: 0.15625\n",
      "Epoch: 106, Loss: 3.4104220867156982, Acc: 0.3125\n",
      "Epoch: 107, Loss: 3.333106279373169, Acc: 0.25\n",
      "Epoch: 108, Loss: 3.0723683834075928, Acc: 0.3125\n",
      "Epoch: 109, Loss: 3.599947214126587, Acc: 0.21875\n",
      "Epoch: 110, Loss: 3.397702693939209, Acc: 0.21875\n",
      "Epoch: 111, Loss: 2.994722604751587, Acc: 0.3125\n",
      "Epoch: 112, Loss: 3.6198434829711914, Acc: 0.1875\n",
      "Epoch: 113, Loss: 3.4631009101867676, Acc: 0.3125\n",
      "Epoch: 114, Loss: 3.07326078414917, Acc: 0.34375\n",
      "Epoch: 115, Loss: 3.0143837928771973, Acc: 0.28125\n",
      "Epoch: 116, Loss: 3.0010769367218018, Acc: 0.3125\n",
      "Epoch: 117, Loss: 3.1157281398773193, Acc: 0.34375\n",
      "Epoch: 118, Loss: 3.143080472946167, Acc: 0.28125\n",
      "Epoch: 119, Loss: 3.239722728729248, Acc: 0.21875\n",
      "Epoch: 120, Loss: 3.59486985206604, Acc: 0.1875\n",
      "Epoch: 121, Loss: 3.1066274642944336, Acc: 0.34375\n",
      "Epoch: 122, Loss: 2.747574806213379, Acc: 0.34375\n",
      "Epoch: 123, Loss: 3.1201133728027344, Acc: 0.34375\n",
      "Epoch: 124, Loss: 3.4350697994232178, Acc: 0.21875\n",
      "Epoch: 125, Loss: 3.332001209259033, Acc: 0.1875\n",
      "Epoch: 126, Loss: 2.9852094650268555, Acc: 0.28125\n",
      "Epoch: 127, Loss: 3.1244871616363525, Acc: 0.25\n",
      "Epoch: 128, Loss: 3.181936025619507, Acc: 0.28125\n",
      "Epoch: 129, Loss: 2.9877190589904785, Acc: 0.25\n",
      "Epoch: 130, Loss: 2.8030757904052734, Acc: 0.34375\n",
      "Epoch: 131, Loss: 3.168295383453369, Acc: 0.3125\n",
      "Epoch: 132, Loss: 2.8540709018707275, Acc: 0.34375\n",
      "Epoch: 133, Loss: 3.2714669704437256, Acc: 0.25\n",
      "Epoch: 134, Loss: 3.414628505706787, Acc: 0.1875\n",
      "Epoch: 135, Loss: 3.027808666229248, Acc: 0.1875\n",
      "Epoch: 136, Loss: 2.5490663051605225, Acc: 0.40625\n",
      "Epoch: 137, Loss: 3.2050621509552, Acc: 0.1875\n",
      "Epoch: 138, Loss: 2.825319528579712, Acc: 0.375\n",
      "Epoch: 139, Loss: 2.640519857406616, Acc: 0.34375\n",
      "Epoch: 140, Loss: 2.731823444366455, Acc: 0.34375\n",
      "Epoch: 141, Loss: 2.8477895259857178, Acc: 0.34375\n",
      "Epoch: 142, Loss: 3.2842917442321777, Acc: 0.15625\n",
      "Epoch: 143, Loss: 2.6474556922912598, Acc: 0.46875\n",
      "Epoch: 144, Loss: 3.103921890258789, Acc: 0.3125\n",
      "Epoch: 145, Loss: 2.671379327774048, Acc: 0.3125\n",
      "Epoch: 146, Loss: 2.957852602005005, Acc: 0.28125\n",
      "Epoch: 147, Loss: 2.8020718097686768, Acc: 0.40625\n",
      "Epoch: 148, Loss: 2.8227388858795166, Acc: 0.21875\n",
      "Epoch: 149, Loss: 2.7102441787719727, Acc: 0.4375\n",
      "Epoch: 150, Loss: 2.5413942337036133, Acc: 0.375\n",
      "Epoch: 151, Loss: 3.1393234729766846, Acc: 0.34375\n",
      "Epoch: 152, Loss: 2.919301986694336, Acc: 0.3125\n",
      "Epoch: 153, Loss: 2.6056888103485107, Acc: 0.40625\n",
      "Epoch: 154, Loss: 2.563293218612671, Acc: 0.375\n",
      "Epoch: 155, Loss: 2.7137694358825684, Acc: 0.3125\n",
      "Epoch: 156, Loss: 2.7368247509002686, Acc: 0.375\n",
      "Epoch: 157, Loss: 2.632133960723877, Acc: 0.3125\n",
      "Epoch: 158, Loss: 2.8959269523620605, Acc: 0.3125\n",
      "Epoch: 159, Loss: 2.7188003063201904, Acc: 0.3125\n",
      "Epoch: 160, Loss: 2.5890135765075684, Acc: 0.3125\n",
      "Epoch: 161, Loss: 2.9813027381896973, Acc: 0.1875\n",
      "Epoch: 162, Loss: 2.9377145767211914, Acc: 0.1875\n",
      "Epoch: 163, Loss: 2.408043146133423, Acc: 0.40625\n",
      "Epoch: 164, Loss: 3.033210277557373, Acc: 0.34375\n",
      "Epoch: 165, Loss: 2.8051676750183105, Acc: 0.1875\n",
      "Epoch: 166, Loss: 2.5338985919952393, Acc: 0.375\n",
      "Epoch: 167, Loss: 2.531500816345215, Acc: 0.34375\n",
      "Epoch: 168, Loss: 2.5123789310455322, Acc: 0.3125\n",
      "Epoch: 169, Loss: 3.07900071144104, Acc: 0.28125\n",
      "Epoch: 170, Loss: 2.7546298503875732, Acc: 0.375\n",
      "Epoch: 171, Loss: 2.841851234436035, Acc: 0.34375\n",
      "Epoch: 172, Loss: 2.5474069118499756, Acc: 0.3125\n",
      "Epoch: 173, Loss: 3.3442752361297607, Acc: 0.3125\n",
      "Epoch: 174, Loss: 2.700873374938965, Acc: 0.28125\n",
      "Epoch: 175, Loss: 2.608311891555786, Acc: 0.375\n",
      "Epoch: 176, Loss: 2.861065149307251, Acc: 0.375\n",
      "Epoch: 177, Loss: 1.7460064888000488, Acc: 0.59375\n",
      "Epoch: 178, Loss: 2.411803722381592, Acc: 0.40625\n",
      "Epoch: 179, Loss: 2.1778337955474854, Acc: 0.5\n",
      "Epoch: 180, Loss: 2.641288995742798, Acc: 0.34375\n",
      "Epoch: 181, Loss: 2.841918706893921, Acc: 0.3125\n",
      "Epoch: 182, Loss: 2.51731538772583, Acc: 0.28125\n",
      "Epoch: 183, Loss: 2.050976514816284, Acc: 0.375\n",
      "Epoch: 184, Loss: 2.2333590984344482, Acc: 0.40625\n",
      "Epoch: 185, Loss: 2.6581780910491943, Acc: 0.375\n",
      "Epoch: 186, Loss: 2.752265214920044, Acc: 0.3125\n",
      "Epoch: 187, Loss: 2.065383195877075, Acc: 0.5\n",
      "Epoch: 188, Loss: 2.2741963863372803, Acc: 0.3125\n",
      "Epoch: 189, Loss: 3.1812427043914795, Acc: 0.15625\n",
      "Epoch: 190, Loss: 2.7360172271728516, Acc: 0.4375\n",
      "Epoch: 191, Loss: 2.8602945804595947, Acc: 0.28125\n",
      "Epoch: 192, Loss: 2.145801544189453, Acc: 0.46875\n",
      "Epoch: 193, Loss: 2.095043182373047, Acc: 0.46875\n",
      "Epoch: 194, Loss: 2.593500852584839, Acc: 0.34375\n",
      "Epoch: 195, Loss: 2.9712746143341064, Acc: 0.28125\n",
      "Epoch: 196, Loss: 2.6415998935699463, Acc: 0.3125\n",
      "Epoch: 197, Loss: 2.4529192447662354, Acc: 0.375\n",
      "Epoch: 198, Loss: 2.4292914867401123, Acc: 0.375\n",
      "Epoch: 199, Loss: 2.3222951889038086, Acc: 0.3125\n",
      "Epoch: 200, Loss: 2.1592977046966553, Acc: 0.53125\n",
      "Epoch: 201, Loss: 2.339334487915039, Acc: 0.4375\n",
      "Epoch: 202, Loss: 2.196734666824341, Acc: 0.46875\n",
      "Epoch: 203, Loss: 2.129857063293457, Acc: 0.375\n",
      "Epoch: 204, Loss: 2.290670871734619, Acc: 0.3125\n",
      "Epoch: 205, Loss: 2.113065004348755, Acc: 0.4375\n",
      "Epoch: 206, Loss: 2.267336845397949, Acc: 0.28125\n",
      "Epoch: 207, Loss: 2.7648539543151855, Acc: 0.375\n",
      "Epoch: 208, Loss: 2.442871570587158, Acc: 0.4375\n",
      "Epoch: 209, Loss: 2.4075121879577637, Acc: 0.3125\n",
      "Epoch: 210, Loss: 2.612734317779541, Acc: 0.46875\n",
      "Epoch: 211, Loss: 2.5423426628112793, Acc: 0.34375\n",
      "Epoch: 212, Loss: 2.5305447578430176, Acc: 0.3125\n",
      "Epoch: 213, Loss: 2.212233543395996, Acc: 0.4375\n",
      "Epoch: 214, Loss: 2.2237892150878906, Acc: 0.4375\n",
      "Epoch: 215, Loss: 2.690483331680298, Acc: 0.34375\n",
      "Epoch: 216, Loss: 2.354652166366577, Acc: 0.40625\n",
      "Epoch: 217, Loss: 2.192089796066284, Acc: 0.5\n",
      "Epoch: 218, Loss: 2.179128646850586, Acc: 0.375\n",
      "Epoch: 219, Loss: 2.3093996047973633, Acc: 0.46875\n",
      "Epoch: 220, Loss: 2.520669937133789, Acc: 0.34375\n",
      "Epoch: 221, Loss: 1.948287010192871, Acc: 0.40625\n",
      "Epoch: 222, Loss: 1.9123035669326782, Acc: 0.46875\n",
      "Epoch: 223, Loss: 2.3955776691436768, Acc: 0.40625\n",
      "Epoch: 224, Loss: 2.3666951656341553, Acc: 0.46875\n",
      "Epoch: 225, Loss: 2.0585851669311523, Acc: 0.46875\n",
      "Epoch: 226, Loss: 1.9381803274154663, Acc: 0.5\n",
      "Epoch: 227, Loss: 2.4126548767089844, Acc: 0.4375\n",
      "Epoch: 228, Loss: 1.9969360828399658, Acc: 0.40625\n",
      "Epoch: 229, Loss: 2.1353609561920166, Acc: 0.5\n",
      "Epoch: 230, Loss: 2.4237568378448486, Acc: 0.28125\n",
      "Epoch: 231, Loss: 2.378370761871338, Acc: 0.375\n",
      "Epoch: 232, Loss: 2.1476964950561523, Acc: 0.4375\n",
      "Epoch: 233, Loss: 2.183400869369507, Acc: 0.46875\n",
      "Epoch: 234, Loss: 1.9155300855636597, Acc: 0.46875\n",
      "Epoch: 235, Loss: 2.0560622215270996, Acc: 0.46875\n",
      "Epoch: 236, Loss: 2.679546356201172, Acc: 0.40625\n",
      "Epoch: 237, Loss: 2.7465436458587646, Acc: 0.34375\n",
      "Epoch: 238, Loss: 2.0864410400390625, Acc: 0.375\n",
      "Epoch: 239, Loss: 2.4886131286621094, Acc: 0.40625\n",
      "Epoch: 240, Loss: 2.0646421909332275, Acc: 0.46875\n",
      "Epoch: 241, Loss: 2.722522020339966, Acc: 0.21875\n",
      "Epoch: 242, Loss: 1.474657654762268, Acc: 0.625\n",
      "Epoch: 243, Loss: 2.3542797565460205, Acc: 0.40625\n",
      "Epoch: 244, Loss: 2.2364447116851807, Acc: 0.34375\n",
      "Epoch: 245, Loss: 2.1172292232513428, Acc: 0.40625\n",
      "Epoch: 246, Loss: 2.2612011432647705, Acc: 0.375\n",
      "Epoch: 247, Loss: 1.8882255554199219, Acc: 0.59375\n",
      "Epoch: 248, Loss: 2.6571128368377686, Acc: 0.3125\n",
      "Epoch: 249, Loss: 2.170691967010498, Acc: 0.5\n",
      "Epoch: 250, Loss: 1.9674029350280762, Acc: 0.5\n",
      "Epoch: 251, Loss: 1.9233192205429077, Acc: 0.46875\n",
      "Epoch: 252, Loss: 2.4072625637054443, Acc: 0.375\n",
      "Epoch: 253, Loss: 2.2824974060058594, Acc: 0.46875\n",
      "Epoch: 254, Loss: 2.467505693435669, Acc: 0.25\n",
      "Epoch: 255, Loss: 1.5982937812805176, Acc: 0.625\n",
      "Epoch: 256, Loss: 2.3013429641723633, Acc: 0.40625\n",
      "Epoch: 257, Loss: 2.380103826522827, Acc: 0.25\n",
      "Epoch: 258, Loss: 2.1295242309570312, Acc: 0.34375\n",
      "Epoch: 259, Loss: 1.8957346677780151, Acc: 0.4375\n",
      "Epoch: 260, Loss: 1.5788744688034058, Acc: 0.5625\n",
      "Epoch: 261, Loss: 1.840718150138855, Acc: 0.5625\n",
      "Epoch: 262, Loss: 1.900421380996704, Acc: 0.5\n",
      "Epoch: 263, Loss: 1.9825907945632935, Acc: 0.4375\n",
      "Epoch: 264, Loss: 2.221827983856201, Acc: 0.40625\n",
      "Epoch: 265, Loss: 2.5039470195770264, Acc: 0.28125\n",
      "Epoch: 266, Loss: 1.6616322994232178, Acc: 0.4375\n",
      "Epoch: 267, Loss: 2.186189651489258, Acc: 0.53125\n",
      "Epoch: 268, Loss: 2.3247110843658447, Acc: 0.375\n",
      "Epoch: 269, Loss: 2.253741502761841, Acc: 0.375\n",
      "Epoch: 270, Loss: 2.1653671264648438, Acc: 0.5\n",
      "Epoch: 271, Loss: 2.703521251678467, Acc: 0.3125\n",
      "Epoch: 272, Loss: 1.6275842189788818, Acc: 0.59375\n",
      "Epoch: 273, Loss: 2.5664138793945312, Acc: 0.34375\n",
      "Epoch: 274, Loss: 2.0593152046203613, Acc: 0.4375\n",
      "Epoch: 275, Loss: 2.6007425785064697, Acc: 0.25\n",
      "Epoch: 276, Loss: 2.306973934173584, Acc: 0.4375\n",
      "Epoch: 277, Loss: 2.520327091217041, Acc: 0.34375\n",
      "Epoch: 278, Loss: 1.894925832748413, Acc: 0.40625\n",
      "Epoch: 279, Loss: 1.8467044830322266, Acc: 0.53125\n",
      "Epoch: 280, Loss: 1.7819983959197998, Acc: 0.53125\n",
      "Epoch: 281, Loss: 1.9769749641418457, Acc: 0.375\n",
      "Epoch: 282, Loss: 1.692548394203186, Acc: 0.5\n",
      "Epoch: 283, Loss: 1.8987749814987183, Acc: 0.4375\n",
      "Epoch: 284, Loss: 1.817030906677246, Acc: 0.46875\n",
      "Epoch: 285, Loss: 1.8174251317977905, Acc: 0.40625\n",
      "Epoch: 286, Loss: 1.865377426147461, Acc: 0.5625\n",
      "Epoch: 287, Loss: 1.8696398735046387, Acc: 0.5625\n",
      "Epoch: 288, Loss: 2.1935946941375732, Acc: 0.3125\n",
      "Epoch: 289, Loss: 1.7638040781021118, Acc: 0.5\n",
      "Epoch: 290, Loss: 1.609207034111023, Acc: 0.59375\n",
      "Epoch: 291, Loss: 2.192655086517334, Acc: 0.40625\n",
      "Epoch: 292, Loss: 1.696408748626709, Acc: 0.5625\n",
      "Epoch: 293, Loss: 2.204732894897461, Acc: 0.3125\n",
      "Epoch: 294, Loss: 2.0499143600463867, Acc: 0.5\n",
      "Epoch: 295, Loss: 2.030029773712158, Acc: 0.46875\n",
      "Epoch: 296, Loss: 2.0138278007507324, Acc: 0.5\n",
      "Epoch: 297, Loss: 1.6120973825454712, Acc: 0.53125\n",
      "Epoch: 298, Loss: 2.0871949195861816, Acc: 0.375\n",
      "Epoch: 299, Loss: 2.2057342529296875, Acc: 0.375\n",
      "Epoch: 300, Loss: 1.9185400009155273, Acc: 0.5\n",
      "Epoch: 301, Loss: 2.025198221206665, Acc: 0.4375\n",
      "Epoch: 302, Loss: 1.9329169988632202, Acc: 0.5\n",
      "Epoch: 303, Loss: 1.6641618013381958, Acc: 0.5\n",
      "Epoch: 304, Loss: 1.9887702465057373, Acc: 0.4375\n",
      "Epoch: 305, Loss: 2.0148534774780273, Acc: 0.4375\n",
      "Epoch: 306, Loss: 1.802323341369629, Acc: 0.4375\n",
      "Epoch: 307, Loss: 1.88890540599823, Acc: 0.46875\n",
      "Epoch: 308, Loss: 1.5260738134384155, Acc: 0.5625\n",
      "Epoch: 309, Loss: 1.9050135612487793, Acc: 0.46875\n",
      "Epoch: 310, Loss: 1.4255167245864868, Acc: 0.6875\n",
      "Epoch: 311, Loss: 1.9576168060302734, Acc: 0.40625\n",
      "Epoch: 312, Loss: 2.059476852416992, Acc: 0.46875\n",
      "Epoch: 313, Loss: 1.624711513519287, Acc: 0.46875\n",
      "Epoch: 314, Loss: 2.1903297901153564, Acc: 0.46875\n",
      "Epoch: 315, Loss: 2.0632572174072266, Acc: 0.4375\n",
      "Epoch: 316, Loss: 1.9578665494918823, Acc: 0.46875\n",
      "Epoch: 317, Loss: 2.0601580142974854, Acc: 0.46875\n",
      "Epoch: 318, Loss: 1.8456764221191406, Acc: 0.46875\n",
      "Epoch: 319, Loss: 1.9664621353149414, Acc: 0.5\n",
      "Epoch: 320, Loss: 1.5386451482772827, Acc: 0.59375\n",
      "Epoch: 321, Loss: 1.744053840637207, Acc: 0.46875\n",
      "Epoch: 322, Loss: 1.4718859195709229, Acc: 0.59375\n",
      "Epoch: 323, Loss: 1.8568648099899292, Acc: 0.5\n",
      "Epoch: 324, Loss: 1.8644295930862427, Acc: 0.53125\n",
      "Epoch: 325, Loss: 1.663150668144226, Acc: 0.5625\n",
      "Epoch: 326, Loss: 2.263603687286377, Acc: 0.40625\n",
      "Epoch: 327, Loss: 1.6973079442977905, Acc: 0.5625\n",
      "Epoch: 328, Loss: 1.7687748670578003, Acc: 0.53125\n",
      "Epoch: 329, Loss: 1.39695143699646, Acc: 0.625\n",
      "Epoch: 330, Loss: 1.4953665733337402, Acc: 0.625\n",
      "Epoch: 331, Loss: 1.5329444408416748, Acc: 0.59375\n",
      "Epoch: 332, Loss: 2.098574638366699, Acc: 0.4375\n",
      "Epoch: 333, Loss: 2.0089364051818848, Acc: 0.34375\n",
      "Epoch: 334, Loss: 2.234889507293701, Acc: 0.46875\n",
      "Epoch: 335, Loss: 1.8893215656280518, Acc: 0.53125\n",
      "Epoch: 336, Loss: 1.828532338142395, Acc: 0.5\n",
      "Epoch: 337, Loss: 1.9098594188690186, Acc: 0.46875\n",
      "Epoch: 338, Loss: 1.605557918548584, Acc: 0.5625\n",
      "Epoch: 339, Loss: 1.3869025707244873, Acc: 0.59375\n",
      "Epoch: 340, Loss: 1.6410441398620605, Acc: 0.5625\n",
      "Epoch: 341, Loss: 1.9507085084915161, Acc: 0.4375\n",
      "Epoch: 342, Loss: 1.5908424854278564, Acc: 0.53125\n",
      "Epoch: 343, Loss: 1.8008108139038086, Acc: 0.46875\n",
      "Epoch: 344, Loss: 1.6536387205123901, Acc: 0.53125\n",
      "Epoch: 345, Loss: 1.8757784366607666, Acc: 0.4375\n",
      "Epoch: 346, Loss: 1.741625189781189, Acc: 0.53125\n",
      "Epoch: 347, Loss: 1.7260494232177734, Acc: 0.5625\n",
      "Epoch: 348, Loss: 2.5360543727874756, Acc: 0.3125\n",
      "Epoch: 349, Loss: 1.751085638999939, Acc: 0.5\n",
      "Epoch: 350, Loss: 1.6495801210403442, Acc: 0.53125\n",
      "Epoch: 351, Loss: 1.8182097673416138, Acc: 0.53125\n",
      "Epoch: 352, Loss: 1.4268202781677246, Acc: 0.75\n",
      "Epoch: 353, Loss: 1.6264761686325073, Acc: 0.53125\n",
      "Epoch: 354, Loss: 2.1204679012298584, Acc: 0.46875\n",
      "Epoch: 355, Loss: 2.094906806945801, Acc: 0.375\n",
      "Epoch: 356, Loss: 1.9670066833496094, Acc: 0.46875\n",
      "Epoch: 357, Loss: 1.5765455961227417, Acc: 0.5\n",
      "Epoch: 358, Loss: 1.7352912425994873, Acc: 0.5\n",
      "Epoch: 359, Loss: 1.9158366918563843, Acc: 0.46875\n",
      "Epoch: 360, Loss: 1.8127624988555908, Acc: 0.4375\n",
      "Epoch: 361, Loss: 1.86402428150177, Acc: 0.34375\n",
      "Epoch: 362, Loss: 2.019512176513672, Acc: 0.53125\n",
      "Epoch: 363, Loss: 1.2662304639816284, Acc: 0.65625\n",
      "Epoch: 364, Loss: 2.1064839363098145, Acc: 0.40625\n",
      "Epoch: 365, Loss: 2.0905308723449707, Acc: 0.5\n",
      "Epoch: 366, Loss: 1.4193223714828491, Acc: 0.46875\n",
      "Epoch: 367, Loss: 1.8486651182174683, Acc: 0.46875\n",
      "Epoch: 368, Loss: 1.5477255582809448, Acc: 0.625\n",
      "Epoch: 369, Loss: 1.6519054174423218, Acc: 0.5\n",
      "Epoch: 370, Loss: 2.0609631538391113, Acc: 0.40625\n",
      "Epoch: 371, Loss: 1.7071951627731323, Acc: 0.59375\n",
      "Epoch: 372, Loss: 1.6001842021942139, Acc: 0.5625\n",
      "Epoch: 373, Loss: 1.8330767154693604, Acc: 0.5\n",
      "Epoch: 374, Loss: 2.3082165718078613, Acc: 0.34375\n",
      "Epoch: 375, Loss: 1.3563975095748901, Acc: 0.59375\n",
      "Epoch: 376, Loss: 1.5105180740356445, Acc: 0.53125\n",
      "Epoch: 377, Loss: 1.8509470224380493, Acc: 0.5\n",
      "Epoch: 378, Loss: 1.4597325325012207, Acc: 0.5625\n",
      "Epoch: 379, Loss: 1.7608842849731445, Acc: 0.53125\n",
      "Epoch: 380, Loss: 1.5863503217697144, Acc: 0.5625\n",
      "Epoch: 381, Loss: 1.9722758531570435, Acc: 0.40625\n",
      "Epoch: 382, Loss: 1.7717067003250122, Acc: 0.4375\n",
      "Epoch: 383, Loss: 1.6779969930648804, Acc: 0.5\n",
      "Epoch: 384, Loss: 1.5838699340820312, Acc: 0.46875\n",
      "Epoch: 385, Loss: 1.7940313816070557, Acc: 0.53125\n",
      "Epoch: 386, Loss: 1.8192740678787231, Acc: 0.34375\n",
      "Epoch: 387, Loss: 1.7040854692459106, Acc: 0.4375\n",
      "Epoch: 388, Loss: 1.8723794221878052, Acc: 0.46875\n",
      "Epoch: 389, Loss: 1.5695114135742188, Acc: 0.59375\n",
      "Epoch: 390, Loss: 1.9244985580444336, Acc: 0.40625\n",
      "Epoch: 391, Loss: 1.7163118124008179, Acc: 0.5625\n",
      "Epoch: 392, Loss: 1.3001915216445923, Acc: 0.59375\n",
      "Epoch: 393, Loss: 1.3119362592697144, Acc: 0.65625\n",
      "Epoch: 394, Loss: 1.3945763111114502, Acc: 0.53125\n",
      "Epoch: 395, Loss: 1.7127524614334106, Acc: 0.5\n",
      "Epoch: 396, Loss: 1.495663046836853, Acc: 0.53125\n",
      "Epoch: 397, Loss: 1.9120252132415771, Acc: 0.53125\n",
      "Epoch: 398, Loss: 1.7747771739959717, Acc: 0.46875\n",
      "Epoch: 399, Loss: 1.3889660835266113, Acc: 0.59375\n",
      "Epoch: 400, Loss: 1.7979543209075928, Acc: 0.25\n",
      "Epoch: 401, Loss: 1.2825802564620972, Acc: 0.625\n",
      "Epoch: 402, Loss: 1.4101752042770386, Acc: 0.5\n",
      "Epoch: 403, Loss: 1.4482251405715942, Acc: 0.5625\n",
      "Epoch: 404, Loss: 1.55098557472229, Acc: 0.5\n",
      "Epoch: 405, Loss: 1.69886314868927, Acc: 0.46875\n",
      "Epoch: 406, Loss: 1.5498346090316772, Acc: 0.59375\n",
      "Epoch: 407, Loss: 1.5593414306640625, Acc: 0.59375\n",
      "Epoch: 408, Loss: 1.3230006694793701, Acc: 0.5625\n",
      "Epoch: 409, Loss: 1.626536250114441, Acc: 0.59375\n",
      "Epoch: 410, Loss: 1.6189818382263184, Acc: 0.4375\n",
      "Epoch: 411, Loss: 1.2904731035232544, Acc: 0.71875\n",
      "Epoch: 412, Loss: 1.2179323434829712, Acc: 0.625\n",
      "Epoch: 413, Loss: 1.6200321912765503, Acc: 0.53125\n",
      "Epoch: 414, Loss: 1.1604530811309814, Acc: 0.65625\n",
      "Epoch: 415, Loss: 1.6388458013534546, Acc: 0.59375\n",
      "Epoch: 416, Loss: 1.2477140426635742, Acc: 0.625\n",
      "Epoch: 417, Loss: 1.488468050956726, Acc: 0.5\n",
      "Epoch: 418, Loss: 1.7229045629501343, Acc: 0.4375\n",
      "Epoch: 419, Loss: 1.4897104501724243, Acc: 0.53125\n",
      "Epoch: 420, Loss: 1.7950905561447144, Acc: 0.40625\n",
      "Epoch: 421, Loss: 1.6597827672958374, Acc: 0.40625\n",
      "Epoch: 422, Loss: 1.7957978248596191, Acc: 0.53125\n",
      "Epoch: 423, Loss: 1.1401525735855103, Acc: 0.65625\n",
      "Epoch: 424, Loss: 1.4834480285644531, Acc: 0.5625\n",
      "Epoch: 425, Loss: 1.96675443649292, Acc: 0.375\n",
      "Epoch: 426, Loss: 1.4486380815505981, Acc: 0.625\n",
      "Epoch: 427, Loss: 1.6598607301712036, Acc: 0.5\n",
      "Epoch: 428, Loss: 1.9224028587341309, Acc: 0.375\n",
      "Epoch: 429, Loss: 1.3367291688919067, Acc: 0.5625\n",
      "Epoch: 430, Loss: 1.61521577835083, Acc: 0.46875\n",
      "Epoch: 431, Loss: 1.1936296224594116, Acc: 0.6875\n",
      "Epoch: 432, Loss: 1.632995843887329, Acc: 0.625\n",
      "Epoch: 433, Loss: 1.262913703918457, Acc: 0.6875\n",
      "Epoch: 434, Loss: 1.811811089515686, Acc: 0.4375\n",
      "Epoch: 435, Loss: 1.221455693244934, Acc: 0.53125\n",
      "Epoch: 436, Loss: 1.7914466857910156, Acc: 0.40625\n",
      "Epoch: 437, Loss: 1.6608810424804688, Acc: 0.53125\n",
      "Epoch: 438, Loss: 1.647878885269165, Acc: 0.5\n",
      "Epoch: 439, Loss: 1.9480764865875244, Acc: 0.40625\n",
      "Epoch: 440, Loss: 1.6727986335754395, Acc: 0.4375\n",
      "Epoch: 441, Loss: 1.3086625337600708, Acc: 0.6875\n",
      "Epoch: 442, Loss: 1.8929821252822876, Acc: 0.4375\n",
      "Epoch: 443, Loss: 1.9285826683044434, Acc: 0.3125\n",
      "Epoch: 444, Loss: 1.588323712348938, Acc: 0.5625\n",
      "Epoch: 445, Loss: 1.4382305145263672, Acc: 0.53125\n",
      "Epoch: 446, Loss: 1.607258677482605, Acc: 0.65625\n",
      "Epoch: 447, Loss: 1.2503284215927124, Acc: 0.625\n",
      "Epoch: 448, Loss: 1.629941701889038, Acc: 0.4375\n",
      "Epoch: 449, Loss: 1.3402557373046875, Acc: 0.5625\n",
      "Epoch: 450, Loss: 1.4739375114440918, Acc: 0.5625\n",
      "Epoch: 451, Loss: 1.4129717350006104, Acc: 0.5625\n",
      "Epoch: 452, Loss: 1.3339306116104126, Acc: 0.59375\n",
      "Epoch: 453, Loss: 1.2942312955856323, Acc: 0.65625\n",
      "Epoch: 454, Loss: 1.3981012105941772, Acc: 0.625\n",
      "Epoch: 455, Loss: 1.6470081806182861, Acc: 0.59375\n",
      "Epoch: 456, Loss: 1.3325098752975464, Acc: 0.53125\n",
      "Epoch: 457, Loss: 1.2368930578231812, Acc: 0.5625\n",
      "Epoch: 458, Loss: 1.4403411149978638, Acc: 0.5625\n",
      "Epoch: 459, Loss: 1.249489665031433, Acc: 0.5625\n",
      "Epoch: 460, Loss: 1.2941499948501587, Acc: 0.71875\n",
      "Epoch: 461, Loss: 1.980117917060852, Acc: 0.5\n",
      "Epoch: 462, Loss: 1.6893742084503174, Acc: 0.4375\n",
      "Epoch: 463, Loss: 1.4845044612884521, Acc: 0.53125\n",
      "Epoch: 464, Loss: 1.7452267408370972, Acc: 0.4375\n",
      "Epoch: 465, Loss: 1.2782455682754517, Acc: 0.59375\n",
      "Epoch: 466, Loss: 1.6157419681549072, Acc: 0.53125\n",
      "Epoch: 467, Loss: 1.152527093887329, Acc: 0.6875\n",
      "Epoch: 468, Loss: 1.265580415725708, Acc: 0.625\n",
      "Epoch: 469, Loss: 1.6587599515914917, Acc: 0.5625\n",
      "Epoch: 470, Loss: 1.515246033668518, Acc: 0.53125\n",
      "Epoch: 471, Loss: 1.7744920253753662, Acc: 0.40625\n",
      "Epoch: 472, Loss: 1.6616265773773193, Acc: 0.53125\n",
      "Epoch: 473, Loss: 1.6874687671661377, Acc: 0.53125\n",
      "Epoch: 474, Loss: 1.2713572978973389, Acc: 0.5625\n",
      "Epoch: 475, Loss: 1.0761520862579346, Acc: 0.71875\n",
      "Epoch: 476, Loss: 1.4355456829071045, Acc: 0.59375\n",
      "Epoch: 477, Loss: 1.212479829788208, Acc: 0.59375\n",
      "Epoch: 478, Loss: 1.833594560623169, Acc: 0.46875\n",
      "Epoch: 479, Loss: 1.5165032148361206, Acc: 0.46875\n",
      "Epoch: 480, Loss: 1.7134464979171753, Acc: 0.53125\n",
      "Epoch: 481, Loss: 1.466924786567688, Acc: 0.53125\n",
      "Epoch: 482, Loss: 1.735790491104126, Acc: 0.46875\n",
      "Epoch: 483, Loss: 1.4997309446334839, Acc: 0.59375\n",
      "Epoch: 484, Loss: 1.242587924003601, Acc: 0.59375\n",
      "Epoch: 485, Loss: 1.1790738105773926, Acc: 0.6875\n",
      "Epoch: 486, Loss: 1.4472302198410034, Acc: 0.53125\n",
      "Epoch: 487, Loss: 1.3710428476333618, Acc: 0.65625\n",
      "Epoch: 488, Loss: 1.4711906909942627, Acc: 0.59375\n",
      "Epoch: 489, Loss: 1.2887883186340332, Acc: 0.59375\n",
      "Epoch: 490, Loss: 1.2778767347335815, Acc: 0.5625\n",
      "Epoch: 491, Loss: 1.8894195556640625, Acc: 0.53125\n",
      "Epoch: 492, Loss: 1.6563565731048584, Acc: 0.59375\n",
      "Epoch: 493, Loss: 1.125740885734558, Acc: 0.71875\n",
      "Epoch: 494, Loss: 1.6317402124404907, Acc: 0.4375\n",
      "Epoch: 495, Loss: 1.5618844032287598, Acc: 0.5625\n",
      "Epoch: 496, Loss: 1.5297435522079468, Acc: 0.65625\n",
      "Epoch: 497, Loss: 1.8185921907424927, Acc: 0.46875\n",
      "Epoch: 498, Loss: 1.629522442817688, Acc: 0.59375\n",
      "Epoch: 499, Loss: 1.3129929304122925, Acc: 0.5625\n",
      "Epoch: 500, Loss: 1.3737424612045288, Acc: 0.5625\n",
      "Epoch: 501, Loss: 1.1778383255004883, Acc: 0.71875\n",
      "Epoch: 502, Loss: 1.517713189125061, Acc: 0.59375\n",
      "Epoch: 503, Loss: 1.1105440855026245, Acc: 0.75\n",
      "Epoch: 504, Loss: 1.6747713088989258, Acc: 0.53125\n",
      "Epoch: 505, Loss: 1.2202510833740234, Acc: 0.5625\n",
      "Epoch: 506, Loss: 1.2445344924926758, Acc: 0.625\n",
      "Epoch: 507, Loss: 1.8241820335388184, Acc: 0.5\n",
      "Epoch: 508, Loss: 1.2798160314559937, Acc: 0.625\n",
      "Epoch: 509, Loss: 1.3751710653305054, Acc: 0.53125\n",
      "Epoch: 510, Loss: 1.3078263998031616, Acc: 0.65625\n",
      "Epoch: 511, Loss: 1.6627302169799805, Acc: 0.4375\n",
      "Epoch: 512, Loss: 1.204208254814148, Acc: 0.59375\n",
      "Epoch: 513, Loss: 1.2153081893920898, Acc: 0.625\n",
      "Epoch: 514, Loss: 1.5094420909881592, Acc: 0.5625\n",
      "Epoch: 515, Loss: 1.1682517528533936, Acc: 0.65625\n",
      "Epoch: 516, Loss: 1.1511664390563965, Acc: 0.6875\n",
      "Epoch: 517, Loss: 0.7571612596511841, Acc: 0.75\n",
      "Epoch: 518, Loss: 0.9760887622833252, Acc: 0.59375\n",
      "Epoch: 519, Loss: 1.0986204147338867, Acc: 0.71875\n",
      "Epoch: 520, Loss: 1.6489975452423096, Acc: 0.59375\n",
      "Epoch: 521, Loss: 1.320723295211792, Acc: 0.5625\n",
      "Epoch: 522, Loss: 1.4257022142410278, Acc: 0.53125\n",
      "Epoch: 523, Loss: 1.7406259775161743, Acc: 0.46875\n",
      "Epoch: 524, Loss: 1.6852405071258545, Acc: 0.53125\n",
      "Epoch: 525, Loss: 1.2746493816375732, Acc: 0.65625\n",
      "Epoch: 526, Loss: 1.3123213052749634, Acc: 0.625\n",
      "Epoch: 527, Loss: 1.684643268585205, Acc: 0.5\n",
      "Epoch: 528, Loss: 1.3293652534484863, Acc: 0.65625\n",
      "Epoch: 529, Loss: 1.11714768409729, Acc: 0.6875\n",
      "Epoch: 530, Loss: 0.9512676000595093, Acc: 0.65625\n",
      "Epoch: 531, Loss: 1.3044713735580444, Acc: 0.59375\n",
      "Epoch: 532, Loss: 1.3617355823516846, Acc: 0.5625\n",
      "Epoch: 533, Loss: 1.2789382934570312, Acc: 0.65625\n",
      "Epoch: 534, Loss: 1.2840147018432617, Acc: 0.625\n",
      "Epoch: 535, Loss: 1.3355309963226318, Acc: 0.625\n",
      "Epoch: 536, Loss: 1.4832998514175415, Acc: 0.5\n",
      "Epoch: 537, Loss: 1.5212959051132202, Acc: 0.5625\n",
      "Epoch: 538, Loss: 1.5314186811447144, Acc: 0.46875\n",
      "Epoch: 539, Loss: 1.6872749328613281, Acc: 0.40625\n",
      "Epoch: 540, Loss: 1.6299997568130493, Acc: 0.5625\n",
      "Epoch: 541, Loss: 1.3532665967941284, Acc: 0.59375\n",
      "Epoch: 542, Loss: 1.6007720232009888, Acc: 0.53125\n",
      "Epoch: 543, Loss: 1.1787681579589844, Acc: 0.65625\n",
      "Epoch: 544, Loss: 0.9487957954406738, Acc: 0.75\n",
      "Epoch: 545, Loss: 1.3613098859786987, Acc: 0.53125\n",
      "Epoch: 546, Loss: 1.1276280879974365, Acc: 0.625\n",
      "Epoch: 547, Loss: 1.8360844850540161, Acc: 0.53125\n",
      "Epoch: 548, Loss: 1.2205839157104492, Acc: 0.59375\n",
      "Epoch: 549, Loss: 1.2293813228607178, Acc: 0.5625\n",
      "Epoch: 550, Loss: 1.7248899936676025, Acc: 0.46875\n",
      "Epoch: 551, Loss: 1.1886959075927734, Acc: 0.65625\n",
      "Epoch: 552, Loss: 1.5368261337280273, Acc: 0.53125\n",
      "Epoch: 553, Loss: 1.5367038249969482, Acc: 0.4375\n",
      "Epoch: 554, Loss: 1.445404052734375, Acc: 0.5\n",
      "Epoch: 555, Loss: 1.7132012844085693, Acc: 0.53125\n",
      "Epoch: 556, Loss: 1.6884897947311401, Acc: 0.5\n",
      "Epoch: 557, Loss: 1.442565679550171, Acc: 0.59375\n",
      "Epoch: 558, Loss: 1.2413045167922974, Acc: 0.59375\n",
      "Epoch: 559, Loss: 1.0638763904571533, Acc: 0.71875\n",
      "Epoch: 560, Loss: 1.3558217287063599, Acc: 0.5625\n",
      "Epoch: 561, Loss: 1.315552830696106, Acc: 0.65625\n",
      "Epoch: 562, Loss: 1.4346973896026611, Acc: 0.5625\n",
      "Epoch: 563, Loss: 1.5036617517471313, Acc: 0.4375\n",
      "Epoch: 564, Loss: 1.4572267532348633, Acc: 0.59375\n",
      "Epoch: 565, Loss: 1.5614778995513916, Acc: 0.5\n",
      "Epoch: 566, Loss: 1.204879879951477, Acc: 0.59375\n",
      "Epoch: 567, Loss: 1.2367849349975586, Acc: 0.5\n",
      "Epoch: 568, Loss: 1.342011570930481, Acc: 0.6875\n",
      "Epoch: 569, Loss: 1.296864628791809, Acc: 0.4375\n",
      "Epoch: 570, Loss: 1.3575552701950073, Acc: 0.59375\n",
      "Epoch: 571, Loss: 1.6073579788208008, Acc: 0.40625\n",
      "Epoch: 572, Loss: 2.039245128631592, Acc: 0.4375\n",
      "Epoch: 573, Loss: 0.8678207993507385, Acc: 0.78125\n",
      "Epoch: 574, Loss: 0.9354722499847412, Acc: 0.75\n",
      "Epoch: 575, Loss: 1.5096971988677979, Acc: 0.53125\n",
      "Epoch: 576, Loss: 1.7829375267028809, Acc: 0.53125\n",
      "Epoch: 577, Loss: 1.4926798343658447, Acc: 0.53125\n",
      "Epoch: 578, Loss: 1.243963360786438, Acc: 0.59375\n",
      "Epoch: 579, Loss: 1.6157703399658203, Acc: 0.5\n",
      "Epoch: 580, Loss: 1.29954993724823, Acc: 0.6875\n",
      "Epoch: 581, Loss: 1.0829973220825195, Acc: 0.59375\n",
      "Epoch: 582, Loss: 1.1751086711883545, Acc: 0.65625\n",
      "Epoch: 583, Loss: 1.1731950044631958, Acc: 0.625\n",
      "Epoch: 584, Loss: 1.0547528266906738, Acc: 0.65625\n",
      "Epoch: 585, Loss: 1.3960890769958496, Acc: 0.5\n",
      "Epoch: 586, Loss: 1.1397773027420044, Acc: 0.5\n",
      "Epoch: 587, Loss: 1.3387165069580078, Acc: 0.6875\n",
      "Epoch: 588, Loss: 1.2880067825317383, Acc: 0.59375\n",
      "Epoch: 589, Loss: 1.2994683980941772, Acc: 0.71875\n",
      "Epoch: 590, Loss: 1.6848200559616089, Acc: 0.59375\n",
      "Epoch: 591, Loss: 1.558626413345337, Acc: 0.53125\n",
      "Epoch: 592, Loss: 1.7245036363601685, Acc: 0.5\n",
      "Epoch: 593, Loss: 1.0137795209884644, Acc: 0.71875\n",
      "Epoch: 594, Loss: 1.240737795829773, Acc: 0.59375\n",
      "Epoch: 595, Loss: 1.0993516445159912, Acc: 0.65625\n",
      "Epoch: 596, Loss: 1.4443347454071045, Acc: 0.46875\n",
      "Epoch: 597, Loss: 1.384413719177246, Acc: 0.5625\n",
      "Epoch: 598, Loss: 1.1501644849777222, Acc: 0.59375\n",
      "Epoch: 599, Loss: 1.5626124143600464, Acc: 0.625\n",
      "Epoch: 600, Loss: 1.2291890382766724, Acc: 0.625\n",
      "Epoch: 601, Loss: 1.2340874671936035, Acc: 0.625\n",
      "Epoch: 602, Loss: 1.2505593299865723, Acc: 0.625\n",
      "Epoch: 603, Loss: 1.5261300802230835, Acc: 0.5\n",
      "Epoch: 604, Loss: 1.143201470375061, Acc: 0.71875\n",
      "Epoch: 605, Loss: 1.2757683992385864, Acc: 0.625\n",
      "Epoch: 606, Loss: 1.2391057014465332, Acc: 0.59375\n",
      "Epoch: 607, Loss: 1.2452712059020996, Acc: 0.59375\n",
      "Epoch: 608, Loss: 1.2735620737075806, Acc: 0.59375\n",
      "Epoch: 609, Loss: 1.7719874382019043, Acc: 0.4375\n",
      "Epoch: 610, Loss: 1.278648018836975, Acc: 0.625\n",
      "Epoch: 611, Loss: 0.97127366065979, Acc: 0.65625\n",
      "Epoch: 612, Loss: 1.6295406818389893, Acc: 0.46875\n",
      "Epoch: 613, Loss: 1.0431573390960693, Acc: 0.65625\n",
      "Epoch: 614, Loss: 1.5828864574432373, Acc: 0.40625\n",
      "Epoch: 615, Loss: 1.4717525243759155, Acc: 0.625\n",
      "Epoch: 616, Loss: 1.6792147159576416, Acc: 0.5625\n",
      "Epoch: 617, Loss: 1.5786789655685425, Acc: 0.46875\n",
      "Epoch: 618, Loss: 1.1833593845367432, Acc: 0.625\n",
      "Epoch: 619, Loss: 1.6735340356826782, Acc: 0.5\n",
      "Epoch: 620, Loss: 1.7254832983016968, Acc: 0.53125\n",
      "Epoch: 621, Loss: 1.1156160831451416, Acc: 0.625\n",
      "Epoch: 622, Loss: 0.891014814376831, Acc: 0.71875\n",
      "Epoch: 623, Loss: 1.3810948133468628, Acc: 0.40625\n",
      "Epoch: 624, Loss: 1.3818567991256714, Acc: 0.625\n",
      "Epoch: 625, Loss: 1.311179518699646, Acc: 0.59375\n",
      "Epoch: 626, Loss: 1.222296953201294, Acc: 0.625\n",
      "Epoch: 627, Loss: 1.3286516666412354, Acc: 0.5\n",
      "Epoch: 628, Loss: 1.2785300016403198, Acc: 0.625\n",
      "Epoch: 629, Loss: 1.2514852285385132, Acc: 0.59375\n",
      "Epoch: 630, Loss: 1.2259001731872559, Acc: 0.65625\n",
      "Epoch: 631, Loss: 1.5448099374771118, Acc: 0.5625\n",
      "Epoch: 632, Loss: 1.2862483263015747, Acc: 0.46875\n",
      "Epoch: 633, Loss: 0.9722082614898682, Acc: 0.6875\n",
      "Epoch: 634, Loss: 1.2181694507598877, Acc: 0.65625\n",
      "Epoch: 635, Loss: 1.3883042335510254, Acc: 0.625\n",
      "Epoch: 636, Loss: 1.1305445432662964, Acc: 0.65625\n",
      "Epoch: 637, Loss: 1.1638188362121582, Acc: 0.71875\n",
      "Epoch: 638, Loss: 1.7687480449676514, Acc: 0.4375\n",
      "Epoch: 639, Loss: 1.5031647682189941, Acc: 0.5\n",
      "Epoch: 640, Loss: 1.4396488666534424, Acc: 0.46875\n",
      "Epoch: 641, Loss: 1.6134322881698608, Acc: 0.4375\n",
      "Epoch: 642, Loss: 1.5608669519424438, Acc: 0.46875\n",
      "Epoch: 643, Loss: 1.0908782482147217, Acc: 0.71875\n",
      "Epoch: 644, Loss: 1.7156647443771362, Acc: 0.46875\n",
      "Epoch: 645, Loss: 1.35256028175354, Acc: 0.53125\n",
      "Epoch: 646, Loss: 1.2492035627365112, Acc: 0.5625\n",
      "Epoch: 647, Loss: 1.743861436843872, Acc: 0.28125\n",
      "Epoch: 648, Loss: 1.3159080743789673, Acc: 0.5625\n",
      "Epoch: 649, Loss: 1.2490782737731934, Acc: 0.59375\n",
      "Epoch: 650, Loss: 1.0512313842773438, Acc: 0.6875\n",
      "Epoch: 651, Loss: 1.1589053869247437, Acc: 0.5625\n",
      "Epoch: 652, Loss: 1.3229217529296875, Acc: 0.59375\n",
      "Epoch: 653, Loss: 1.012292742729187, Acc: 0.625\n",
      "Epoch: 654, Loss: 1.2352697849273682, Acc: 0.59375\n",
      "Epoch: 655, Loss: 1.1124855279922485, Acc: 0.65625\n",
      "Epoch: 656, Loss: 1.2616689205169678, Acc: 0.65625\n",
      "Epoch: 657, Loss: 0.9047118425369263, Acc: 0.71875\n",
      "Epoch: 658, Loss: 1.353203296661377, Acc: 0.5\n",
      "Epoch: 659, Loss: 1.2211768627166748, Acc: 0.75\n",
      "Epoch: 660, Loss: 1.1413151025772095, Acc: 0.75\n",
      "Epoch: 661, Loss: 0.9721570611000061, Acc: 0.625\n",
      "Epoch: 662, Loss: 1.4010400772094727, Acc: 0.5\n",
      "Epoch: 663, Loss: 1.0330445766448975, Acc: 0.65625\n",
      "Epoch: 664, Loss: 1.0204005241394043, Acc: 0.6875\n",
      "Epoch: 665, Loss: 0.9458945393562317, Acc: 0.6875\n",
      "Epoch: 666, Loss: 1.4030687808990479, Acc: 0.53125\n",
      "Epoch: 667, Loss: 1.237578272819519, Acc: 0.65625\n",
      "Epoch: 668, Loss: 1.1492811441421509, Acc: 0.5625\n",
      "Epoch: 669, Loss: 0.9553053379058838, Acc: 0.75\n",
      "Epoch: 670, Loss: 1.061901330947876, Acc: 0.71875\n",
      "Epoch: 671, Loss: 1.2122695446014404, Acc: 0.59375\n",
      "Epoch: 672, Loss: 1.1751912832260132, Acc: 0.65625\n",
      "Epoch: 673, Loss: 1.7998664379119873, Acc: 0.5\n",
      "Epoch: 674, Loss: 1.0309128761291504, Acc: 0.65625\n",
      "Epoch: 675, Loss: 1.1654293537139893, Acc: 0.625\n",
      "Epoch: 676, Loss: 1.105065941810608, Acc: 0.65625\n",
      "Epoch: 677, Loss: 1.1977514028549194, Acc: 0.625\n",
      "Epoch: 678, Loss: 1.2948118448257446, Acc: 0.625\n",
      "Epoch: 679, Loss: 1.5536590814590454, Acc: 0.46875\n",
      "Epoch: 680, Loss: 1.064900279045105, Acc: 0.71875\n",
      "Epoch: 681, Loss: 1.0785285234451294, Acc: 0.71875\n",
      "Epoch: 682, Loss: 1.2416974306106567, Acc: 0.65625\n",
      "Epoch: 683, Loss: 1.617645263671875, Acc: 0.5\n",
      "Epoch: 684, Loss: 1.422916054725647, Acc: 0.53125\n",
      "Epoch: 685, Loss: 1.5975148677825928, Acc: 0.40625\n",
      "Epoch: 686, Loss: 1.396026849746704, Acc: 0.5\n",
      "Epoch: 687, Loss: 1.210065245628357, Acc: 0.65625\n",
      "Epoch: 688, Loss: 1.0054616928100586, Acc: 0.625\n",
      "Epoch: 689, Loss: 0.8497803807258606, Acc: 0.6875\n",
      "Epoch: 690, Loss: 1.146246075630188, Acc: 0.5625\n",
      "Epoch: 691, Loss: 1.4080694913864136, Acc: 0.59375\n",
      "Epoch: 692, Loss: 1.2655351161956787, Acc: 0.59375\n",
      "Epoch: 693, Loss: 0.9423527121543884, Acc: 0.65625\n",
      "Epoch: 694, Loss: 1.0473589897155762, Acc: 0.6875\n",
      "Epoch: 695, Loss: 1.2941299676895142, Acc: 0.5625\n",
      "Epoch: 696, Loss: 1.2899012565612793, Acc: 0.625\n",
      "Epoch: 697, Loss: 1.2912640571594238, Acc: 0.5\n",
      "Epoch: 698, Loss: 1.0457381010055542, Acc: 0.6875\n",
      "Epoch: 699, Loss: 1.1420401334762573, Acc: 0.59375\n",
      "Epoch: 700, Loss: 1.381117820739746, Acc: 0.5625\n",
      "Epoch: 701, Loss: 0.9485092163085938, Acc: 0.59375\n",
      "Epoch: 702, Loss: 1.3792684078216553, Acc: 0.5625\n",
      "Epoch: 703, Loss: 1.2735233306884766, Acc: 0.53125\n",
      "Epoch: 704, Loss: 1.5112779140472412, Acc: 0.5625\n",
      "Epoch: 705, Loss: 1.0320693254470825, Acc: 0.625\n",
      "Epoch: 706, Loss: 0.8851743936538696, Acc: 0.71875\n",
      "Epoch: 707, Loss: 1.7111408710479736, Acc: 0.4375\n",
      "Epoch: 708, Loss: 1.2682487964630127, Acc: 0.625\n",
      "Epoch: 709, Loss: 1.2859338521957397, Acc: 0.65625\n",
      "Epoch: 710, Loss: 1.4552775621414185, Acc: 0.59375\n",
      "Epoch: 711, Loss: 1.5842947959899902, Acc: 0.46875\n",
      "Epoch: 712, Loss: 0.8135140538215637, Acc: 0.78125\n",
      "Epoch: 713, Loss: 1.1876342296600342, Acc: 0.65625\n",
      "Epoch: 714, Loss: 0.8844913244247437, Acc: 0.625\n",
      "Epoch: 715, Loss: 1.5474810600280762, Acc: 0.5\n",
      "Epoch: 716, Loss: 1.0829616785049438, Acc: 0.65625\n",
      "Epoch: 717, Loss: 1.3212844133377075, Acc: 0.59375\n",
      "Epoch: 718, Loss: 1.431806206703186, Acc: 0.5625\n",
      "Epoch: 719, Loss: 1.1790217161178589, Acc: 0.5\n",
      "Epoch: 720, Loss: 1.1296076774597168, Acc: 0.625\n",
      "Epoch: 721, Loss: 1.2058990001678467, Acc: 0.75\n",
      "Epoch: 722, Loss: 1.1457765102386475, Acc: 0.65625\n",
      "Epoch: 723, Loss: 1.331670880317688, Acc: 0.5\n",
      "Epoch: 724, Loss: 1.268573522567749, Acc: 0.5\n",
      "Epoch: 725, Loss: 0.9876716732978821, Acc: 0.59375\n",
      "Epoch: 726, Loss: 1.2900854349136353, Acc: 0.53125\n",
      "Epoch: 727, Loss: 1.1560825109481812, Acc: 0.625\n",
      "Epoch: 728, Loss: 1.2490646839141846, Acc: 0.5\n",
      "Epoch: 729, Loss: 1.1023344993591309, Acc: 0.65625\n",
      "Epoch: 730, Loss: 1.3594681024551392, Acc: 0.53125\n",
      "Epoch: 731, Loss: 1.264770269393921, Acc: 0.59375\n",
      "Epoch: 732, Loss: 1.2165073156356812, Acc: 0.59375\n",
      "Epoch: 733, Loss: 0.9935572147369385, Acc: 0.65625\n",
      "Epoch: 734, Loss: 1.716933012008667, Acc: 0.40625\n",
      "Epoch: 735, Loss: 1.8268451690673828, Acc: 0.34375\n",
      "Epoch: 736, Loss: 0.9840360283851624, Acc: 0.625\n",
      "Epoch: 737, Loss: 1.3486931324005127, Acc: 0.5\n",
      "Epoch: 738, Loss: 0.9617292284965515, Acc: 0.71875\n",
      "Epoch: 739, Loss: 1.0179036855697632, Acc: 0.6875\n",
      "Epoch: 740, Loss: 0.9193658828735352, Acc: 0.65625\n",
      "Epoch: 741, Loss: 0.9637032151222229, Acc: 0.6875\n",
      "Epoch: 742, Loss: 1.445590853691101, Acc: 0.46875\n",
      "Epoch: 743, Loss: 1.2186391353607178, Acc: 0.5625\n",
      "Epoch: 744, Loss: 0.948232889175415, Acc: 0.71875\n",
      "Epoch: 745, Loss: 1.1612566709518433, Acc: 0.6875\n",
      "Epoch: 746, Loss: 1.0812000036239624, Acc: 0.71875\n",
      "Epoch: 747, Loss: 1.0213087797164917, Acc: 0.625\n",
      "Epoch: 748, Loss: 1.3476839065551758, Acc: 0.53125\n",
      "Epoch: 749, Loss: 1.072527289390564, Acc: 0.65625\n",
      "Epoch: 750, Loss: 1.4182008504867554, Acc: 0.5\n",
      "Epoch: 751, Loss: 1.2945083379745483, Acc: 0.59375\n",
      "Epoch: 752, Loss: 1.0671530961990356, Acc: 0.65625\n",
      "Epoch: 753, Loss: 1.0180332660675049, Acc: 0.78125\n",
      "Epoch: 754, Loss: 1.164249300956726, Acc: 0.65625\n",
      "Epoch: 755, Loss: 0.6122447848320007, Acc: 0.84375\n",
      "Epoch: 756, Loss: 1.1087952852249146, Acc: 0.625\n",
      "Epoch: 757, Loss: 0.992620050907135, Acc: 0.65625\n",
      "Epoch: 758, Loss: 0.9051892757415771, Acc: 0.71875\n",
      "Epoch: 759, Loss: 0.8324883580207825, Acc: 0.84375\n",
      "Epoch: 760, Loss: 1.1651370525360107, Acc: 0.6875\n",
      "Epoch: 761, Loss: 1.409339189529419, Acc: 0.625\n",
      "Epoch: 762, Loss: 1.0591450929641724, Acc: 0.6875\n",
      "Epoch: 763, Loss: 0.9779728651046753, Acc: 0.625\n",
      "Epoch: 764, Loss: 1.1593902111053467, Acc: 0.6875\n",
      "Epoch: 765, Loss: 1.0900566577911377, Acc: 0.625\n",
      "Epoch: 766, Loss: 0.8863147497177124, Acc: 0.75\n",
      "Epoch: 767, Loss: 1.3640600442886353, Acc: 0.5625\n",
      "Epoch: 768, Loss: 1.23828125, Acc: 0.65625\n",
      "Epoch: 769, Loss: 1.1211501359939575, Acc: 0.6875\n",
      "Epoch: 770, Loss: 0.9729396104812622, Acc: 0.59375\n",
      "Epoch: 771, Loss: 1.8219761848449707, Acc: 0.34375\n",
      "Epoch: 772, Loss: 1.1801551580429077, Acc: 0.625\n",
      "Epoch: 773, Loss: 1.3297885656356812, Acc: 0.5625\n",
      "Epoch: 774, Loss: 1.3576033115386963, Acc: 0.59375\n",
      "Epoch: 775, Loss: 1.083211064338684, Acc: 0.65625\n",
      "Epoch: 776, Loss: 1.0710980892181396, Acc: 0.59375\n",
      "Epoch: 777, Loss: 0.6565204858779907, Acc: 0.84375\n",
      "Epoch: 778, Loss: 1.2560819387435913, Acc: 0.53125\n",
      "Epoch: 779, Loss: 0.8444298505783081, Acc: 0.6875\n",
      "Epoch: 780, Loss: 1.233713984489441, Acc: 0.625\n",
      "Epoch: 781, Loss: 1.3261836767196655, Acc: 0.5625\n",
      "Epoch: 782, Loss: 1.2366575002670288, Acc: 0.5625\n",
      "Epoch: 783, Loss: 1.0012925863265991, Acc: 0.625\n",
      "Epoch: 784, Loss: 1.1908915042877197, Acc: 0.59375\n",
      "Epoch: 785, Loss: 1.1328080892562866, Acc: 0.5625\n",
      "Epoch: 786, Loss: 1.467018723487854, Acc: 0.625\n",
      "Epoch: 787, Loss: 1.2585772275924683, Acc: 0.46875\n",
      "Epoch: 788, Loss: 1.4370975494384766, Acc: 0.625\n",
      "Epoch: 789, Loss: 1.2746834754943848, Acc: 0.59375\n",
      "Epoch: 790, Loss: 1.241674542427063, Acc: 0.65625\n",
      "Epoch: 791, Loss: 1.4304991960525513, Acc: 0.5625\n",
      "Epoch: 792, Loss: 1.1859291791915894, Acc: 0.65625\n",
      "Epoch: 793, Loss: 1.2514747381210327, Acc: 0.65625\n",
      "Epoch: 794, Loss: 0.9415482878684998, Acc: 0.6875\n",
      "Epoch: 795, Loss: 1.343491554260254, Acc: 0.46875\n",
      "Epoch: 796, Loss: 0.8753721714019775, Acc: 0.75\n",
      "Epoch: 797, Loss: 1.153358817100525, Acc: 0.59375\n",
      "Epoch: 798, Loss: 1.3638734817504883, Acc: 0.59375\n",
      "Epoch: 799, Loss: 0.9677599668502808, Acc: 0.71875\n",
      "Epoch: 800, Loss: 0.8798054456710815, Acc: 0.71875\n",
      "Epoch: 801, Loss: 0.9856070876121521, Acc: 0.71875\n",
      "Epoch: 802, Loss: 1.0750560760498047, Acc: 0.625\n",
      "Epoch: 803, Loss: 1.1102900505065918, Acc: 0.625\n",
      "Epoch: 804, Loss: 1.2840113639831543, Acc: 0.5\n",
      "Epoch: 805, Loss: 1.1942901611328125, Acc: 0.59375\n",
      "Epoch: 806, Loss: 1.0631327629089355, Acc: 0.6875\n",
      "Epoch: 807, Loss: 1.000300645828247, Acc: 0.6875\n",
      "Epoch: 808, Loss: 0.8721147179603577, Acc: 0.65625\n",
      "Epoch: 809, Loss: 0.9037342667579651, Acc: 0.6875\n",
      "Epoch: 810, Loss: 0.9837138652801514, Acc: 0.6875\n",
      "Epoch: 811, Loss: 0.8938403129577637, Acc: 0.75\n",
      "Epoch: 812, Loss: 1.2869689464569092, Acc: 0.5625\n",
      "Epoch: 813, Loss: 1.1848593950271606, Acc: 0.71875\n",
      "Epoch: 814, Loss: 0.776332437992096, Acc: 0.8125\n",
      "Epoch: 815, Loss: 1.285423755645752, Acc: 0.65625\n",
      "Epoch: 816, Loss: 1.424743413925171, Acc: 0.5\n",
      "Epoch: 817, Loss: 0.8727802038192749, Acc: 0.59375\n",
      "Epoch: 818, Loss: 1.1157853603363037, Acc: 0.59375\n",
      "Epoch: 819, Loss: 1.0901963710784912, Acc: 0.65625\n",
      "Epoch: 820, Loss: 1.39253830909729, Acc: 0.53125\n",
      "Epoch: 821, Loss: 1.1650710105895996, Acc: 0.5625\n",
      "Epoch: 822, Loss: 1.2761677503585815, Acc: 0.53125\n",
      "Epoch: 823, Loss: 1.371870756149292, Acc: 0.40625\n",
      "Epoch: 824, Loss: 1.3175979852676392, Acc: 0.6875\n",
      "Epoch: 825, Loss: 1.2869209051132202, Acc: 0.5\n",
      "Epoch: 826, Loss: 0.7526476979255676, Acc: 0.78125\n",
      "Epoch: 827, Loss: 1.1972875595092773, Acc: 0.65625\n",
      "Epoch: 828, Loss: 1.2754403352737427, Acc: 0.625\n",
      "Epoch: 829, Loss: 1.1501846313476562, Acc: 0.625\n",
      "Epoch: 830, Loss: 1.3100608587265015, Acc: 0.65625\n",
      "Epoch: 831, Loss: 1.1891107559204102, Acc: 0.59375\n",
      "Epoch: 832, Loss: 1.2995036840438843, Acc: 0.75\n",
      "Epoch: 833, Loss: 1.280413269996643, Acc: 0.59375\n",
      "Epoch: 834, Loss: 1.31756591796875, Acc: 0.5625\n",
      "Epoch: 835, Loss: 0.7749220728874207, Acc: 0.75\n",
      "Epoch: 836, Loss: 1.3996611833572388, Acc: 0.4375\n",
      "Epoch: 837, Loss: 0.8244008421897888, Acc: 0.8125\n",
      "Epoch: 838, Loss: 0.9356657862663269, Acc: 0.625\n",
      "Epoch: 839, Loss: 1.2305487394332886, Acc: 0.625\n",
      "Epoch: 840, Loss: 1.23688542842865, Acc: 0.625\n",
      "Epoch: 841, Loss: 0.7745596766471863, Acc: 0.78125\n",
      "Epoch: 842, Loss: 1.2448261976242065, Acc: 0.5\n",
      "Epoch: 843, Loss: 0.9106689691543579, Acc: 0.65625\n",
      "Epoch: 844, Loss: 1.3230328559875488, Acc: 0.59375\n",
      "Epoch: 845, Loss: 1.3292707204818726, Acc: 0.5625\n",
      "Epoch: 846, Loss: 1.432724118232727, Acc: 0.5625\n",
      "Epoch: 847, Loss: 0.6509817838668823, Acc: 0.78125\n",
      "Epoch: 848, Loss: 1.223411202430725, Acc: 0.625\n",
      "Epoch: 849, Loss: 0.9436507225036621, Acc: 0.6875\n",
      "Epoch: 850, Loss: 1.1777722835540771, Acc: 0.59375\n",
      "Epoch: 851, Loss: 0.9052092432975769, Acc: 0.71875\n",
      "Epoch: 852, Loss: 1.120302438735962, Acc: 0.625\n",
      "Epoch: 853, Loss: 1.0333974361419678, Acc: 0.625\n",
      "Epoch: 854, Loss: 1.1825922727584839, Acc: 0.5625\n",
      "Epoch: 855, Loss: 1.3100675344467163, Acc: 0.5\n",
      "Epoch: 856, Loss: 0.8787903785705566, Acc: 0.6875\n",
      "Epoch: 857, Loss: 1.2641401290893555, Acc: 0.625\n",
      "Epoch: 858, Loss: 0.7566146850585938, Acc: 0.71875\n",
      "Epoch: 859, Loss: 1.219094157218933, Acc: 0.53125\n",
      "Epoch: 860, Loss: 1.041276454925537, Acc: 0.65625\n",
      "Epoch: 861, Loss: 1.3739460706710815, Acc: 0.46875\n",
      "Epoch: 862, Loss: 1.0350115299224854, Acc: 0.71875\n",
      "Epoch: 863, Loss: 1.3591442108154297, Acc: 0.46875\n",
      "Epoch: 864, Loss: 1.0052248239517212, Acc: 0.6875\n",
      "Epoch: 865, Loss: 1.0464714765548706, Acc: 0.6875\n",
      "Epoch: 866, Loss: 1.3608739376068115, Acc: 0.53125\n",
      "Epoch: 867, Loss: 0.994358479976654, Acc: 0.59375\n",
      "Epoch: 868, Loss: 0.9492904543876648, Acc: 0.71875\n",
      "Epoch: 869, Loss: 1.2222328186035156, Acc: 0.59375\n",
      "Epoch: 870, Loss: 1.005798101425171, Acc: 0.6875\n",
      "Epoch: 871, Loss: 1.0536904335021973, Acc: 0.625\n",
      "Epoch: 872, Loss: 1.1442104578018188, Acc: 0.5625\n",
      "Epoch: 873, Loss: 0.8834593296051025, Acc: 0.71875\n",
      "Epoch: 874, Loss: 1.2417149543762207, Acc: 0.59375\n",
      "Epoch: 875, Loss: 1.1464225053787231, Acc: 0.78125\n",
      "Epoch: 876, Loss: 1.3777607679367065, Acc: 0.4375\n",
      "Epoch: 877, Loss: 0.7581470012664795, Acc: 0.8125\n",
      "Epoch: 878, Loss: 1.0859583616256714, Acc: 0.65625\n",
      "Epoch: 879, Loss: 0.5889481902122498, Acc: 0.84375\n",
      "Epoch: 880, Loss: 0.9575392603874207, Acc: 0.6875\n",
      "Epoch: 881, Loss: 1.0651271343231201, Acc: 0.6875\n",
      "Epoch: 882, Loss: 1.148482084274292, Acc: 0.59375\n",
      "Epoch: 883, Loss: 0.9699483513832092, Acc: 0.6875\n",
      "Epoch: 884, Loss: 1.106858253479004, Acc: 0.5625\n",
      "Epoch: 885, Loss: 1.0456805229187012, Acc: 0.6875\n",
      "Epoch: 886, Loss: 0.6823400855064392, Acc: 0.78125\n",
      "Epoch: 887, Loss: 0.9350817799568176, Acc: 0.75\n",
      "Epoch: 888, Loss: 1.0082719326019287, Acc: 0.6875\n",
      "Epoch: 889, Loss: 1.2760483026504517, Acc: 0.46875\n",
      "Epoch: 890, Loss: 1.2910072803497314, Acc: 0.5625\n",
      "Epoch: 891, Loss: 0.9733076095581055, Acc: 0.71875\n",
      "Epoch: 892, Loss: 0.8494293689727783, Acc: 0.6875\n",
      "Epoch: 893, Loss: 1.4343606233596802, Acc: 0.625\n",
      "Epoch: 894, Loss: 1.0517724752426147, Acc: 0.65625\n",
      "Epoch: 895, Loss: 1.225416660308838, Acc: 0.5\n",
      "Epoch: 896, Loss: 1.002680778503418, Acc: 0.6875\n",
      "Epoch: 897, Loss: 1.3899680376052856, Acc: 0.46875\n",
      "Epoch: 898, Loss: 0.9817703366279602, Acc: 0.6875\n",
      "Epoch: 899, Loss: 1.493321180343628, Acc: 0.40625\n",
      "Epoch: 900, Loss: 1.2785775661468506, Acc: 0.625\n",
      "Epoch: 901, Loss: 0.9041005373001099, Acc: 0.75\n",
      "Epoch: 902, Loss: 1.3481465578079224, Acc: 0.6875\n",
      "Epoch: 903, Loss: 1.1741156578063965, Acc: 0.65625\n",
      "Epoch: 904, Loss: 1.2299153804779053, Acc: 0.625\n",
      "Epoch: 905, Loss: 1.0545986890792847, Acc: 0.5625\n",
      "Epoch: 906, Loss: 0.9102969169616699, Acc: 0.65625\n",
      "Epoch: 907, Loss: 0.7265004515647888, Acc: 0.78125\n",
      "Epoch: 908, Loss: 1.068297266960144, Acc: 0.625\n",
      "Epoch: 909, Loss: 1.0932531356811523, Acc: 0.6875\n",
      "Epoch: 910, Loss: 1.14581298828125, Acc: 0.6875\n",
      "Epoch: 911, Loss: 0.9839721918106079, Acc: 0.75\n",
      "Epoch: 912, Loss: 1.3533658981323242, Acc: 0.53125\n",
      "Epoch: 913, Loss: 1.1438629627227783, Acc: 0.71875\n",
      "Epoch: 914, Loss: 1.2232720851898193, Acc: 0.59375\n",
      "Epoch: 915, Loss: 0.9092687368392944, Acc: 0.75\n",
      "Epoch: 916, Loss: 1.2395217418670654, Acc: 0.65625\n",
      "Epoch: 917, Loss: 1.0738276243209839, Acc: 0.53125\n",
      "Epoch: 918, Loss: 0.9613109230995178, Acc: 0.75\n",
      "Epoch: 919, Loss: 1.0158394575119019, Acc: 0.71875\n",
      "Epoch: 920, Loss: 0.8669415712356567, Acc: 0.65625\n",
      "Epoch: 921, Loss: 1.3164708614349365, Acc: 0.625\n",
      "Epoch: 922, Loss: 0.7542675733566284, Acc: 0.78125\n",
      "Epoch: 923, Loss: 0.9258826971054077, Acc: 0.625\n",
      "Epoch: 924, Loss: 0.9052993655204773, Acc: 0.75\n",
      "Epoch: 925, Loss: 0.801770806312561, Acc: 0.8125\n",
      "Epoch: 926, Loss: 0.9929713010787964, Acc: 0.65625\n",
      "Epoch: 927, Loss: 1.205316185951233, Acc: 0.65625\n",
      "Epoch: 928, Loss: 0.7689005136489868, Acc: 0.84375\n",
      "Epoch: 929, Loss: 1.1250596046447754, Acc: 0.5625\n",
      "Epoch: 930, Loss: 1.0581060647964478, Acc: 0.625\n",
      "Epoch: 931, Loss: 1.5624977350234985, Acc: 0.5625\n",
      "Epoch: 932, Loss: 1.139352798461914, Acc: 0.6875\n",
      "Epoch: 933, Loss: 0.868622362613678, Acc: 0.71875\n",
      "Epoch: 934, Loss: 0.9955472946166992, Acc: 0.71875\n",
      "Epoch: 935, Loss: 0.9247957468032837, Acc: 0.75\n",
      "Epoch: 936, Loss: 1.0643737316131592, Acc: 0.6875\n",
      "Epoch: 937, Loss: 0.9192514419555664, Acc: 0.65625\n",
      "Epoch: 938, Loss: 0.7519915699958801, Acc: 0.71875\n",
      "Epoch: 939, Loss: 0.9515963196754456, Acc: 0.625\n",
      "Epoch: 940, Loss: 1.1483922004699707, Acc: 0.65625\n",
      "Epoch: 941, Loss: 1.287071943283081, Acc: 0.625\n",
      "Epoch: 942, Loss: 0.6426578760147095, Acc: 0.8125\n",
      "Epoch: 943, Loss: 1.1276153326034546, Acc: 0.65625\n",
      "Epoch: 944, Loss: 0.7118223905563354, Acc: 0.8125\n",
      "Epoch: 945, Loss: 0.9468412399291992, Acc: 0.78125\n",
      "Epoch: 946, Loss: 1.0377449989318848, Acc: 0.65625\n",
      "Epoch: 947, Loss: 0.8630179762840271, Acc: 0.78125\n",
      "Epoch: 948, Loss: 0.9754061698913574, Acc: 0.6875\n",
      "Epoch: 949, Loss: 1.2233010530471802, Acc: 0.65625\n",
      "Epoch: 950, Loss: 1.1436946392059326, Acc: 0.65625\n",
      "Epoch: 951, Loss: 1.0762265920639038, Acc: 0.65625\n",
      "Epoch: 952, Loss: 0.9276615381240845, Acc: 0.6875\n",
      "Epoch: 953, Loss: 1.2691717147827148, Acc: 0.5\n",
      "Epoch: 954, Loss: 0.8140414953231812, Acc: 0.8125\n",
      "Epoch: 955, Loss: 1.3208576440811157, Acc: 0.59375\n",
      "Epoch: 956, Loss: 0.6666650772094727, Acc: 0.78125\n",
      "Epoch: 957, Loss: 0.8764441013336182, Acc: 0.71875\n",
      "Epoch: 958, Loss: 1.145873785018921, Acc: 0.59375\n",
      "Epoch: 959, Loss: 0.8891611695289612, Acc: 0.71875\n",
      "Epoch: 960, Loss: 0.6696592569351196, Acc: 0.78125\n",
      "Epoch: 961, Loss: 1.0149052143096924, Acc: 0.5\n",
      "Epoch: 962, Loss: 1.0956796407699585, Acc: 0.625\n",
      "Epoch: 963, Loss: 1.0869473218917847, Acc: 0.5625\n",
      "Epoch: 964, Loss: 0.9202560782432556, Acc: 0.75\n",
      "Epoch: 965, Loss: 1.2054929733276367, Acc: 0.5625\n",
      "Epoch: 966, Loss: 0.6047948598861694, Acc: 0.8125\n",
      "Epoch: 967, Loss: 1.198322057723999, Acc: 0.625\n",
      "Epoch: 968, Loss: 0.9892609119415283, Acc: 0.59375\n",
      "Epoch: 969, Loss: 1.1461421251296997, Acc: 0.625\n",
      "Epoch: 970, Loss: 0.7818529605865479, Acc: 0.8125\n",
      "Epoch: 971, Loss: 0.8243072032928467, Acc: 0.75\n",
      "Epoch: 972, Loss: 1.079493522644043, Acc: 0.6875\n",
      "Epoch: 973, Loss: 0.9777348041534424, Acc: 0.71875\n",
      "Epoch: 974, Loss: 0.9352433085441589, Acc: 0.6875\n",
      "Epoch: 975, Loss: 0.9854416847229004, Acc: 0.625\n",
      "Epoch: 976, Loss: 0.8490987420082092, Acc: 0.71875\n",
      "Epoch: 977, Loss: 0.9704978466033936, Acc: 0.75\n",
      "Epoch: 978, Loss: 1.0903033018112183, Acc: 0.6875\n",
      "Epoch: 979, Loss: 1.0511952638626099, Acc: 0.65625\n",
      "Epoch: 980, Loss: 0.9756525158882141, Acc: 0.59375\n",
      "Epoch: 981, Loss: 0.8160156607627869, Acc: 0.6875\n",
      "Epoch: 982, Loss: 1.0840944051742554, Acc: 0.59375\n",
      "Epoch: 983, Loss: 0.8004674911499023, Acc: 0.6875\n",
      "Epoch: 984, Loss: 0.7854396104812622, Acc: 0.71875\n",
      "Epoch: 985, Loss: 1.0462325811386108, Acc: 0.71875\n",
      "Epoch: 986, Loss: 0.6194977760314941, Acc: 0.78125\n",
      "Epoch: 987, Loss: 0.7666624784469604, Acc: 0.71875\n",
      "Epoch: 988, Loss: 1.3866870403289795, Acc: 0.5\n",
      "Epoch: 989, Loss: 0.965317964553833, Acc: 0.65625\n",
      "Epoch: 990, Loss: 0.8780550956726074, Acc: 0.6875\n",
      "Epoch: 991, Loss: 1.0385373830795288, Acc: 0.65625\n",
      "Epoch: 992, Loss: 0.9115814566612244, Acc: 0.6875\n",
      "Epoch: 993, Loss: 0.661562979221344, Acc: 0.75\n",
      "Epoch: 994, Loss: 0.7703065872192383, Acc: 0.84375\n",
      "Epoch: 995, Loss: 0.997704267501831, Acc: 0.71875\n",
      "Epoch: 996, Loss: 0.8375044465065002, Acc: 0.8125\n",
      "Epoch: 997, Loss: 0.9701162576675415, Acc: 0.625\n",
      "Epoch: 998, Loss: 1.0223935842514038, Acc: 0.59375\n",
      "Epoch: 999, Loss: 1.2958725690841675, Acc: 0.59375\n",
      "Epoch: 1000, Loss: 1.3682830333709717, Acc: 0.59375\n",
      "Epoch: 1001, Loss: 0.9735444784164429, Acc: 0.78125\n",
      "Epoch: 1002, Loss: 0.6694650053977966, Acc: 0.75\n",
      "Epoch: 1003, Loss: 1.020376443862915, Acc: 0.65625\n",
      "Epoch: 1004, Loss: 1.0841069221496582, Acc: 0.625\n",
      "Epoch: 1005, Loss: 1.3923366069793701, Acc: 0.59375\n",
      "Epoch: 1006, Loss: 0.8281746506690979, Acc: 0.6875\n",
      "Epoch: 1007, Loss: 0.763926088809967, Acc: 0.75\n",
      "Epoch: 1008, Loss: 0.9390307664871216, Acc: 0.59375\n",
      "Epoch: 1009, Loss: 1.1416325569152832, Acc: 0.625\n",
      "Epoch: 1010, Loss: 0.9564141631126404, Acc: 0.59375\n",
      "Epoch: 1011, Loss: 1.3685290813446045, Acc: 0.5625\n",
      "Epoch: 1012, Loss: 0.8210712671279907, Acc: 0.75\n",
      "Epoch: 1013, Loss: 1.2119359970092773, Acc: 0.625\n",
      "Epoch: 1014, Loss: 1.1250979900360107, Acc: 0.71875\n",
      "Epoch: 1015, Loss: 1.0907829999923706, Acc: 0.65625\n",
      "Epoch: 1016, Loss: 0.8173714280128479, Acc: 0.78125\n",
      "Epoch: 1017, Loss: 1.1668740510940552, Acc: 0.625\n",
      "Epoch: 1018, Loss: 0.7704160213470459, Acc: 0.75\n",
      "Epoch: 1019, Loss: 1.0671836137771606, Acc: 0.6875\n",
      "Epoch: 1020, Loss: 1.108932375907898, Acc: 0.6875\n",
      "Epoch: 1021, Loss: 1.0909565687179565, Acc: 0.65625\n",
      "Epoch: 1022, Loss: 0.8088142275810242, Acc: 0.8125\n",
      "Epoch: 1023, Loss: 1.0046714544296265, Acc: 0.625\n",
      "Epoch: 1024, Loss: 1.1124886274337769, Acc: 0.53125\n",
      "Epoch: 1025, Loss: 0.8799729347229004, Acc: 0.71875\n",
      "Epoch: 1026, Loss: 0.977233350276947, Acc: 0.59375\n",
      "Epoch: 1027, Loss: 0.8384706377983093, Acc: 0.71875\n",
      "Epoch: 1028, Loss: 0.7277183532714844, Acc: 0.8125\n",
      "Epoch: 1029, Loss: 1.1588538885116577, Acc: 0.5625\n",
      "Epoch: 1030, Loss: 1.0359947681427002, Acc: 0.5625\n",
      "Epoch: 1031, Loss: 1.1463239192962646, Acc: 0.625\n",
      "Epoch: 1032, Loss: 0.9716880321502686, Acc: 0.65625\n",
      "Epoch: 1033, Loss: 0.8711345791816711, Acc: 0.75\n",
      "Epoch: 1034, Loss: 0.8373328447341919, Acc: 0.6875\n",
      "Epoch: 1035, Loss: 1.213950276374817, Acc: 0.625\n",
      "Epoch: 1036, Loss: 1.1033215522766113, Acc: 0.6875\n",
      "Epoch: 1037, Loss: 1.18899667263031, Acc: 0.65625\n",
      "Epoch: 1038, Loss: 0.70201575756073, Acc: 0.78125\n",
      "Epoch: 1039, Loss: 0.8651663661003113, Acc: 0.78125\n",
      "Epoch: 1040, Loss: 0.6966872215270996, Acc: 0.8125\n",
      "Epoch: 1041, Loss: 0.5859987735748291, Acc: 0.8125\n",
      "Epoch: 1042, Loss: 1.1564069986343384, Acc: 0.71875\n",
      "Epoch: 1043, Loss: 1.061737060546875, Acc: 0.65625\n",
      "Epoch: 1044, Loss: 0.5903538465499878, Acc: 0.8125\n",
      "Epoch: 1045, Loss: 0.9772754311561584, Acc: 0.65625\n",
      "Epoch: 1046, Loss: 1.2997921705245972, Acc: 0.59375\n",
      "Epoch: 1047, Loss: 1.2070032358169556, Acc: 0.53125\n",
      "Epoch: 1048, Loss: 0.8806155323982239, Acc: 0.78125\n",
      "Epoch: 1049, Loss: 0.876059353351593, Acc: 0.75\n",
      "Epoch: 1050, Loss: 1.1484986543655396, Acc: 0.59375\n",
      "Epoch: 1051, Loss: 1.0135430097579956, Acc: 0.65625\n",
      "Epoch: 1052, Loss: 1.2300859689712524, Acc: 0.625\n",
      "Epoch: 1053, Loss: 0.5742689371109009, Acc: 0.78125\n",
      "Epoch: 1054, Loss: 0.9350138902664185, Acc: 0.75\n",
      "Epoch: 1055, Loss: 0.9351540207862854, Acc: 0.71875\n",
      "Epoch: 1056, Loss: 0.8650570511817932, Acc: 0.6875\n",
      "Epoch: 1057, Loss: 0.7817345261573792, Acc: 0.75\n",
      "Epoch: 1058, Loss: 0.9239944815635681, Acc: 0.625\n",
      "Epoch: 1059, Loss: 0.9885842204093933, Acc: 0.75\n",
      "Epoch: 1060, Loss: 0.5973052978515625, Acc: 0.78125\n",
      "Epoch: 1061, Loss: 0.6566541790962219, Acc: 0.84375\n",
      "Epoch: 1062, Loss: 1.0074018239974976, Acc: 0.65625\n",
      "Epoch: 1063, Loss: 0.7190473675727844, Acc: 0.6875\n",
      "Epoch: 1064, Loss: 0.7265855669975281, Acc: 0.75\n",
      "Epoch: 1065, Loss: 0.7332847118377686, Acc: 0.8125\n",
      "Epoch: 1066, Loss: 1.0545694828033447, Acc: 0.65625\n",
      "Epoch: 1067, Loss: 1.2622594833374023, Acc: 0.65625\n",
      "Epoch: 1068, Loss: 0.8118188381195068, Acc: 0.6875\n",
      "Epoch: 1069, Loss: 0.8089411854743958, Acc: 0.78125\n",
      "Epoch: 1070, Loss: 0.9457491636276245, Acc: 0.71875\n",
      "Epoch: 1071, Loss: 0.6134567856788635, Acc: 0.78125\n",
      "Epoch: 1072, Loss: 0.9416776299476624, Acc: 0.6875\n",
      "Epoch: 1073, Loss: 1.178236722946167, Acc: 0.625\n",
      "Epoch: 1074, Loss: 0.7962979078292847, Acc: 0.75\n",
      "Epoch: 1075, Loss: 1.1993194818496704, Acc: 0.5625\n",
      "Epoch: 1076, Loss: 0.901589035987854, Acc: 0.75\n",
      "Epoch: 1077, Loss: 1.3081427812576294, Acc: 0.625\n",
      "Epoch: 1078, Loss: 1.0274606943130493, Acc: 0.65625\n",
      "Epoch: 1079, Loss: 0.924311101436615, Acc: 0.6875\n",
      "Epoch: 1080, Loss: 0.690762460231781, Acc: 0.78125\n",
      "Epoch: 1081, Loss: 0.7296241521835327, Acc: 0.84375\n",
      "Epoch: 1082, Loss: 0.7886826992034912, Acc: 0.8125\n",
      "Epoch: 1083, Loss: 1.0105229616165161, Acc: 0.65625\n",
      "Epoch: 1084, Loss: 0.8611974716186523, Acc: 0.71875\n",
      "Epoch: 1085, Loss: 1.0221830606460571, Acc: 0.6875\n",
      "Epoch: 1086, Loss: 1.2527872323989868, Acc: 0.5625\n",
      "Epoch: 1087, Loss: 1.004715919494629, Acc: 0.75\n",
      "Epoch: 1088, Loss: 1.0061664581298828, Acc: 0.6875\n",
      "Epoch: 1089, Loss: 0.8375126719474792, Acc: 0.6875\n",
      "Epoch: 1090, Loss: 0.4685656726360321, Acc: 0.90625\n",
      "Epoch: 1091, Loss: 1.2724292278289795, Acc: 0.625\n",
      "Epoch: 1092, Loss: 0.7800050377845764, Acc: 0.78125\n",
      "Epoch: 1093, Loss: 0.5542560815811157, Acc: 0.84375\n",
      "Epoch: 1094, Loss: 1.0727839469909668, Acc: 0.65625\n",
      "Epoch: 1095, Loss: 0.7738839387893677, Acc: 0.75\n",
      "Epoch: 1096, Loss: 0.6962520480155945, Acc: 0.71875\n",
      "Epoch: 1097, Loss: 0.9584144949913025, Acc: 0.625\n",
      "Epoch: 1098, Loss: 0.7003885507583618, Acc: 0.6875\n",
      "Epoch: 1099, Loss: 0.8596308827400208, Acc: 0.625\n",
      "Epoch: 1100, Loss: 0.8341427445411682, Acc: 0.71875\n",
      "Epoch: 1101, Loss: 1.0737838745117188, Acc: 0.6875\n",
      "Epoch: 1102, Loss: 0.8450817465782166, Acc: 0.65625\n",
      "Epoch: 1103, Loss: 0.7662762999534607, Acc: 0.75\n",
      "Epoch: 1104, Loss: 0.8516020178794861, Acc: 0.75\n",
      "Epoch: 1105, Loss: 1.1279776096343994, Acc: 0.625\n",
      "Epoch: 1106, Loss: 0.49106812477111816, Acc: 0.875\n",
      "Epoch: 1107, Loss: 1.0424423217773438, Acc: 0.625\n",
      "Epoch: 1108, Loss: 0.9696485996246338, Acc: 0.625\n",
      "Epoch: 1109, Loss: 0.9171366095542908, Acc: 0.6875\n",
      "Epoch: 1110, Loss: 0.8968325853347778, Acc: 0.71875\n",
      "Epoch: 1111, Loss: 0.7882504463195801, Acc: 0.75\n",
      "Epoch: 1112, Loss: 0.5698449015617371, Acc: 0.8125\n",
      "Epoch: 1113, Loss: 0.9709767699241638, Acc: 0.71875\n",
      "Epoch: 1114, Loss: 1.0392637252807617, Acc: 0.6875\n",
      "Epoch: 1115, Loss: 0.6979413628578186, Acc: 0.75\n",
      "Epoch: 1116, Loss: 0.9826689958572388, Acc: 0.59375\n",
      "Epoch: 1117, Loss: 1.4835288524627686, Acc: 0.4375\n",
      "Epoch: 1118, Loss: 0.9388097524642944, Acc: 0.59375\n",
      "Epoch: 1119, Loss: 1.091085433959961, Acc: 0.71875\n",
      "Epoch: 1120, Loss: 0.7819639444351196, Acc: 0.6875\n",
      "Epoch: 1121, Loss: 0.852841317653656, Acc: 0.71875\n",
      "Epoch: 1122, Loss: 0.6398674845695496, Acc: 0.75\n",
      "Epoch: 1123, Loss: 1.1893892288208008, Acc: 0.6875\n",
      "Epoch: 1124, Loss: 0.7473841309547424, Acc: 0.71875\n",
      "Epoch: 1125, Loss: 1.072059154510498, Acc: 0.625\n",
      "Epoch: 1126, Loss: 0.8703161478042603, Acc: 0.75\n",
      "Epoch: 1127, Loss: 0.9616683125495911, Acc: 0.65625\n",
      "Epoch: 1128, Loss: 0.6773032546043396, Acc: 0.75\n",
      "Epoch: 1129, Loss: 0.9290270209312439, Acc: 0.6875\n",
      "Epoch: 1130, Loss: 0.8310356140136719, Acc: 0.6875\n",
      "Epoch: 1131, Loss: 0.8071391582489014, Acc: 0.75\n",
      "Epoch: 1132, Loss: 1.1044131517410278, Acc: 0.625\n",
      "Epoch: 1133, Loss: 1.0186772346496582, Acc: 0.65625\n",
      "Epoch: 1134, Loss: 0.5352388024330139, Acc: 0.875\n",
      "Epoch: 1135, Loss: 1.147879958152771, Acc: 0.625\n",
      "Epoch: 1136, Loss: 1.3415924310684204, Acc: 0.53125\n",
      "Epoch: 1137, Loss: 1.0750210285186768, Acc: 0.71875\n",
      "Epoch: 1138, Loss: 0.8834888339042664, Acc: 0.6875\n",
      "Epoch: 1139, Loss: 0.7203100323677063, Acc: 0.78125\n",
      "Epoch: 1140, Loss: 0.9699772000312805, Acc: 0.75\n",
      "Epoch: 1141, Loss: 0.7694090008735657, Acc: 0.75\n",
      "Epoch: 1142, Loss: 1.0426883697509766, Acc: 0.71875\n",
      "Epoch: 1143, Loss: 1.1250779628753662, Acc: 0.65625\n",
      "Epoch: 1144, Loss: 1.2149534225463867, Acc: 0.65625\n",
      "Epoch: 1145, Loss: 0.5810436606407166, Acc: 0.78125\n",
      "Epoch: 1146, Loss: 0.7129622101783752, Acc: 0.75\n",
      "Epoch: 1147, Loss: 0.9610776305198669, Acc: 0.71875\n",
      "Epoch: 1148, Loss: 0.9741595387458801, Acc: 0.6875\n",
      "Epoch: 1149, Loss: 0.7484464645385742, Acc: 0.75\n",
      "Epoch: 1150, Loss: 0.8916620016098022, Acc: 0.71875\n",
      "Epoch: 1151, Loss: 1.1091804504394531, Acc: 0.59375\n",
      "Epoch: 1152, Loss: 0.6962361335754395, Acc: 0.8125\n",
      "Epoch: 1153, Loss: 0.9019089937210083, Acc: 0.6875\n",
      "Epoch: 1154, Loss: 1.0874000787734985, Acc: 0.65625\n",
      "Epoch: 1155, Loss: 0.6674569249153137, Acc: 0.78125\n",
      "Epoch: 1156, Loss: 0.8268366456031799, Acc: 0.65625\n",
      "Epoch: 1157, Loss: 0.9660124182701111, Acc: 0.65625\n",
      "Epoch: 1158, Loss: 0.4070509970188141, Acc: 0.875\n",
      "Epoch: 1159, Loss: 0.8136134147644043, Acc: 0.75\n",
      "Epoch: 1160, Loss: 0.9052490592002869, Acc: 0.71875\n",
      "Epoch: 1161, Loss: 0.7695313096046448, Acc: 0.75\n",
      "Epoch: 1162, Loss: 0.8542196750640869, Acc: 0.6875\n",
      "Epoch: 1163, Loss: 0.8573983907699585, Acc: 0.6875\n",
      "Epoch: 1164, Loss: 0.9880822896957397, Acc: 0.71875\n",
      "Epoch: 1165, Loss: 0.8349780440330505, Acc: 0.75\n",
      "Epoch: 1166, Loss: 0.7978532314300537, Acc: 0.65625\n",
      "Epoch: 1167, Loss: 0.8525463342666626, Acc: 0.71875\n",
      "Epoch: 1168, Loss: 0.9019758105278015, Acc: 0.6875\n",
      "Epoch: 1169, Loss: 0.7517601251602173, Acc: 0.75\n",
      "Epoch: 1170, Loss: 0.7531463503837585, Acc: 0.8125\n",
      "Epoch: 1171, Loss: 1.0196094512939453, Acc: 0.625\n",
      "Epoch: 1172, Loss: 0.8418658971786499, Acc: 0.71875\n",
      "Epoch: 1173, Loss: 0.725683331489563, Acc: 0.78125\n",
      "Epoch: 1174, Loss: 0.7705312967300415, Acc: 0.75\n",
      "Epoch: 1175, Loss: 0.759279727935791, Acc: 0.75\n",
      "Epoch: 1176, Loss: 1.0067644119262695, Acc: 0.6875\n",
      "Epoch: 1177, Loss: 0.7530048489570618, Acc: 0.71875\n",
      "Epoch: 1178, Loss: 0.8722500801086426, Acc: 0.75\n",
      "Epoch: 1179, Loss: 1.1481119394302368, Acc: 0.6875\n",
      "Epoch: 1180, Loss: 0.9100441932678223, Acc: 0.6875\n",
      "Epoch: 1181, Loss: 1.0538660287857056, Acc: 0.625\n",
      "Epoch: 1182, Loss: 1.1776844263076782, Acc: 0.59375\n",
      "Epoch: 1183, Loss: 0.827682375907898, Acc: 0.75\n",
      "Epoch: 1184, Loss: 1.0303093194961548, Acc: 0.6875\n",
      "Epoch: 1185, Loss: 0.8291463255882263, Acc: 0.71875\n",
      "Epoch: 1186, Loss: 0.4754267930984497, Acc: 0.90625\n",
      "Epoch: 1187, Loss: 0.7385523319244385, Acc: 0.78125\n",
      "Epoch: 1188, Loss: 1.0914555788040161, Acc: 0.625\n",
      "Epoch: 1189, Loss: 0.8422682881355286, Acc: 0.65625\n",
      "Epoch: 1190, Loss: 1.1097345352172852, Acc: 0.59375\n",
      "Epoch: 1191, Loss: 1.108449935913086, Acc: 0.6875\n",
      "Epoch: 1192, Loss: 0.7615528106689453, Acc: 0.75\n",
      "Epoch: 1193, Loss: 0.8771962523460388, Acc: 0.6875\n",
      "Epoch: 1194, Loss: 0.8972779512405396, Acc: 0.65625\n",
      "Epoch: 1195, Loss: 0.8912636041641235, Acc: 0.6875\n",
      "Epoch: 1196, Loss: 0.7756206393241882, Acc: 0.78125\n",
      "Epoch: 1197, Loss: 0.9753366112709045, Acc: 0.65625\n",
      "Epoch: 1198, Loss: 0.971646785736084, Acc: 0.75\n",
      "Epoch: 1199, Loss: 0.8455938696861267, Acc: 0.71875\n",
      "Epoch: 1200, Loss: 0.914124071598053, Acc: 0.65625\n",
      "Epoch: 1201, Loss: 0.9383420944213867, Acc: 0.6875\n",
      "Epoch: 1202, Loss: 0.9613255262374878, Acc: 0.71875\n",
      "Epoch: 1203, Loss: 1.033172369003296, Acc: 0.65625\n",
      "Epoch: 1204, Loss: 0.7223596572875977, Acc: 0.71875\n",
      "Epoch: 1205, Loss: 1.0211925506591797, Acc: 0.75\n",
      "Epoch: 1206, Loss: 0.5362981557846069, Acc: 0.875\n",
      "Epoch: 1207, Loss: 0.6536163687705994, Acc: 0.8125\n",
      "Epoch: 1208, Loss: 0.953450083732605, Acc: 0.6875\n",
      "Epoch: 1209, Loss: 0.5827651023864746, Acc: 0.8125\n",
      "Epoch: 1210, Loss: 0.8154351115226746, Acc: 0.71875\n",
      "Epoch: 1211, Loss: 0.8102491497993469, Acc: 0.6875\n",
      "Epoch: 1212, Loss: 0.9494171142578125, Acc: 0.65625\n",
      "Epoch: 1213, Loss: 1.001399278640747, Acc: 0.78125\n",
      "Epoch: 1214, Loss: 0.6311060786247253, Acc: 0.75\n",
      "Epoch: 1215, Loss: 1.2275062799453735, Acc: 0.46875\n",
      "Epoch: 1216, Loss: 1.1253262758255005, Acc: 0.65625\n",
      "Epoch: 1217, Loss: 0.5677955746650696, Acc: 0.875\n",
      "Epoch: 1218, Loss: 0.8972579836845398, Acc: 0.71875\n",
      "Epoch: 1219, Loss: 0.9391939640045166, Acc: 0.71875\n",
      "Epoch: 1220, Loss: 1.0780375003814697, Acc: 0.5625\n",
      "Epoch: 1221, Loss: 0.8187056183815002, Acc: 0.65625\n",
      "Epoch: 1222, Loss: 1.000590205192566, Acc: 0.6875\n",
      "Epoch: 1223, Loss: 0.8179428577423096, Acc: 0.75\n",
      "Epoch: 1224, Loss: 0.8372137546539307, Acc: 0.625\n",
      "Epoch: 1225, Loss: 0.7214285135269165, Acc: 0.78125\n",
      "Epoch: 1226, Loss: 1.0294182300567627, Acc: 0.625\n",
      "Epoch: 1227, Loss: 0.9886788129806519, Acc: 0.6875\n",
      "Epoch: 1228, Loss: 1.011913776397705, Acc: 0.78125\n",
      "Epoch: 1229, Loss: 0.8610016703605652, Acc: 0.625\n",
      "Epoch: 1230, Loss: 1.033695936203003, Acc: 0.6875\n",
      "Epoch: 1231, Loss: 0.6849138140678406, Acc: 0.8125\n",
      "Epoch: 1232, Loss: 1.0159993171691895, Acc: 0.71875\n",
      "Epoch: 1233, Loss: 0.6882901787757874, Acc: 0.78125\n",
      "Epoch: 1234, Loss: 0.8184259533882141, Acc: 0.78125\n",
      "Epoch: 1235, Loss: 0.8982113003730774, Acc: 0.65625\n",
      "Epoch: 1236, Loss: 1.0487428903579712, Acc: 0.71875\n",
      "Epoch: 1237, Loss: 1.0487844944000244, Acc: 0.59375\n",
      "Epoch: 1238, Loss: 0.3757041096687317, Acc: 0.90625\n",
      "Epoch: 1239, Loss: 0.9902979135513306, Acc: 0.59375\n",
      "Epoch: 1240, Loss: 1.106469750404358, Acc: 0.65625\n",
      "Epoch: 1241, Loss: 1.1699790954589844, Acc: 0.71875\n",
      "Epoch: 1242, Loss: 1.0949608087539673, Acc: 0.5625\n",
      "Epoch: 1243, Loss: 0.7537249326705933, Acc: 0.78125\n",
      "Epoch: 1244, Loss: 0.7086108326911926, Acc: 0.6875\n",
      "Epoch: 1245, Loss: 0.6930985450744629, Acc: 0.75\n",
      "Epoch: 1246, Loss: 0.8953326940536499, Acc: 0.6875\n",
      "Epoch: 1247, Loss: 1.0236643552780151, Acc: 0.6875\n",
      "Epoch: 1248, Loss: 1.0473206043243408, Acc: 0.71875\n",
      "Epoch: 1249, Loss: 0.8764665722846985, Acc: 0.59375\n",
      "Epoch: 1250, Loss: 0.6344431638717651, Acc: 0.78125\n",
      "Epoch: 1251, Loss: 0.827505350112915, Acc: 0.71875\n",
      "Epoch: 1252, Loss: 0.5813976526260376, Acc: 0.84375\n",
      "Epoch: 1253, Loss: 0.7686779499053955, Acc: 0.71875\n",
      "Epoch: 1254, Loss: 0.6960201263427734, Acc: 0.71875\n",
      "Epoch: 1255, Loss: 0.514893114566803, Acc: 0.8125\n",
      "Epoch: 1256, Loss: 0.8921317458152771, Acc: 0.6875\n",
      "Epoch: 1257, Loss: 0.8382593989372253, Acc: 0.71875\n",
      "Epoch: 1258, Loss: 1.1226444244384766, Acc: 0.59375\n",
      "Epoch: 1259, Loss: 0.6851975917816162, Acc: 0.84375\n",
      "Epoch: 1260, Loss: 1.1577037572860718, Acc: 0.6875\n",
      "Epoch: 1261, Loss: 0.6482828855514526, Acc: 0.75\n",
      "Epoch: 1262, Loss: 0.8438262939453125, Acc: 0.65625\n",
      "Epoch: 1263, Loss: 0.3749978840351105, Acc: 0.9375\n",
      "Epoch: 1264, Loss: 0.8368053436279297, Acc: 0.75\n",
      "Epoch: 1265, Loss: 0.635133683681488, Acc: 0.78125\n",
      "Epoch: 1266, Loss: 0.647405743598938, Acc: 0.75\n",
      "Epoch: 1267, Loss: 1.0758159160614014, Acc: 0.59375\n",
      "Epoch: 1268, Loss: 0.896837592124939, Acc: 0.65625\n",
      "Epoch: 1269, Loss: 1.1893136501312256, Acc: 0.5625\n",
      "Epoch: 1270, Loss: 0.7902880311012268, Acc: 0.71875\n",
      "Epoch: 1271, Loss: 0.8407829403877258, Acc: 0.6875\n",
      "Epoch: 1272, Loss: 1.2161002159118652, Acc: 0.65625\n",
      "Epoch: 1273, Loss: 0.8736780285835266, Acc: 0.65625\n",
      "Epoch: 1274, Loss: 1.0483556985855103, Acc: 0.6875\n",
      "Epoch: 1275, Loss: 0.805367112159729, Acc: 0.71875\n",
      "Epoch: 1276, Loss: 0.7872586846351624, Acc: 0.71875\n",
      "Epoch: 1277, Loss: 0.6569000482559204, Acc: 0.78125\n",
      "Epoch: 1278, Loss: 0.6754048466682434, Acc: 0.71875\n",
      "Epoch: 1279, Loss: 0.9571079611778259, Acc: 0.6875\n",
      "Epoch: 1280, Loss: 0.5477858781814575, Acc: 0.8125\n",
      "Epoch: 1281, Loss: 0.7299129962921143, Acc: 0.8125\n",
      "Epoch: 1282, Loss: 0.805469274520874, Acc: 0.71875\n",
      "Epoch: 1283, Loss: 0.8877957463264465, Acc: 0.71875\n",
      "Epoch: 1284, Loss: 1.235371708869934, Acc: 0.625\n",
      "Epoch: 1285, Loss: 0.6118874549865723, Acc: 0.78125\n",
      "Epoch: 1286, Loss: 0.8707536458969116, Acc: 0.75\n",
      "Epoch: 1287, Loss: 0.6160697937011719, Acc: 0.78125\n",
      "Epoch: 1288, Loss: 0.8213313817977905, Acc: 0.75\n",
      "Epoch: 1289, Loss: 0.7874264717102051, Acc: 0.78125\n",
      "Epoch: 1290, Loss: 0.8900158405303955, Acc: 0.6875\n",
      "Epoch: 1291, Loss: 0.6496738791465759, Acc: 0.875\n",
      "Epoch: 1292, Loss: 0.8347615599632263, Acc: 0.78125\n",
      "Epoch: 1293, Loss: 0.5443011522293091, Acc: 0.8125\n",
      "Epoch: 1294, Loss: 0.9167126417160034, Acc: 0.6875\n",
      "Epoch: 1295, Loss: 0.7213902473449707, Acc: 0.78125\n",
      "Epoch: 1296, Loss: 0.6775574684143066, Acc: 0.8125\n",
      "Epoch: 1297, Loss: 0.9415477514266968, Acc: 0.71875\n",
      "Epoch: 1298, Loss: 0.9039392471313477, Acc: 0.6875\n",
      "Epoch: 1299, Loss: 0.8961496353149414, Acc: 0.65625\n",
      "Epoch: 1300, Loss: 0.7538649439811707, Acc: 0.71875\n",
      "Epoch: 1301, Loss: 0.6943259239196777, Acc: 0.84375\n",
      "Epoch: 1302, Loss: 0.7403730154037476, Acc: 0.78125\n",
      "Epoch: 1303, Loss: 0.822214663028717, Acc: 0.78125\n",
      "Epoch: 1304, Loss: 0.9125935435295105, Acc: 0.6875\n",
      "Epoch: 1305, Loss: 0.9805409908294678, Acc: 0.625\n",
      "Epoch: 1306, Loss: 0.7461996674537659, Acc: 0.84375\n",
      "Epoch: 1307, Loss: 0.8596135973930359, Acc: 0.71875\n",
      "Epoch: 1308, Loss: 0.5505057573318481, Acc: 0.84375\n",
      "Epoch: 1309, Loss: 1.0605136156082153, Acc: 0.5625\n",
      "Epoch: 1310, Loss: 0.8565546870231628, Acc: 0.71875\n",
      "Epoch: 1311, Loss: 0.8708599805831909, Acc: 0.6875\n",
      "Epoch: 1312, Loss: 0.7206872701644897, Acc: 0.78125\n",
      "Epoch: 1313, Loss: 0.7127312421798706, Acc: 0.78125\n",
      "Epoch: 1314, Loss: 0.8507503867149353, Acc: 0.6875\n",
      "Epoch: 1315, Loss: 0.9566234946250916, Acc: 0.5625\n",
      "Epoch: 1316, Loss: 0.6484348177909851, Acc: 0.8125\n",
      "Epoch: 1317, Loss: 0.7413296103477478, Acc: 0.78125\n",
      "Epoch: 1318, Loss: 0.8303528428077698, Acc: 0.6875\n",
      "Epoch: 1319, Loss: 1.13724946975708, Acc: 0.59375\n",
      "Epoch: 1320, Loss: 0.6880233287811279, Acc: 0.84375\n",
      "Epoch: 1321, Loss: 0.9819201827049255, Acc: 0.71875\n",
      "Epoch: 1322, Loss: 1.5983752012252808, Acc: 0.5625\n",
      "Epoch: 1323, Loss: 0.7817279100418091, Acc: 0.71875\n",
      "Epoch: 1324, Loss: 0.8020077347755432, Acc: 0.65625\n",
      "Epoch: 1325, Loss: 0.6952773332595825, Acc: 0.78125\n",
      "Epoch: 1326, Loss: 0.7587333917617798, Acc: 0.78125\n",
      "Epoch: 1327, Loss: 1.0882854461669922, Acc: 0.71875\n",
      "Epoch: 1328, Loss: 0.8377631306648254, Acc: 0.59375\n",
      "Epoch: 1329, Loss: 0.8383427858352661, Acc: 0.71875\n",
      "Epoch: 1330, Loss: 0.9171267747879028, Acc: 0.65625\n",
      "Epoch: 1331, Loss: 0.809231698513031, Acc: 0.6875\n",
      "Epoch: 1332, Loss: 0.5109786987304688, Acc: 0.84375\n",
      "Epoch: 1333, Loss: 0.8808658719062805, Acc: 0.6875\n",
      "Epoch: 1334, Loss: 0.6998664736747742, Acc: 0.78125\n",
      "Epoch: 1335, Loss: 0.9084286689758301, Acc: 0.75\n",
      "Epoch: 1336, Loss: 0.8451501131057739, Acc: 0.75\n",
      "Epoch: 1337, Loss: 0.9494547247886658, Acc: 0.5625\n",
      "Epoch: 1338, Loss: 0.47081348299980164, Acc: 0.875\n",
      "Epoch: 1339, Loss: 0.8314326405525208, Acc: 0.78125\n",
      "Epoch: 1340, Loss: 0.532768726348877, Acc: 0.875\n",
      "Epoch: 1341, Loss: 0.8576101660728455, Acc: 0.6875\n",
      "Epoch: 1342, Loss: 0.6470118761062622, Acc: 0.875\n",
      "Epoch: 1343, Loss: 1.3390370607376099, Acc: 0.5625\n",
      "Epoch: 1344, Loss: 0.9845954775810242, Acc: 0.71875\n",
      "Epoch: 1345, Loss: 0.9951032996177673, Acc: 0.65625\n",
      "Epoch: 1346, Loss: 0.7116783261299133, Acc: 0.8125\n",
      "Epoch: 1347, Loss: 0.7773186564445496, Acc: 0.6875\n",
      "Epoch: 1348, Loss: 0.8048658967018127, Acc: 0.6875\n",
      "Epoch: 1349, Loss: 0.6829020977020264, Acc: 0.78125\n",
      "Epoch: 1350, Loss: 1.0493851900100708, Acc: 0.6875\n",
      "Epoch: 1351, Loss: 1.326022982597351, Acc: 0.625\n",
      "Epoch: 1352, Loss: 0.9804584383964539, Acc: 0.625\n",
      "Epoch: 1353, Loss: 1.0078531503677368, Acc: 0.71875\n",
      "Epoch: 1354, Loss: 0.5437216758728027, Acc: 0.875\n",
      "Epoch: 1355, Loss: 0.4287019968032837, Acc: 0.875\n",
      "Epoch: 1356, Loss: 0.7015944719314575, Acc: 0.71875\n",
      "Epoch: 1357, Loss: 0.5744696855545044, Acc: 0.78125\n",
      "Epoch: 1358, Loss: 0.6382982730865479, Acc: 0.84375\n",
      "Epoch: 1359, Loss: 0.8527742624282837, Acc: 0.71875\n",
      "Epoch: 1360, Loss: 1.0892921686172485, Acc: 0.65625\n",
      "Epoch: 1361, Loss: 1.2001826763153076, Acc: 0.75\n",
      "Epoch: 1362, Loss: 0.6662547588348389, Acc: 0.75\n",
      "Epoch: 1363, Loss: 1.16215980052948, Acc: 0.65625\n",
      "Epoch: 1364, Loss: 0.8624416589736938, Acc: 0.71875\n",
      "Epoch: 1365, Loss: 1.345916509628296, Acc: 0.53125\n",
      "Epoch: 1366, Loss: 0.9424698948860168, Acc: 0.6875\n",
      "Epoch: 1367, Loss: 0.8500668406486511, Acc: 0.71875\n",
      "Epoch: 1368, Loss: 0.8173660635948181, Acc: 0.625\n",
      "Epoch: 1369, Loss: 0.6025112867355347, Acc: 0.8125\n",
      "Epoch: 1370, Loss: 0.5826665759086609, Acc: 0.8125\n",
      "Epoch: 1371, Loss: 0.7426467537879944, Acc: 0.8125\n",
      "Epoch: 1372, Loss: 0.7563641667366028, Acc: 0.71875\n",
      "Epoch: 1373, Loss: 0.8837155699729919, Acc: 0.6875\n",
      "Epoch: 1374, Loss: 0.8377971649169922, Acc: 0.65625\n",
      "Epoch: 1375, Loss: 1.0958423614501953, Acc: 0.6875\n",
      "Epoch: 1376, Loss: 0.8316342234611511, Acc: 0.6875\n",
      "Epoch: 1377, Loss: 0.8336688280105591, Acc: 0.78125\n",
      "Epoch: 1378, Loss: 0.9103510975837708, Acc: 0.6875\n",
      "Epoch: 1379, Loss: 0.9533770680427551, Acc: 0.6875\n",
      "Epoch: 1380, Loss: 1.028414249420166, Acc: 0.6875\n",
      "Epoch: 1381, Loss: 0.9028120636940002, Acc: 0.75\n",
      "Epoch: 1382, Loss: 0.7977406978607178, Acc: 0.6875\n",
      "Epoch: 1383, Loss: 0.726439893245697, Acc: 0.78125\n",
      "Epoch: 1384, Loss: 1.3730453252792358, Acc: 0.5625\n",
      "Epoch: 1385, Loss: 0.722251832485199, Acc: 0.78125\n",
      "Epoch: 1386, Loss: 0.9877908825874329, Acc: 0.6875\n",
      "Epoch: 1387, Loss: 0.7544726133346558, Acc: 0.8125\n",
      "Epoch: 1388, Loss: 1.0526542663574219, Acc: 0.6875\n",
      "Epoch: 1389, Loss: 0.8776230216026306, Acc: 0.75\n",
      "Epoch: 1390, Loss: 0.9570079445838928, Acc: 0.6875\n",
      "Epoch: 1391, Loss: 0.8434110879898071, Acc: 0.71875\n",
      "Epoch: 1392, Loss: 0.5389818549156189, Acc: 0.8125\n",
      "Epoch: 1393, Loss: 0.630170464515686, Acc: 0.875\n",
      "Epoch: 1394, Loss: 1.0379862785339355, Acc: 0.6875\n",
      "Epoch: 1395, Loss: 0.7105229496955872, Acc: 0.75\n",
      "Epoch: 1396, Loss: 0.5528202652931213, Acc: 0.75\n",
      "Epoch: 1397, Loss: 0.6128057837486267, Acc: 0.84375\n",
      "Epoch: 1398, Loss: 1.0526800155639648, Acc: 0.53125\n",
      "Epoch: 1399, Loss: 0.7666967511177063, Acc: 0.75\n",
      "Epoch: 1400, Loss: 0.9296157956123352, Acc: 0.75\n",
      "Epoch: 1401, Loss: 0.6470605731010437, Acc: 0.8125\n",
      "Epoch: 1402, Loss: 0.7270261645317078, Acc: 0.71875\n",
      "Epoch: 1403, Loss: 0.7835959792137146, Acc: 0.75\n",
      "Epoch: 1404, Loss: 0.7508054375648499, Acc: 0.8125\n",
      "Epoch: 1405, Loss: 0.6290285587310791, Acc: 0.8125\n",
      "Epoch: 1406, Loss: 0.5022428631782532, Acc: 0.90625\n",
      "Epoch: 1407, Loss: 1.0292147397994995, Acc: 0.65625\n",
      "Epoch: 1408, Loss: 0.6256243586540222, Acc: 0.875\n",
      "Epoch: 1409, Loss: 1.0265262126922607, Acc: 0.6875\n",
      "Epoch: 1410, Loss: 0.905331015586853, Acc: 0.75\n",
      "Epoch: 1411, Loss: 0.8987990021705627, Acc: 0.65625\n",
      "Epoch: 1412, Loss: 0.6823058724403381, Acc: 0.8125\n",
      "Epoch: 1413, Loss: 0.8934816122055054, Acc: 0.65625\n",
      "Epoch: 1414, Loss: 0.8385958075523376, Acc: 0.75\n",
      "Epoch: 1415, Loss: 0.8523579835891724, Acc: 0.78125\n",
      "Epoch: 1416, Loss: 0.764538586139679, Acc: 0.65625\n",
      "Epoch: 1417, Loss: 0.9254077672958374, Acc: 0.625\n",
      "Epoch: 1418, Loss: 1.0392069816589355, Acc: 0.65625\n",
      "Epoch: 1419, Loss: 0.840895414352417, Acc: 0.71875\n",
      "Epoch: 1420, Loss: 0.6504325270652771, Acc: 0.875\n",
      "Epoch: 1421, Loss: 1.0009565353393555, Acc: 0.65625\n",
      "Epoch: 1422, Loss: 0.7466232180595398, Acc: 0.71875\n",
      "Epoch: 1423, Loss: 1.2300667762756348, Acc: 0.625\n",
      "Epoch: 1424, Loss: 0.7789003252983093, Acc: 0.75\n",
      "Epoch: 1425, Loss: 0.8796859979629517, Acc: 0.65625\n",
      "Epoch: 1426, Loss: 0.9914329648017883, Acc: 0.6875\n",
      "Epoch: 1427, Loss: 0.9638035297393799, Acc: 0.6875\n",
      "Epoch: 1428, Loss: 0.8883466124534607, Acc: 0.78125\n",
      "Epoch: 1429, Loss: 1.0271942615509033, Acc: 0.625\n",
      "Epoch: 1430, Loss: 0.5064986944198608, Acc: 0.9375\n",
      "Epoch: 1431, Loss: 0.7104623317718506, Acc: 0.84375\n",
      "Epoch: 1432, Loss: 0.8945066928863525, Acc: 0.6875\n",
      "Epoch: 1433, Loss: 0.5288569927215576, Acc: 0.9375\n",
      "Epoch: 1434, Loss: 0.6514660120010376, Acc: 0.8125\n",
      "Epoch: 1435, Loss: 0.7973042130470276, Acc: 0.75\n",
      "Epoch: 1436, Loss: 0.8376531600952148, Acc: 0.6875\n",
      "Epoch: 1437, Loss: 0.555160641670227, Acc: 0.84375\n",
      "Epoch: 1438, Loss: 0.7771995067596436, Acc: 0.75\n",
      "Epoch: 1439, Loss: 0.34118300676345825, Acc: 0.90625\n",
      "Epoch: 1440, Loss: 0.9058124423027039, Acc: 0.75\n",
      "Epoch: 1441, Loss: 0.7242047190666199, Acc: 0.84375\n",
      "Epoch: 1442, Loss: 0.8913434743881226, Acc: 0.6875\n",
      "Epoch: 1443, Loss: 1.0004829168319702, Acc: 0.65625\n",
      "Epoch: 1444, Loss: 0.7097189426422119, Acc: 0.78125\n",
      "Epoch: 1445, Loss: 1.027510643005371, Acc: 0.71875\n",
      "Epoch: 1446, Loss: 0.7900294065475464, Acc: 0.75\n",
      "Epoch: 1447, Loss: 0.6703283786773682, Acc: 0.78125\n",
      "Epoch: 1448, Loss: 1.1415079832077026, Acc: 0.625\n",
      "Epoch: 1449, Loss: 0.7775899171829224, Acc: 0.78125\n",
      "Epoch: 1450, Loss: 0.7224683165550232, Acc: 0.75\n",
      "Epoch: 1451, Loss: 0.8270093202590942, Acc: 0.65625\n",
      "Epoch: 1452, Loss: 0.6921972036361694, Acc: 0.75\n",
      "Epoch: 1453, Loss: 0.7870159149169922, Acc: 0.75\n",
      "Epoch: 1454, Loss: 0.814954400062561, Acc: 0.71875\n",
      "Epoch: 1455, Loss: 0.7961038947105408, Acc: 0.8125\n",
      "Epoch: 1456, Loss: 0.8811534643173218, Acc: 0.6875\n",
      "Epoch: 1457, Loss: 0.45375779271125793, Acc: 0.90625\n",
      "Epoch: 1458, Loss: 0.7698396444320679, Acc: 0.75\n",
      "Epoch: 1459, Loss: 0.4469970762729645, Acc: 0.90625\n",
      "Epoch: 1460, Loss: 0.910066545009613, Acc: 0.6875\n",
      "Epoch: 1461, Loss: 0.5275998115539551, Acc: 0.78125\n",
      "Epoch: 1462, Loss: 0.4821755290031433, Acc: 0.8125\n",
      "Epoch: 1463, Loss: 0.7047308087348938, Acc: 0.78125\n",
      "Epoch: 1464, Loss: 0.9638670086860657, Acc: 0.71875\n",
      "Epoch: 1465, Loss: 0.891462504863739, Acc: 0.6875\n",
      "Epoch: 1466, Loss: 0.6829058527946472, Acc: 0.75\n",
      "Epoch: 1467, Loss: 0.8312963247299194, Acc: 0.71875\n",
      "Epoch: 1468, Loss: 0.9092790484428406, Acc: 0.78125\n",
      "Epoch: 1469, Loss: 0.6973651051521301, Acc: 0.75\n",
      "Epoch: 1470, Loss: 0.5765253305435181, Acc: 0.8125\n",
      "Epoch: 1471, Loss: 0.9822509288787842, Acc: 0.625\n",
      "Epoch: 1472, Loss: 0.5455933213233948, Acc: 0.875\n",
      "Epoch: 1473, Loss: 0.7266852855682373, Acc: 0.78125\n",
      "Epoch: 1474, Loss: 0.8172553777694702, Acc: 0.71875\n",
      "Epoch: 1475, Loss: 1.5739707946777344, Acc: 0.59375\n",
      "Epoch: 1476, Loss: 0.6299616098403931, Acc: 0.84375\n",
      "Epoch: 1477, Loss: 0.8236064314842224, Acc: 0.6875\n",
      "Epoch: 1478, Loss: 0.912543535232544, Acc: 0.6875\n",
      "Epoch: 1479, Loss: 0.6275784969329834, Acc: 0.6875\n",
      "Epoch: 1480, Loss: 0.7496309876441956, Acc: 0.6875\n",
      "Epoch: 1481, Loss: 0.9221394658088684, Acc: 0.6875\n",
      "Epoch: 1482, Loss: 0.8456316590309143, Acc: 0.65625\n",
      "Epoch: 1483, Loss: 0.8631265759468079, Acc: 0.8125\n",
      "Epoch: 1484, Loss: 0.97939133644104, Acc: 0.625\n",
      "Epoch: 1485, Loss: 0.7542413473129272, Acc: 0.78125\n",
      "Epoch: 1486, Loss: 0.8755599856376648, Acc: 0.6875\n",
      "Epoch: 1487, Loss: 0.822904646396637, Acc: 0.6875\n",
      "Epoch: 1488, Loss: 0.8958479762077332, Acc: 0.6875\n",
      "Epoch: 1489, Loss: 0.8554503321647644, Acc: 0.75\n",
      "Epoch: 1490, Loss: 1.3177169561386108, Acc: 0.59375\n",
      "Epoch: 1491, Loss: 0.7931052446365356, Acc: 0.71875\n",
      "Epoch: 1492, Loss: 0.6515992879867554, Acc: 0.6875\n",
      "Epoch: 1493, Loss: 0.7690584659576416, Acc: 0.75\n",
      "Epoch: 1494, Loss: 0.8484934568405151, Acc: 0.875\n",
      "Epoch: 1495, Loss: 0.5495216250419617, Acc: 0.875\n",
      "Epoch: 1496, Loss: 1.0310251712799072, Acc: 0.6875\n",
      "Epoch: 1497, Loss: 1.047533631324768, Acc: 0.59375\n",
      "Epoch: 1498, Loss: 0.7607660889625549, Acc: 0.75\n",
      "Epoch: 1499, Loss: 0.744784414768219, Acc: 0.625\n",
      "Epoch: 1500, Loss: 1.0879430770874023, Acc: 0.71875\n",
      "Epoch: 1501, Loss: 0.6170501112937927, Acc: 0.8125\n",
      "Epoch: 1502, Loss: 0.7014715075492859, Acc: 0.78125\n",
      "Epoch: 1503, Loss: 0.9669157862663269, Acc: 0.6875\n",
      "Epoch: 1504, Loss: 0.8112807273864746, Acc: 0.75\n",
      "Epoch: 1505, Loss: 0.7604196667671204, Acc: 0.8125\n",
      "Epoch: 1506, Loss: 0.5699609518051147, Acc: 0.78125\n",
      "Epoch: 1507, Loss: 0.8171064853668213, Acc: 0.8125\n",
      "Epoch: 1508, Loss: 0.4562040865421295, Acc: 0.8125\n",
      "Epoch: 1509, Loss: 0.9282811284065247, Acc: 0.6875\n",
      "Epoch: 1510, Loss: 0.8296263813972473, Acc: 0.75\n",
      "Epoch: 1511, Loss: 0.6601949334144592, Acc: 0.75\n",
      "Epoch: 1512, Loss: 1.0941648483276367, Acc: 0.625\n",
      "Epoch: 1513, Loss: 0.8200539350509644, Acc: 0.6875\n",
      "Epoch: 1514, Loss: 1.1247674226760864, Acc: 0.6875\n",
      "Epoch: 1515, Loss: 0.9008374214172363, Acc: 0.65625\n",
      "Epoch: 1516, Loss: 0.9267380237579346, Acc: 0.6875\n",
      "Epoch: 1517, Loss: 0.9661117196083069, Acc: 0.6875\n",
      "Epoch: 1518, Loss: 0.923621654510498, Acc: 0.75\n",
      "Epoch: 1519, Loss: 0.883215069770813, Acc: 0.71875\n",
      "Epoch: 1520, Loss: 0.9479353427886963, Acc: 0.6875\n",
      "Epoch: 1521, Loss: 0.866858959197998, Acc: 0.71875\n",
      "Epoch: 1522, Loss: 0.8353254199028015, Acc: 0.65625\n",
      "Epoch: 1523, Loss: 0.9561668634414673, Acc: 0.75\n",
      "Epoch: 1524, Loss: 0.6448112726211548, Acc: 0.78125\n",
      "Epoch: 1525, Loss: 1.051952838897705, Acc: 0.65625\n",
      "Epoch: 1526, Loss: 0.5417595505714417, Acc: 0.75\n",
      "Epoch: 1527, Loss: 0.4848168194293976, Acc: 0.84375\n",
      "Epoch: 1528, Loss: 0.6422773599624634, Acc: 0.8125\n",
      "Epoch: 1529, Loss: 0.35760223865509033, Acc: 0.84375\n",
      "Epoch: 1530, Loss: 0.63015216588974, Acc: 0.78125\n",
      "Epoch: 1531, Loss: 0.5560337901115417, Acc: 0.8125\n",
      "Epoch: 1532, Loss: 0.6835219860076904, Acc: 0.78125\n",
      "Epoch: 1533, Loss: 0.6678488254547119, Acc: 0.75\n",
      "Epoch: 1534, Loss: 1.1590158939361572, Acc: 0.6875\n",
      "Epoch: 1535, Loss: 0.9986301064491272, Acc: 0.71875\n",
      "Epoch: 1536, Loss: 0.9542073607444763, Acc: 0.71875\n",
      "Epoch: 1537, Loss: 1.118042230606079, Acc: 0.6875\n",
      "Epoch: 1538, Loss: 0.8985604047775269, Acc: 0.75\n",
      "Epoch: 1539, Loss: 0.5950959324836731, Acc: 0.875\n",
      "Epoch: 1540, Loss: 0.5953533053398132, Acc: 0.84375\n",
      "Epoch: 1541, Loss: 0.8590444326400757, Acc: 0.75\n",
      "Epoch: 1542, Loss: 0.6124607920646667, Acc: 0.84375\n",
      "Epoch: 1543, Loss: 0.4276074767112732, Acc: 0.84375\n",
      "Epoch: 1544, Loss: 0.37030380964279175, Acc: 0.90625\n",
      "Epoch: 1545, Loss: 0.6772649884223938, Acc: 0.78125\n",
      "Epoch: 1546, Loss: 0.6760172843933105, Acc: 0.78125\n",
      "Epoch: 1547, Loss: 0.802316427230835, Acc: 0.71875\n",
      "Epoch: 1548, Loss: 0.8642780184745789, Acc: 0.625\n",
      "Epoch: 1549, Loss: 0.5817585587501526, Acc: 0.78125\n",
      "Epoch: 1550, Loss: 0.5351215600967407, Acc: 0.8125\n",
      "Epoch: 1551, Loss: 0.5815386772155762, Acc: 0.84375\n",
      "Epoch: 1552, Loss: 0.8910231590270996, Acc: 0.6875\n",
      "Epoch: 1553, Loss: 0.7787103652954102, Acc: 0.75\n",
      "Epoch: 1554, Loss: 0.8319057822227478, Acc: 0.78125\n",
      "Epoch: 1555, Loss: 0.5610423684120178, Acc: 0.8125\n",
      "Epoch: 1556, Loss: 0.9410898089408875, Acc: 0.65625\n",
      "Epoch: 1557, Loss: 0.7498073577880859, Acc: 0.6875\n",
      "Epoch: 1558, Loss: 1.0175681114196777, Acc: 0.5625\n",
      "Epoch: 1559, Loss: 1.1402262449264526, Acc: 0.71875\n",
      "Epoch: 1560, Loss: 0.7966718673706055, Acc: 0.71875\n",
      "Epoch: 1561, Loss: 0.6009092926979065, Acc: 0.8125\n",
      "Epoch: 1562, Loss: 0.7098849415779114, Acc: 0.75\n",
      "Epoch: 1563, Loss: 0.9253275394439697, Acc: 0.75\n",
      "Epoch: 1564, Loss: 1.038476586341858, Acc: 0.625\n",
      "Epoch: 1565, Loss: 1.0234224796295166, Acc: 0.65625\n",
      "Epoch: 1566, Loss: 0.8617804050445557, Acc: 0.78125\n",
      "Epoch: 1567, Loss: 0.5071226358413696, Acc: 0.9375\n",
      "Epoch: 1568, Loss: 0.8950247168540955, Acc: 0.75\n",
      "Epoch: 1569, Loss: 0.619452178478241, Acc: 0.84375\n",
      "Epoch: 1570, Loss: 0.6633989810943604, Acc: 0.71875\n",
      "Epoch: 1571, Loss: 0.6289910674095154, Acc: 0.8125\n",
      "Epoch: 1572, Loss: 0.9724433422088623, Acc: 0.6875\n",
      "Epoch: 1573, Loss: 0.6391143798828125, Acc: 0.84375\n",
      "Epoch: 1574, Loss: 0.7989736199378967, Acc: 0.71875\n",
      "Epoch: 1575, Loss: 0.7627097964286804, Acc: 0.78125\n",
      "Epoch: 1576, Loss: 0.8813190460205078, Acc: 0.75\n",
      "Epoch: 1577, Loss: 0.5677585601806641, Acc: 0.875\n",
      "Epoch: 1578, Loss: 0.6781206130981445, Acc: 0.8125\n",
      "Epoch: 1579, Loss: 0.8821213245391846, Acc: 0.6875\n",
      "Epoch: 1580, Loss: 1.071864366531372, Acc: 0.65625\n",
      "Epoch: 1581, Loss: 0.6403710246086121, Acc: 0.8125\n",
      "Epoch: 1582, Loss: 0.8995463848114014, Acc: 0.8125\n",
      "Epoch: 1583, Loss: 1.0157668590545654, Acc: 0.59375\n",
      "Epoch: 1584, Loss: 0.9869905710220337, Acc: 0.5625\n",
      "Epoch: 1585, Loss: 0.8741587996482849, Acc: 0.6875\n",
      "Epoch: 1586, Loss: 0.626379132270813, Acc: 0.8125\n",
      "Epoch: 1587, Loss: 0.7802836894989014, Acc: 0.78125\n",
      "Epoch: 1588, Loss: 0.8446001410484314, Acc: 0.6875\n",
      "Epoch: 1589, Loss: 0.8326773643493652, Acc: 0.71875\n",
      "Epoch: 1590, Loss: 0.5800095796585083, Acc: 0.71875\n",
      "Epoch: 1591, Loss: 0.8354427218437195, Acc: 0.6875\n",
      "Epoch: 1592, Loss: 0.823063850402832, Acc: 0.6875\n",
      "Epoch: 1593, Loss: 0.8400523066520691, Acc: 0.8125\n",
      "Epoch: 1594, Loss: 0.6797016859054565, Acc: 0.78125\n",
      "Epoch: 1595, Loss: 0.8593858480453491, Acc: 0.71875\n",
      "Epoch: 1596, Loss: 0.772909939289093, Acc: 0.78125\n",
      "Epoch: 1597, Loss: 0.5702641606330872, Acc: 0.8125\n",
      "Epoch: 1598, Loss: 0.9746944308280945, Acc: 0.75\n",
      "Epoch: 1599, Loss: 0.896286129951477, Acc: 0.6875\n",
      "Epoch: 1600, Loss: 0.8153557777404785, Acc: 0.71875\n",
      "Epoch: 1601, Loss: 0.9745275974273682, Acc: 0.59375\n",
      "Epoch: 1602, Loss: 0.6220022439956665, Acc: 0.8125\n",
      "Epoch: 1603, Loss: 0.8417134284973145, Acc: 0.75\n",
      "Epoch: 1604, Loss: 0.7198354601860046, Acc: 0.78125\n",
      "Epoch: 1605, Loss: 1.1818548440933228, Acc: 0.59375\n",
      "Epoch: 1606, Loss: 0.9439652562141418, Acc: 0.6875\n",
      "Epoch: 1607, Loss: 0.6718789339065552, Acc: 0.84375\n",
      "Epoch: 1608, Loss: 0.7355388402938843, Acc: 0.71875\n",
      "Epoch: 1609, Loss: 0.959039032459259, Acc: 0.65625\n",
      "Epoch: 1610, Loss: 0.9471815824508667, Acc: 0.71875\n",
      "Epoch: 1611, Loss: 0.7031948566436768, Acc: 0.71875\n",
      "Epoch: 1612, Loss: 0.808657705783844, Acc: 0.8125\n",
      "Epoch: 1613, Loss: 1.0362133979797363, Acc: 0.625\n",
      "Epoch: 1614, Loss: 0.45483556389808655, Acc: 0.875\n",
      "Epoch: 1615, Loss: 0.7945103049278259, Acc: 0.71875\n",
      "Epoch: 1616, Loss: 0.8511652946472168, Acc: 0.75\n",
      "Epoch: 1617, Loss: 0.5699285864830017, Acc: 0.8125\n",
      "Epoch: 1618, Loss: 0.7486952543258667, Acc: 0.75\n",
      "Epoch: 1619, Loss: 1.1256341934204102, Acc: 0.625\n",
      "Epoch: 1620, Loss: 0.5453319549560547, Acc: 0.78125\n",
      "Epoch: 1621, Loss: 1.2731201648712158, Acc: 0.53125\n",
      "Epoch: 1622, Loss: 1.1035454273223877, Acc: 0.71875\n",
      "Epoch: 1623, Loss: 0.7275233268737793, Acc: 0.78125\n",
      "Epoch: 1624, Loss: 1.066963791847229, Acc: 0.625\n",
      "Epoch: 1625, Loss: 0.5800377726554871, Acc: 0.90625\n",
      "Epoch: 1626, Loss: 0.7276394367218018, Acc: 0.75\n",
      "Epoch: 1627, Loss: 1.1341341733932495, Acc: 0.65625\n",
      "Epoch: 1628, Loss: 0.9987960457801819, Acc: 0.625\n",
      "Epoch: 1629, Loss: 0.7135132551193237, Acc: 0.8125\n",
      "Epoch: 1630, Loss: 0.9374653100967407, Acc: 0.65625\n",
      "Epoch: 1631, Loss: 0.5147876143455505, Acc: 0.84375\n",
      "Epoch: 1632, Loss: 1.037966012954712, Acc: 0.65625\n",
      "Epoch: 1633, Loss: 1.059632658958435, Acc: 0.75\n",
      "Epoch: 1634, Loss: 0.9531185626983643, Acc: 0.6875\n",
      "Epoch: 1635, Loss: 1.0673304796218872, Acc: 0.6875\n",
      "Epoch: 1636, Loss: 0.8322989344596863, Acc: 0.6875\n",
      "Epoch: 1637, Loss: 0.8983457088470459, Acc: 0.6875\n",
      "Epoch: 1638, Loss: 0.49230965971946716, Acc: 0.84375\n",
      "Epoch: 1639, Loss: 0.6795289516448975, Acc: 0.78125\n",
      "Epoch: 1640, Loss: 0.6904363036155701, Acc: 0.78125\n",
      "Epoch: 1641, Loss: 0.6813891530036926, Acc: 0.78125\n",
      "Epoch: 1642, Loss: 0.5488137006759644, Acc: 0.8125\n",
      "Epoch: 1643, Loss: 1.010170578956604, Acc: 0.75\n",
      "Epoch: 1644, Loss: 0.6786730289459229, Acc: 0.6875\n",
      "Epoch: 1645, Loss: 0.5384698510169983, Acc: 0.75\n",
      "Epoch: 1646, Loss: 0.7357603311538696, Acc: 0.6875\n",
      "Epoch: 1647, Loss: 0.6189532279968262, Acc: 0.75\n",
      "Epoch: 1648, Loss: 0.9796388149261475, Acc: 0.625\n",
      "Epoch: 1649, Loss: 0.6842894554138184, Acc: 0.71875\n",
      "Epoch: 1650, Loss: 0.7203373312950134, Acc: 0.8125\n",
      "Epoch: 1651, Loss: 0.9321231842041016, Acc: 0.71875\n",
      "Epoch: 1652, Loss: 0.6849326491355896, Acc: 0.78125\n",
      "Epoch: 1653, Loss: 0.7074002027511597, Acc: 0.625\n",
      "Epoch: 1654, Loss: 0.9504735469818115, Acc: 0.625\n",
      "Epoch: 1655, Loss: 0.6014608144760132, Acc: 0.84375\n",
      "Epoch: 1656, Loss: 0.7374467253684998, Acc: 0.71875\n",
      "Epoch: 1657, Loss: 0.563042163848877, Acc: 0.78125\n",
      "Epoch: 1658, Loss: 0.9777597784996033, Acc: 0.6875\n",
      "Epoch: 1659, Loss: 0.38641229271888733, Acc: 0.84375\n",
      "Epoch: 1660, Loss: 0.7742639780044556, Acc: 0.75\n",
      "Epoch: 1661, Loss: 0.8403359651565552, Acc: 0.75\n",
      "Epoch: 1662, Loss: 0.758787214756012, Acc: 0.875\n",
      "Epoch: 1663, Loss: 0.7329072952270508, Acc: 0.71875\n",
      "Epoch: 1664, Loss: 1.0046087503433228, Acc: 0.6875\n",
      "Epoch: 1665, Loss: 0.7247423529624939, Acc: 0.84375\n",
      "Epoch: 1666, Loss: 0.7989272475242615, Acc: 0.71875\n",
      "Epoch: 1667, Loss: 0.5579602718353271, Acc: 0.84375\n",
      "Epoch: 1668, Loss: 0.5151764750480652, Acc: 0.84375\n",
      "Epoch: 1669, Loss: 0.7956018447875977, Acc: 0.6875\n",
      "Epoch: 1670, Loss: 0.8305555582046509, Acc: 0.71875\n",
      "Epoch: 1671, Loss: 0.7508587837219238, Acc: 0.78125\n",
      "Epoch: 1672, Loss: 0.654240608215332, Acc: 0.84375\n",
      "Epoch: 1673, Loss: 0.7561807632446289, Acc: 0.71875\n",
      "Epoch: 1674, Loss: 0.991756021976471, Acc: 0.625\n",
      "Epoch: 1675, Loss: 1.135131597518921, Acc: 0.59375\n",
      "Epoch: 1676, Loss: 0.9173627495765686, Acc: 0.65625\n",
      "Epoch: 1677, Loss: 0.7385028600692749, Acc: 0.71875\n",
      "Epoch: 1678, Loss: 0.6722984313964844, Acc: 0.78125\n",
      "Epoch: 1679, Loss: 0.6921062469482422, Acc: 0.875\n",
      "Epoch: 1680, Loss: 0.6334458589553833, Acc: 0.8125\n",
      "Epoch: 1681, Loss: 0.39997297525405884, Acc: 0.90625\n",
      "Epoch: 1682, Loss: 0.5931275486946106, Acc: 0.78125\n",
      "Epoch: 1683, Loss: 0.933323085308075, Acc: 0.71875\n",
      "Epoch: 1684, Loss: 0.6224967241287231, Acc: 0.65625\n",
      "Epoch: 1685, Loss: 0.718338668346405, Acc: 0.75\n",
      "Epoch: 1686, Loss: 0.7978746294975281, Acc: 0.78125\n",
      "Epoch: 1687, Loss: 0.6331117153167725, Acc: 0.78125\n",
      "Epoch: 1688, Loss: 0.6656565070152283, Acc: 0.71875\n",
      "Epoch: 1689, Loss: 0.6838436722755432, Acc: 0.8125\n",
      "Epoch: 1690, Loss: 0.7291942238807678, Acc: 0.75\n",
      "Epoch: 1691, Loss: 1.05026113986969, Acc: 0.625\n",
      "Epoch: 1692, Loss: 0.441841185092926, Acc: 0.875\n",
      "Epoch: 1693, Loss: 0.9740975499153137, Acc: 0.75\n",
      "Epoch: 1694, Loss: 0.6618395447731018, Acc: 0.8125\n",
      "Epoch: 1695, Loss: 0.5026870369911194, Acc: 0.78125\n",
      "Epoch: 1696, Loss: 0.6281367540359497, Acc: 0.78125\n",
      "Epoch: 1697, Loss: 1.175112247467041, Acc: 0.65625\n",
      "Epoch: 1698, Loss: 0.8126741051673889, Acc: 0.71875\n",
      "Epoch: 1699, Loss: 0.7483649849891663, Acc: 0.71875\n",
      "Epoch: 1700, Loss: 1.0735867023468018, Acc: 0.6875\n",
      "Epoch: 1701, Loss: 0.9987149238586426, Acc: 0.6875\n",
      "Epoch: 1702, Loss: 0.7486750483512878, Acc: 0.8125\n",
      "Epoch: 1703, Loss: 0.7652636170387268, Acc: 0.8125\n",
      "Epoch: 1704, Loss: 0.622133731842041, Acc: 0.71875\n",
      "Epoch: 1705, Loss: 0.672968864440918, Acc: 0.71875\n",
      "Epoch: 1706, Loss: 0.8857336640357971, Acc: 0.75\n",
      "Epoch: 1707, Loss: 0.8699731230735779, Acc: 0.75\n",
      "Epoch: 1708, Loss: 0.6635388135910034, Acc: 0.8125\n",
      "Epoch: 1709, Loss: 0.7520653605461121, Acc: 0.75\n",
      "Epoch: 1710, Loss: 0.6607024669647217, Acc: 0.75\n",
      "Epoch: 1711, Loss: 0.530785083770752, Acc: 0.84375\n",
      "Epoch: 1712, Loss: 0.8655741810798645, Acc: 0.75\n",
      "Epoch: 1713, Loss: 0.7243049144744873, Acc: 0.84375\n",
      "Epoch: 1714, Loss: 0.9235286712646484, Acc: 0.59375\n",
      "Epoch: 1715, Loss: 1.0532478094100952, Acc: 0.65625\n",
      "Epoch: 1716, Loss: 0.7418286204338074, Acc: 0.71875\n",
      "Epoch: 1717, Loss: 0.7338235974311829, Acc: 0.78125\n",
      "Epoch: 1718, Loss: 0.4442497491836548, Acc: 0.84375\n",
      "Epoch: 1719, Loss: 0.8668777346611023, Acc: 0.75\n",
      "Epoch: 1720, Loss: 0.6842159032821655, Acc: 0.75\n",
      "Epoch: 1721, Loss: 0.6222115755081177, Acc: 0.78125\n",
      "Epoch: 1722, Loss: 0.6957741379737854, Acc: 0.8125\n",
      "Epoch: 1723, Loss: 0.5213027000427246, Acc: 0.75\n",
      "Epoch: 1724, Loss: 0.5893716812133789, Acc: 0.84375\n",
      "Epoch: 1725, Loss: 0.73207688331604, Acc: 0.71875\n",
      "Epoch: 1726, Loss: 0.5152974128723145, Acc: 0.90625\n",
      "Epoch: 1727, Loss: 0.3915829360485077, Acc: 0.9375\n",
      "Epoch: 1728, Loss: 0.5770906209945679, Acc: 0.8125\n",
      "Epoch: 1729, Loss: 0.590110182762146, Acc: 0.75\n",
      "Epoch: 1730, Loss: 0.5584153532981873, Acc: 0.78125\n",
      "Epoch: 1731, Loss: 0.7922801375389099, Acc: 0.8125\n",
      "Epoch: 1732, Loss: 0.73014897108078, Acc: 0.75\n",
      "Epoch: 1733, Loss: 0.7652300596237183, Acc: 0.6875\n",
      "Epoch: 1734, Loss: 0.552594006061554, Acc: 0.875\n",
      "Epoch: 1735, Loss: 0.8543599247932434, Acc: 0.6875\n",
      "Epoch: 1736, Loss: 0.6806798577308655, Acc: 0.71875\n",
      "Epoch: 1737, Loss: 0.6694415211677551, Acc: 0.71875\n",
      "Epoch: 1738, Loss: 0.5798417925834656, Acc: 0.875\n",
      "Epoch: 1739, Loss: 0.9958903789520264, Acc: 0.6875\n",
      "Epoch: 1740, Loss: 0.4337354898452759, Acc: 0.84375\n",
      "Epoch: 1741, Loss: 0.6665310263633728, Acc: 0.75\n",
      "Epoch: 1742, Loss: 0.914907693862915, Acc: 0.625\n",
      "Epoch: 1743, Loss: 0.6183800101280212, Acc: 0.6875\n",
      "Epoch: 1744, Loss: 0.5533047318458557, Acc: 0.84375\n",
      "Epoch: 1745, Loss: 0.7866121530532837, Acc: 0.78125\n",
      "Epoch: 1746, Loss: 0.6324801445007324, Acc: 0.78125\n",
      "Epoch: 1747, Loss: 0.6513755917549133, Acc: 0.84375\n",
      "Epoch: 1748, Loss: 0.7277827262878418, Acc: 0.75\n",
      "Epoch: 1749, Loss: 0.5393815636634827, Acc: 0.84375\n",
      "Epoch: 1750, Loss: 0.6749434471130371, Acc: 0.8125\n",
      "Epoch: 1751, Loss: 0.983547031879425, Acc: 0.71875\n",
      "Epoch: 1752, Loss: 0.757490873336792, Acc: 0.6875\n",
      "Epoch: 1753, Loss: 0.5294482707977295, Acc: 0.75\n",
      "Epoch: 1754, Loss: 0.984060525894165, Acc: 0.6875\n",
      "Epoch: 1755, Loss: 0.5091478824615479, Acc: 0.875\n",
      "Epoch: 1756, Loss: 0.7074387669563293, Acc: 0.8125\n",
      "Epoch: 1757, Loss: 1.0436078310012817, Acc: 0.78125\n",
      "Epoch: 1758, Loss: 0.5970863699913025, Acc: 0.90625\n",
      "Epoch: 1759, Loss: 0.7863447070121765, Acc: 0.78125\n",
      "Epoch: 1760, Loss: 0.577082097530365, Acc: 0.84375\n",
      "Epoch: 1761, Loss: 0.8124373555183411, Acc: 0.65625\n",
      "Epoch: 1762, Loss: 1.0004656314849854, Acc: 0.75\n",
      "Epoch: 1763, Loss: 0.9787313938140869, Acc: 0.65625\n",
      "Epoch: 1764, Loss: 0.44291752576828003, Acc: 0.875\n",
      "Epoch: 1765, Loss: 1.1058908700942993, Acc: 0.53125\n",
      "Epoch: 1766, Loss: 0.569697916507721, Acc: 0.75\n",
      "Epoch: 1767, Loss: 0.5872542858123779, Acc: 0.75\n",
      "Epoch: 1768, Loss: 0.34308508038520813, Acc: 0.84375\n",
      "Epoch: 1769, Loss: 0.9151232838630676, Acc: 0.71875\n",
      "Epoch: 1770, Loss: 0.6738539338111877, Acc: 0.78125\n",
      "Epoch: 1771, Loss: 0.5549072027206421, Acc: 0.8125\n",
      "Epoch: 1772, Loss: 0.9280310273170471, Acc: 0.59375\n",
      "Epoch: 1773, Loss: 0.9426109790802002, Acc: 0.6875\n",
      "Epoch: 1774, Loss: 0.49079635739326477, Acc: 0.84375\n",
      "Epoch: 1775, Loss: 0.37741217017173767, Acc: 0.875\n",
      "Epoch: 1776, Loss: 0.3645241856575012, Acc: 0.90625\n",
      "Epoch: 1777, Loss: 0.6360457539558411, Acc: 0.875\n",
      "Epoch: 1778, Loss: 0.5222569704055786, Acc: 0.84375\n",
      "Epoch: 1779, Loss: 0.9421576261520386, Acc: 0.625\n",
      "Epoch: 1780, Loss: 1.0300960540771484, Acc: 0.625\n",
      "Epoch: 1781, Loss: 0.8573578000068665, Acc: 0.6875\n",
      "Epoch: 1782, Loss: 0.6300808191299438, Acc: 0.78125\n",
      "Epoch: 1783, Loss: 0.6898793578147888, Acc: 0.71875\n",
      "Epoch: 1784, Loss: 1.2012231349945068, Acc: 0.71875\n",
      "Epoch: 1785, Loss: 0.8813583850860596, Acc: 0.71875\n",
      "Epoch: 1786, Loss: 0.748640239238739, Acc: 0.8125\n",
      "Epoch: 1787, Loss: 0.6994962692260742, Acc: 0.8125\n",
      "Epoch: 1788, Loss: 0.9710814356803894, Acc: 0.6875\n",
      "Epoch: 1789, Loss: 0.4416789412498474, Acc: 0.90625\n",
      "Epoch: 1790, Loss: 0.6255213618278503, Acc: 0.75\n",
      "Epoch: 1791, Loss: 0.9113146662712097, Acc: 0.6875\n",
      "Epoch: 1792, Loss: 0.6472957134246826, Acc: 0.78125\n",
      "Epoch: 1793, Loss: 0.5513535141944885, Acc: 0.84375\n",
      "Epoch: 1794, Loss: 1.0977898836135864, Acc: 0.625\n",
      "Epoch: 1795, Loss: 0.7165604829788208, Acc: 0.8125\n",
      "Epoch: 1796, Loss: 0.7371265292167664, Acc: 0.78125\n",
      "Epoch: 1797, Loss: 0.7771909236907959, Acc: 0.75\n",
      "Epoch: 1798, Loss: 0.9551471471786499, Acc: 0.6875\n",
      "Epoch: 1799, Loss: 0.872768223285675, Acc: 0.65625\n",
      "Epoch: 1800, Loss: 0.5435434579849243, Acc: 0.8125\n",
      "Epoch: 1801, Loss: 0.5166817903518677, Acc: 0.875\n",
      "Epoch: 1802, Loss: 1.1294645071029663, Acc: 0.5625\n",
      "Epoch: 1803, Loss: 0.5989391803741455, Acc: 0.8125\n",
      "Epoch: 1804, Loss: 0.613835871219635, Acc: 0.75\n",
      "Epoch: 1805, Loss: 1.0027369260787964, Acc: 0.71875\n",
      "Epoch: 1806, Loss: 0.39604783058166504, Acc: 0.90625\n",
      "Epoch: 1807, Loss: 0.6516991257667542, Acc: 0.78125\n",
      "Epoch: 1808, Loss: 0.7205277681350708, Acc: 0.71875\n",
      "Epoch: 1809, Loss: 0.9828163385391235, Acc: 0.65625\n",
      "Epoch: 1810, Loss: 0.5753877758979797, Acc: 0.75\n",
      "Epoch: 1811, Loss: 0.5930772423744202, Acc: 0.71875\n",
      "Epoch: 1812, Loss: 0.630379319190979, Acc: 0.78125\n",
      "Epoch: 1813, Loss: 0.6334702372550964, Acc: 0.71875\n",
      "Epoch: 1814, Loss: 0.5780230760574341, Acc: 0.84375\n",
      "Epoch: 1815, Loss: 0.6923208832740784, Acc: 0.78125\n",
      "Epoch: 1816, Loss: 0.5746617913246155, Acc: 0.75\n",
      "Epoch: 1817, Loss: 0.4876217246055603, Acc: 0.84375\n",
      "Epoch: 1818, Loss: 1.0023659467697144, Acc: 0.65625\n",
      "Epoch: 1819, Loss: 0.8136366009712219, Acc: 0.75\n",
      "Epoch: 1820, Loss: 0.7165851593017578, Acc: 0.71875\n",
      "Epoch: 1821, Loss: 0.7921450734138489, Acc: 0.84375\n",
      "Epoch: 1822, Loss: 0.5847066640853882, Acc: 0.75\n",
      "Epoch: 1823, Loss: 0.5890888571739197, Acc: 0.84375\n",
      "Epoch: 1824, Loss: 0.5482566952705383, Acc: 0.84375\n",
      "Epoch: 1825, Loss: 0.5580974817276001, Acc: 0.8125\n",
      "Epoch: 1826, Loss: 0.6200100779533386, Acc: 0.84375\n",
      "Epoch: 1827, Loss: 0.8699304461479187, Acc: 0.75\n",
      "Epoch: 1828, Loss: 0.6056848764419556, Acc: 0.8125\n",
      "Epoch: 1829, Loss: 0.7251313328742981, Acc: 0.71875\n",
      "Epoch: 1830, Loss: 0.4305000305175781, Acc: 0.78125\n",
      "Epoch: 1831, Loss: 0.822364091873169, Acc: 0.75\n",
      "Epoch: 1832, Loss: 0.6102307438850403, Acc: 0.84375\n",
      "Epoch: 1833, Loss: 0.278323233127594, Acc: 0.9375\n",
      "Epoch: 1834, Loss: 0.7239167094230652, Acc: 0.71875\n",
      "Epoch: 1835, Loss: 0.6809031367301941, Acc: 0.78125\n",
      "Epoch: 1836, Loss: 0.4769620895385742, Acc: 0.875\n",
      "Epoch: 1837, Loss: 0.5534888505935669, Acc: 0.84375\n",
      "Epoch: 1838, Loss: 0.7306792736053467, Acc: 0.6875\n",
      "Epoch: 1839, Loss: 0.5148165822029114, Acc: 0.8125\n",
      "Epoch: 1840, Loss: 0.8518669605255127, Acc: 0.78125\n",
      "Epoch: 1841, Loss: 0.6300448179244995, Acc: 0.8125\n",
      "Epoch: 1842, Loss: 0.5767959952354431, Acc: 0.84375\n",
      "Epoch: 1843, Loss: 0.6758381724357605, Acc: 0.8125\n",
      "Epoch: 1844, Loss: 0.9032937288284302, Acc: 0.6875\n",
      "Epoch: 1845, Loss: 0.6879662275314331, Acc: 0.8125\n",
      "Epoch: 1846, Loss: 1.0105947256088257, Acc: 0.65625\n",
      "Epoch: 1847, Loss: 0.6998640298843384, Acc: 0.78125\n",
      "Epoch: 1848, Loss: 0.8048117756843567, Acc: 0.75\n",
      "Epoch: 1849, Loss: 0.9351767897605896, Acc: 0.71875\n",
      "Epoch: 1850, Loss: 0.883912205696106, Acc: 0.71875\n",
      "Epoch: 1851, Loss: 0.6170991659164429, Acc: 0.75\n",
      "Epoch: 1852, Loss: 1.1099532842636108, Acc: 0.6875\n",
      "Epoch: 1853, Loss: 0.48771724104881287, Acc: 0.78125\n",
      "Epoch: 1854, Loss: 0.642819344997406, Acc: 0.8125\n",
      "Epoch: 1855, Loss: 0.9716365933418274, Acc: 0.625\n",
      "Epoch: 1856, Loss: 0.7988000512123108, Acc: 0.75\n",
      "Epoch: 1857, Loss: 0.937079906463623, Acc: 0.75\n",
      "Epoch: 1858, Loss: 0.4725128710269928, Acc: 0.8125\n",
      "Epoch: 1859, Loss: 0.35719308257102966, Acc: 0.96875\n",
      "Epoch: 1860, Loss: 0.5986852049827576, Acc: 0.8125\n",
      "Epoch: 1861, Loss: 0.8958238959312439, Acc: 0.78125\n",
      "Epoch: 1862, Loss: 0.6622985005378723, Acc: 0.78125\n",
      "Epoch: 1863, Loss: 0.4461868405342102, Acc: 0.90625\n",
      "Epoch: 1864, Loss: 0.8004165887832642, Acc: 0.71875\n",
      "Epoch: 1865, Loss: 0.7041746377944946, Acc: 0.78125\n",
      "Epoch: 1866, Loss: 0.41164061427116394, Acc: 0.84375\n",
      "Epoch: 1867, Loss: 0.6590597629547119, Acc: 0.8125\n",
      "Epoch: 1868, Loss: 0.715972363948822, Acc: 0.71875\n",
      "Epoch: 1869, Loss: 0.6968366503715515, Acc: 0.8125\n",
      "Epoch: 1870, Loss: 1.1310371160507202, Acc: 0.6875\n",
      "Epoch: 1871, Loss: 0.8081397414207458, Acc: 0.6875\n",
      "Epoch: 1872, Loss: 1.3652507066726685, Acc: 0.5625\n",
      "Epoch: 1873, Loss: 0.6839286684989929, Acc: 0.75\n",
      "Epoch: 1874, Loss: 0.7321302890777588, Acc: 0.71875\n",
      "Epoch: 1875, Loss: 0.6727004051208496, Acc: 0.78125\n",
      "Epoch: 1876, Loss: 0.5742893815040588, Acc: 0.875\n",
      "Epoch: 1877, Loss: 0.6087393164634705, Acc: 0.75\n",
      "Epoch: 1878, Loss: 0.580629825592041, Acc: 0.78125\n",
      "Epoch: 1879, Loss: 0.7150883078575134, Acc: 0.71875\n",
      "Epoch: 1880, Loss: 0.6579245328903198, Acc: 0.71875\n",
      "Epoch: 1881, Loss: 0.5362442135810852, Acc: 0.78125\n",
      "Epoch: 1882, Loss: 0.9940937757492065, Acc: 0.6875\n",
      "Epoch: 1883, Loss: 0.7926342487335205, Acc: 0.75\n",
      "Epoch: 1884, Loss: 0.641835629940033, Acc: 0.84375\n",
      "Epoch: 1885, Loss: 0.9060789346694946, Acc: 0.6875\n",
      "Epoch: 1886, Loss: 0.8579928874969482, Acc: 0.65625\n",
      "Epoch: 1887, Loss: 0.8897068500518799, Acc: 0.75\n",
      "Epoch: 1888, Loss: 0.6161006689071655, Acc: 0.84375\n",
      "Epoch: 1889, Loss: 0.9041503667831421, Acc: 0.6875\n",
      "Epoch: 1890, Loss: 0.945264458656311, Acc: 0.625\n",
      "Epoch: 1891, Loss: 0.44219714403152466, Acc: 0.8125\n",
      "Epoch: 1892, Loss: 0.8120783567428589, Acc: 0.78125\n",
      "Epoch: 1893, Loss: 0.35644465684890747, Acc: 0.875\n",
      "Epoch: 1894, Loss: 0.4022141396999359, Acc: 0.90625\n",
      "Epoch: 1895, Loss: 0.5853271484375, Acc: 0.78125\n",
      "Epoch: 1896, Loss: 1.0366265773773193, Acc: 0.6875\n",
      "Epoch: 1897, Loss: 0.6902098059654236, Acc: 0.84375\n",
      "Epoch: 1898, Loss: 0.8503549098968506, Acc: 0.78125\n",
      "Epoch: 1899, Loss: 0.5970622897148132, Acc: 0.78125\n",
      "Epoch: 1900, Loss: 0.8725352883338928, Acc: 0.6875\n",
      "Epoch: 1901, Loss: 0.5111566781997681, Acc: 0.8125\n",
      "Epoch: 1902, Loss: 0.685483992099762, Acc: 0.75\n",
      "Epoch: 1903, Loss: 0.8813844323158264, Acc: 0.65625\n",
      "Epoch: 1904, Loss: 0.9105835556983948, Acc: 0.75\n",
      "Epoch: 1905, Loss: 0.8744078874588013, Acc: 0.65625\n",
      "Epoch: 1906, Loss: 0.6503945589065552, Acc: 0.78125\n",
      "Epoch: 1907, Loss: 0.6427210569381714, Acc: 0.8125\n",
      "Epoch: 1908, Loss: 0.5299707055091858, Acc: 0.84375\n",
      "Epoch: 1909, Loss: 0.6380598545074463, Acc: 0.8125\n",
      "Epoch: 1910, Loss: 0.9804529547691345, Acc: 0.65625\n",
      "Epoch: 1911, Loss: 0.5388613939285278, Acc: 0.78125\n",
      "Epoch: 1912, Loss: 0.7202869057655334, Acc: 0.75\n",
      "Epoch: 1913, Loss: 0.8426936268806458, Acc: 0.71875\n",
      "Epoch: 1914, Loss: 0.861148476600647, Acc: 0.75\n",
      "Epoch: 1915, Loss: 0.9040745496749878, Acc: 0.71875\n",
      "Epoch: 1916, Loss: 0.6596924066543579, Acc: 0.8125\n",
      "Epoch: 1917, Loss: 0.6892333626747131, Acc: 0.75\n",
      "Epoch: 1918, Loss: 1.1341416835784912, Acc: 0.71875\n",
      "Epoch: 1919, Loss: 0.6595790386199951, Acc: 0.8125\n",
      "Epoch: 1920, Loss: 0.8359412550926208, Acc: 0.75\n",
      "Epoch: 1921, Loss: 1.2016122341156006, Acc: 0.625\n",
      "Epoch: 1922, Loss: 0.6643325686454773, Acc: 0.75\n",
      "Epoch: 1923, Loss: 0.869097888469696, Acc: 0.71875\n",
      "Epoch: 1924, Loss: 0.5481307506561279, Acc: 0.8125\n",
      "Epoch: 1925, Loss: 0.9694246649742126, Acc: 0.65625\n",
      "Epoch: 1926, Loss: 0.42734870314598083, Acc: 0.875\n",
      "Epoch: 1927, Loss: 0.7775964140892029, Acc: 0.78125\n",
      "Epoch: 1928, Loss: 1.0080252885818481, Acc: 0.6875\n",
      "Epoch: 1929, Loss: 0.8339858055114746, Acc: 0.78125\n",
      "Epoch: 1930, Loss: 0.7622247934341431, Acc: 0.71875\n",
      "Epoch: 1931, Loss: 0.712837815284729, Acc: 0.75\n",
      "Epoch: 1932, Loss: 0.3728044033050537, Acc: 0.875\n",
      "Epoch: 1933, Loss: 1.0112178325653076, Acc: 0.65625\n",
      "Epoch: 1934, Loss: 0.5520368218421936, Acc: 0.75\n",
      "Epoch: 1935, Loss: 1.0050973892211914, Acc: 0.65625\n",
      "Epoch: 1936, Loss: 0.7033664584159851, Acc: 0.78125\n",
      "Epoch: 1937, Loss: 0.5912564992904663, Acc: 0.84375\n",
      "Epoch: 1938, Loss: 0.5844355821609497, Acc: 0.8125\n",
      "Epoch: 1939, Loss: 0.7603731751441956, Acc: 0.65625\n",
      "Epoch: 1940, Loss: 0.8995212912559509, Acc: 0.71875\n",
      "Epoch: 1941, Loss: 0.8448789119720459, Acc: 0.75\n",
      "Epoch: 1942, Loss: 0.8133070468902588, Acc: 0.71875\n",
      "Epoch: 1943, Loss: 0.8352092504501343, Acc: 0.75\n",
      "Epoch: 1944, Loss: 0.616174578666687, Acc: 0.78125\n",
      "Epoch: 1945, Loss: 0.6758068799972534, Acc: 0.8125\n",
      "Epoch: 1946, Loss: 0.8730087876319885, Acc: 0.75\n",
      "Epoch: 1947, Loss: 0.8290148377418518, Acc: 0.6875\n",
      "Epoch: 1948, Loss: 0.48834311962127686, Acc: 0.8125\n",
      "Epoch: 1949, Loss: 0.48472458124160767, Acc: 0.8125\n",
      "Epoch: 1950, Loss: 0.4666847288608551, Acc: 0.8125\n",
      "Epoch: 1951, Loss: 0.5384454727172852, Acc: 0.8125\n",
      "Epoch: 1952, Loss: 0.7048377990722656, Acc: 0.8125\n",
      "Epoch: 1953, Loss: 0.6372491717338562, Acc: 0.6875\n",
      "Epoch: 1954, Loss: 0.33234745264053345, Acc: 0.90625\n",
      "Epoch: 1955, Loss: 0.7554965019226074, Acc: 0.84375\n",
      "Epoch: 1956, Loss: 0.5706592798233032, Acc: 0.84375\n",
      "Epoch: 1957, Loss: 0.9227648377418518, Acc: 0.71875\n",
      "Epoch: 1958, Loss: 1.0131304264068604, Acc: 0.78125\n",
      "Epoch: 1959, Loss: 0.859586775302887, Acc: 0.65625\n",
      "Epoch: 1960, Loss: 0.7402240633964539, Acc: 0.65625\n",
      "Epoch: 1961, Loss: 0.8714808821678162, Acc: 0.71875\n",
      "Epoch: 1962, Loss: 0.7378765940666199, Acc: 0.71875\n",
      "Epoch: 1963, Loss: 0.6814018487930298, Acc: 0.84375\n",
      "Epoch: 1964, Loss: 1.1850345134735107, Acc: 0.625\n",
      "Epoch: 1965, Loss: 0.4343704581260681, Acc: 0.84375\n",
      "Epoch: 1966, Loss: 0.6840895414352417, Acc: 0.8125\n",
      "Epoch: 1967, Loss: 0.693225085735321, Acc: 0.71875\n",
      "Epoch: 1968, Loss: 0.7057000398635864, Acc: 0.8125\n",
      "Epoch: 1969, Loss: 0.7975515723228455, Acc: 0.84375\n",
      "Epoch: 1970, Loss: 0.7932652235031128, Acc: 0.8125\n",
      "Epoch: 1971, Loss: 0.45384079217910767, Acc: 0.84375\n",
      "Epoch: 1972, Loss: 0.7540620565414429, Acc: 0.71875\n",
      "Epoch: 1973, Loss: 0.5491954684257507, Acc: 0.78125\n",
      "Epoch: 1974, Loss: 0.8029869198799133, Acc: 0.78125\n",
      "Epoch: 1975, Loss: 0.7411792874336243, Acc: 0.75\n",
      "Epoch: 1976, Loss: 0.8440621495246887, Acc: 0.6875\n",
      "Epoch: 1977, Loss: 0.5526595711708069, Acc: 0.875\n",
      "Epoch: 1978, Loss: 0.8228087425231934, Acc: 0.75\n",
      "Epoch: 1979, Loss: 0.4654192328453064, Acc: 0.875\n",
      "Epoch: 1980, Loss: 0.8107194900512695, Acc: 0.8125\n",
      "Epoch: 1981, Loss: 0.9052233099937439, Acc: 0.6875\n",
      "Epoch: 1982, Loss: 0.4571855366230011, Acc: 0.84375\n",
      "Epoch: 1983, Loss: 0.7122890949249268, Acc: 0.75\n",
      "Epoch: 1984, Loss: 0.9720643758773804, Acc: 0.6875\n",
      "Epoch: 1985, Loss: 0.5378960371017456, Acc: 0.875\n",
      "Epoch: 1986, Loss: 0.41963428258895874, Acc: 0.78125\n",
      "Epoch: 1987, Loss: 0.49207770824432373, Acc: 0.875\n",
      "Epoch: 1988, Loss: 0.3261820077896118, Acc: 0.875\n",
      "Epoch: 1989, Loss: 0.49391239881515503, Acc: 0.875\n",
      "Epoch: 1990, Loss: 0.6234719157218933, Acc: 0.78125\n",
      "Epoch: 1991, Loss: 0.8986515402793884, Acc: 0.78125\n",
      "Epoch: 1992, Loss: 0.5104532837867737, Acc: 0.78125\n",
      "Epoch: 1993, Loss: 0.7618533968925476, Acc: 0.75\n",
      "Epoch: 1994, Loss: 0.5736469030380249, Acc: 0.8125\n",
      "Epoch: 1995, Loss: 0.5259406566619873, Acc: 0.84375\n",
      "Epoch: 1996, Loss: 0.9929027557373047, Acc: 0.71875\n",
      "Epoch: 1997, Loss: 0.42840343713760376, Acc: 0.84375\n",
      "Epoch: 1998, Loss: 0.5101388096809387, Acc: 0.84375\n",
      "Epoch: 1999, Loss: 0.3812524676322937, Acc: 0.875\n",
      "Epoch: 2000, Loss: 0.7912122011184692, Acc: 0.71875\n",
      "Epoch: 2001, Loss: 0.5483922958374023, Acc: 0.78125\n",
      "Epoch: 2002, Loss: 0.7642487287521362, Acc: 0.78125\n",
      "Epoch: 2003, Loss: 0.8713451623916626, Acc: 0.6875\n",
      "Epoch: 2004, Loss: 0.7290481328964233, Acc: 0.71875\n",
      "Epoch: 2005, Loss: 0.722328245639801, Acc: 0.75\n",
      "Epoch: 2006, Loss: 0.5412447452545166, Acc: 0.84375\n",
      "Epoch: 2007, Loss: 0.5808154940605164, Acc: 0.8125\n",
      "Epoch: 2008, Loss: 0.6970245242118835, Acc: 0.71875\n",
      "Epoch: 2009, Loss: 0.721032977104187, Acc: 0.78125\n",
      "Epoch: 2010, Loss: 0.7624025940895081, Acc: 0.8125\n",
      "Epoch: 2011, Loss: 0.6675011515617371, Acc: 0.78125\n",
      "Epoch: 2012, Loss: 0.9290394186973572, Acc: 0.71875\n",
      "Epoch: 2013, Loss: 0.8421257734298706, Acc: 0.625\n",
      "Epoch: 2014, Loss: 0.75187087059021, Acc: 0.78125\n",
      "Epoch: 2015, Loss: 0.659260630607605, Acc: 0.8125\n",
      "Epoch: 2016, Loss: 0.7426007986068726, Acc: 0.71875\n",
      "Epoch: 2017, Loss: 0.48519107699394226, Acc: 0.78125\n",
      "Epoch: 2018, Loss: 0.6705034971237183, Acc: 0.84375\n",
      "Epoch: 2019, Loss: 0.32688358426094055, Acc: 0.90625\n",
      "Epoch: 2020, Loss: 0.9498742818832397, Acc: 0.75\n",
      "Epoch: 2021, Loss: 0.6257808804512024, Acc: 0.8125\n",
      "Epoch: 2022, Loss: 0.7137575745582581, Acc: 0.78125\n",
      "Epoch: 2023, Loss: 0.4355853796005249, Acc: 0.875\n",
      "Epoch: 2024, Loss: 1.0070855617523193, Acc: 0.65625\n",
      "Epoch: 2025, Loss: 0.5716925263404846, Acc: 0.84375\n",
      "Epoch: 2026, Loss: 0.7667068839073181, Acc: 0.75\n",
      "Epoch: 2027, Loss: 0.7657522559165955, Acc: 0.71875\n",
      "Epoch: 2028, Loss: 0.6540518999099731, Acc: 0.78125\n",
      "Epoch: 2029, Loss: 0.4994785487651825, Acc: 0.84375\n",
      "Epoch: 2030, Loss: 0.9503742456436157, Acc: 0.65625\n",
      "Epoch: 2031, Loss: 0.6257896423339844, Acc: 0.8125\n",
      "Epoch: 2032, Loss: 0.6096473336219788, Acc: 0.8125\n",
      "Epoch: 2033, Loss: 0.7254564762115479, Acc: 0.71875\n",
      "Epoch: 2034, Loss: 0.6433199644088745, Acc: 0.875\n",
      "Epoch: 2035, Loss: 1.0099431276321411, Acc: 0.65625\n",
      "Epoch: 2036, Loss: 0.4635680019855499, Acc: 0.875\n",
      "Epoch: 2037, Loss: 0.7878089547157288, Acc: 0.65625\n",
      "Epoch: 2038, Loss: 0.6610016822814941, Acc: 0.78125\n",
      "Epoch: 2039, Loss: 0.6252973675727844, Acc: 0.78125\n",
      "Epoch: 2040, Loss: 1.0292686223983765, Acc: 0.6875\n",
      "Epoch: 2041, Loss: 0.6041646003723145, Acc: 0.84375\n",
      "Epoch: 2042, Loss: 0.45695316791534424, Acc: 0.84375\n",
      "Epoch: 2043, Loss: 0.4160928726196289, Acc: 0.84375\n",
      "Epoch: 2044, Loss: 0.7478557229042053, Acc: 0.6875\n",
      "Epoch: 2045, Loss: 0.41080161929130554, Acc: 0.875\n",
      "Epoch: 2046, Loss: 1.0542582273483276, Acc: 0.5625\n",
      "Epoch: 2047, Loss: 0.8863770961761475, Acc: 0.71875\n",
      "Epoch: 2048, Loss: 0.34305891394615173, Acc: 0.9375\n",
      "Epoch: 2049, Loss: 0.5281742215156555, Acc: 0.84375\n",
      "Epoch: 2050, Loss: 0.664361298084259, Acc: 0.71875\n",
      "Epoch: 2051, Loss: 0.8605949282646179, Acc: 0.6875\n",
      "Epoch: 2052, Loss: 0.8049072027206421, Acc: 0.71875\n",
      "Epoch: 2053, Loss: 0.624708890914917, Acc: 0.8125\n",
      "Epoch: 2054, Loss: 0.6685956120491028, Acc: 0.78125\n",
      "Epoch: 2055, Loss: 0.3966442048549652, Acc: 0.90625\n",
      "Epoch: 2056, Loss: 0.49997177720069885, Acc: 0.78125\n",
      "Epoch: 2057, Loss: 0.9931082725524902, Acc: 0.6875\n",
      "Epoch: 2058, Loss: 0.6428670883178711, Acc: 0.75\n",
      "Epoch: 2059, Loss: 0.45692262053489685, Acc: 0.875\n",
      "Epoch: 2060, Loss: 0.40063732862472534, Acc: 0.875\n",
      "Epoch: 2061, Loss: 0.5749152302742004, Acc: 0.875\n",
      "Epoch: 2062, Loss: 0.5132697224617004, Acc: 0.875\n",
      "Epoch: 2063, Loss: 0.8184561133384705, Acc: 0.78125\n",
      "Epoch: 2064, Loss: 0.8961899280548096, Acc: 0.75\n",
      "Epoch: 2065, Loss: 0.6572691798210144, Acc: 0.875\n",
      "Epoch: 2066, Loss: 0.8803180456161499, Acc: 0.75\n",
      "Epoch: 2067, Loss: 0.8259485363960266, Acc: 0.75\n",
      "Epoch: 2068, Loss: 0.5389425754547119, Acc: 0.84375\n",
      "Epoch: 2069, Loss: 0.9817649722099304, Acc: 0.75\n",
      "Epoch: 2070, Loss: 0.6660978198051453, Acc: 0.8125\n",
      "Epoch: 2071, Loss: 0.5665812492370605, Acc: 0.8125\n",
      "Epoch: 2072, Loss: 0.6400368213653564, Acc: 0.78125\n",
      "Epoch: 2073, Loss: 0.7266188263893127, Acc: 0.75\n",
      "Epoch: 2074, Loss: 0.5309001803398132, Acc: 0.875\n",
      "Epoch: 2075, Loss: 0.5934723615646362, Acc: 0.8125\n",
      "Epoch: 2076, Loss: 0.5218567252159119, Acc: 0.78125\n",
      "Epoch: 2077, Loss: 0.7285597324371338, Acc: 0.78125\n",
      "Epoch: 2078, Loss: 0.7175047993659973, Acc: 0.71875\n",
      "Epoch: 2079, Loss: 0.4530370235443115, Acc: 0.84375\n",
      "Epoch: 2080, Loss: 0.5263556241989136, Acc: 0.875\n",
      "Epoch: 2081, Loss: 0.7391740083694458, Acc: 0.71875\n",
      "Epoch: 2082, Loss: 0.3586529493331909, Acc: 0.9375\n",
      "Epoch: 2083, Loss: 0.6613930463790894, Acc: 0.71875\n",
      "Epoch: 2084, Loss: 0.5316256284713745, Acc: 0.78125\n",
      "Epoch: 2085, Loss: 0.8836250305175781, Acc: 0.71875\n",
      "Epoch: 2086, Loss: 0.957141101360321, Acc: 0.71875\n",
      "Epoch: 2087, Loss: 0.68398517370224, Acc: 0.75\n",
      "Epoch: 2088, Loss: 0.6160870790481567, Acc: 0.71875\n",
      "Epoch: 2089, Loss: 0.5001440048217773, Acc: 0.875\n",
      "Epoch: 2090, Loss: 0.8707028031349182, Acc: 0.6875\n",
      "Epoch: 2091, Loss: 0.9213953614234924, Acc: 0.71875\n",
      "Epoch: 2092, Loss: 0.8844585418701172, Acc: 0.71875\n",
      "Epoch: 2093, Loss: 0.31869181990623474, Acc: 0.90625\n",
      "Epoch: 2094, Loss: 0.8126570582389832, Acc: 0.8125\n",
      "Epoch: 2095, Loss: 0.7989420294761658, Acc: 0.71875\n",
      "Epoch: 2096, Loss: 0.4276663661003113, Acc: 0.9375\n",
      "Epoch: 2097, Loss: 0.8209888935089111, Acc: 0.59375\n",
      "Epoch: 2098, Loss: 0.633552074432373, Acc: 0.75\n",
      "Epoch: 2099, Loss: 0.6654819250106812, Acc: 0.875\n",
      "Epoch: 2100, Loss: 0.5592583417892456, Acc: 0.8125\n",
      "Epoch: 2101, Loss: 0.4780872166156769, Acc: 0.875\n",
      "Epoch: 2102, Loss: 0.6990530490875244, Acc: 0.75\n",
      "Epoch: 2103, Loss: 0.6491032838821411, Acc: 0.75\n",
      "Epoch: 2104, Loss: 0.3567345142364502, Acc: 0.9375\n",
      "Epoch: 2105, Loss: 0.6439884901046753, Acc: 0.84375\n",
      "Epoch: 2106, Loss: 1.0143553018569946, Acc: 0.6875\n",
      "Epoch: 2107, Loss: 0.4045398533344269, Acc: 0.875\n",
      "Epoch: 2108, Loss: 0.3949526250362396, Acc: 0.875\n",
      "Epoch: 2109, Loss: 0.6604534983634949, Acc: 0.6875\n",
      "Epoch: 2110, Loss: 0.7358594536781311, Acc: 0.71875\n",
      "Epoch: 2111, Loss: 0.9820043444633484, Acc: 0.75\n",
      "Epoch: 2112, Loss: 0.7810934782028198, Acc: 0.78125\n",
      "Epoch: 2113, Loss: 0.9037392735481262, Acc: 0.6875\n",
      "Epoch: 2114, Loss: 0.5853543281555176, Acc: 0.78125\n",
      "Epoch: 2115, Loss: 0.6277920007705688, Acc: 0.78125\n",
      "Epoch: 2116, Loss: 0.6322111487388611, Acc: 0.8125\n",
      "Epoch: 2117, Loss: 0.5218849182128906, Acc: 0.875\n",
      "Epoch: 2118, Loss: 0.8176571130752563, Acc: 0.6875\n",
      "Epoch: 2119, Loss: 0.6036472320556641, Acc: 0.78125\n",
      "Epoch: 2120, Loss: 0.9142667055130005, Acc: 0.71875\n",
      "Epoch: 2121, Loss: 0.8642321228981018, Acc: 0.71875\n",
      "Epoch: 2122, Loss: 0.5981766581535339, Acc: 0.84375\n",
      "Epoch: 2123, Loss: 0.7658380270004272, Acc: 0.75\n",
      "Epoch: 2124, Loss: 0.621751070022583, Acc: 0.75\n",
      "Epoch: 2125, Loss: 0.9634039402008057, Acc: 0.65625\n",
      "Epoch: 2126, Loss: 0.6913877129554749, Acc: 0.71875\n",
      "Epoch: 2127, Loss: 0.8241738080978394, Acc: 0.6875\n",
      "Epoch: 2128, Loss: 0.736005425453186, Acc: 0.8125\n",
      "Epoch: 2129, Loss: 0.547918438911438, Acc: 0.78125\n",
      "Epoch: 2130, Loss: 0.7470518946647644, Acc: 0.75\n",
      "Epoch: 2131, Loss: 0.5716129541397095, Acc: 0.84375\n",
      "Epoch: 2132, Loss: 0.528333842754364, Acc: 0.8125\n",
      "Epoch: 2133, Loss: 0.8002266883850098, Acc: 0.78125\n",
      "Epoch: 2134, Loss: 0.9738731384277344, Acc: 0.6875\n",
      "Epoch: 2135, Loss: 0.693778932094574, Acc: 0.8125\n",
      "Epoch: 2136, Loss: 0.5967146754264832, Acc: 0.78125\n",
      "Epoch: 2137, Loss: 0.5162078142166138, Acc: 0.875\n",
      "Epoch: 2138, Loss: 0.5566142797470093, Acc: 0.8125\n",
      "Epoch: 2139, Loss: 0.4191688597202301, Acc: 0.84375\n",
      "Epoch: 2140, Loss: 0.5501277446746826, Acc: 0.78125\n",
      "Epoch: 2141, Loss: 0.8841429948806763, Acc: 0.75\n",
      "Epoch: 2142, Loss: 0.8648667335510254, Acc: 0.75\n",
      "Epoch: 2143, Loss: 0.857027530670166, Acc: 0.75\n",
      "Epoch: 2144, Loss: 0.47442203760147095, Acc: 0.84375\n",
      "Epoch: 2145, Loss: 0.6702932119369507, Acc: 0.75\n",
      "Epoch: 2146, Loss: 0.9375893473625183, Acc: 0.59375\n",
      "Epoch: 2147, Loss: 0.4932290017604828, Acc: 0.84375\n",
      "Epoch: 2148, Loss: 1.0737507343292236, Acc: 0.65625\n",
      "Epoch: 2149, Loss: 0.9475402235984802, Acc: 0.6875\n",
      "Epoch: 2150, Loss: 0.42012152075767517, Acc: 0.84375\n",
      "Epoch: 2151, Loss: 0.5841294527053833, Acc: 0.84375\n",
      "Epoch: 2152, Loss: 0.7708319425582886, Acc: 0.75\n",
      "Epoch: 2153, Loss: 0.8033294081687927, Acc: 0.75\n",
      "Epoch: 2154, Loss: 0.5967522263526917, Acc: 0.8125\n",
      "Epoch: 2155, Loss: 0.6160302758216858, Acc: 0.8125\n",
      "Epoch: 2156, Loss: 0.5965575575828552, Acc: 0.75\n",
      "Epoch: 2157, Loss: 0.7767614126205444, Acc: 0.75\n",
      "Epoch: 2158, Loss: 0.8206478953361511, Acc: 0.75\n",
      "Epoch: 2159, Loss: 0.6572974920272827, Acc: 0.75\n",
      "Epoch: 2160, Loss: 0.5882765054702759, Acc: 0.8125\n",
      "Epoch: 2161, Loss: 0.7459839582443237, Acc: 0.8125\n",
      "Epoch: 2162, Loss: 0.671685516834259, Acc: 0.75\n",
      "Epoch: 2163, Loss: 0.6256194114685059, Acc: 0.78125\n",
      "Epoch: 2164, Loss: 0.4847121238708496, Acc: 0.84375\n",
      "Epoch: 2165, Loss: 0.5752595663070679, Acc: 0.78125\n",
      "Epoch: 2166, Loss: 0.5530819892883301, Acc: 0.84375\n",
      "Epoch: 2167, Loss: 0.6235100030899048, Acc: 0.78125\n",
      "Epoch: 2168, Loss: 0.5530789494514465, Acc: 0.84375\n",
      "Epoch: 2169, Loss: 0.7929053902626038, Acc: 0.6875\n",
      "Epoch: 2170, Loss: 0.4711952805519104, Acc: 0.78125\n",
      "Epoch: 2171, Loss: 0.573897123336792, Acc: 0.8125\n",
      "Epoch: 2172, Loss: 0.7489851713180542, Acc: 0.75\n",
      "Epoch: 2173, Loss: 0.7816486954689026, Acc: 0.71875\n",
      "Epoch: 2174, Loss: 0.7727481722831726, Acc: 0.75\n",
      "Epoch: 2175, Loss: 0.5170965194702148, Acc: 0.8125\n",
      "Epoch: 2176, Loss: 0.5515408515930176, Acc: 0.8125\n",
      "Epoch: 2177, Loss: 0.35858726501464844, Acc: 0.84375\n",
      "Epoch: 2178, Loss: 0.739453136920929, Acc: 0.71875\n",
      "Epoch: 2179, Loss: 0.7525292038917542, Acc: 0.75\n",
      "Epoch: 2180, Loss: 0.374585896730423, Acc: 0.78125\n",
      "Epoch: 2181, Loss: 0.4568049907684326, Acc: 0.78125\n",
      "Epoch: 2182, Loss: 0.4314824342727661, Acc: 0.8125\n",
      "Epoch: 2183, Loss: 0.52787846326828, Acc: 0.875\n",
      "Epoch: 2184, Loss: 0.5901563167572021, Acc: 0.875\n",
      "Epoch: 2185, Loss: 0.5307900309562683, Acc: 0.8125\n",
      "Epoch: 2186, Loss: 0.6164706945419312, Acc: 0.78125\n",
      "Epoch: 2187, Loss: 0.6310333609580994, Acc: 0.8125\n",
      "Epoch: 2188, Loss: 0.7489293217658997, Acc: 0.78125\n",
      "Epoch: 2189, Loss: 0.6657544374465942, Acc: 0.71875\n",
      "Epoch: 2190, Loss: 0.5224800109863281, Acc: 0.75\n",
      "Epoch: 2191, Loss: 0.4098292291164398, Acc: 0.84375\n",
      "Epoch: 2192, Loss: 0.5750981569290161, Acc: 0.875\n",
      "Epoch: 2193, Loss: 0.4164745807647705, Acc: 0.90625\n",
      "Epoch: 2194, Loss: 0.32897186279296875, Acc: 0.90625\n",
      "Epoch: 2195, Loss: 0.24404962360858917, Acc: 0.9375\n",
      "Epoch: 2196, Loss: 0.2693779766559601, Acc: 0.9375\n",
      "Epoch: 2197, Loss: 0.4340302050113678, Acc: 0.84375\n",
      "Epoch: 2198, Loss: 0.40713685750961304, Acc: 0.84375\n",
      "Epoch: 2199, Loss: 0.8282639980316162, Acc: 0.71875\n",
      "Epoch: 2200, Loss: 0.6212928295135498, Acc: 0.75\n",
      "Epoch: 2201, Loss: 0.6387671828269958, Acc: 0.8125\n",
      "Epoch: 2202, Loss: 0.5673791766166687, Acc: 0.78125\n",
      "Epoch: 2203, Loss: 0.5002061724662781, Acc: 0.8125\n",
      "Epoch: 2204, Loss: 0.6023387908935547, Acc: 0.90625\n",
      "Epoch: 2205, Loss: 0.4248281419277191, Acc: 0.875\n",
      "Epoch: 2206, Loss: 0.24384573101997375, Acc: 0.96875\n",
      "Epoch: 2207, Loss: 0.5480985641479492, Acc: 0.84375\n",
      "Epoch: 2208, Loss: 0.429379940032959, Acc: 0.84375\n",
      "Epoch: 2209, Loss: 0.538250744342804, Acc: 0.84375\n",
      "Epoch: 2210, Loss: 0.668180525302887, Acc: 0.8125\n",
      "Epoch: 2211, Loss: 0.540988028049469, Acc: 0.8125\n",
      "Epoch: 2212, Loss: 0.6338200569152832, Acc: 0.78125\n",
      "Epoch: 2213, Loss: 0.944200873374939, Acc: 0.71875\n",
      "Epoch: 2214, Loss: 0.9711684584617615, Acc: 0.6875\n",
      "Epoch: 2215, Loss: 0.5587834119796753, Acc: 0.84375\n",
      "Epoch: 2216, Loss: 0.7809696793556213, Acc: 0.6875\n",
      "Epoch: 2217, Loss: 0.5954976081848145, Acc: 0.71875\n",
      "Epoch: 2218, Loss: 0.8453288674354553, Acc: 0.78125\n",
      "Epoch: 2219, Loss: 0.8661049604415894, Acc: 0.6875\n",
      "Epoch: 2220, Loss: 0.46946993470191956, Acc: 0.8125\n",
      "Epoch: 2221, Loss: 0.9492264986038208, Acc: 0.71875\n",
      "Epoch: 2222, Loss: 0.4898882210254669, Acc: 0.875\n",
      "Epoch: 2223, Loss: 0.7573826313018799, Acc: 0.78125\n",
      "Epoch: 2224, Loss: 0.8208349943161011, Acc: 0.78125\n",
      "Epoch: 2225, Loss: 0.7330892086029053, Acc: 0.75\n",
      "Epoch: 2226, Loss: 0.6106349229812622, Acc: 0.75\n",
      "Epoch: 2227, Loss: 0.70271235704422, Acc: 0.78125\n",
      "Epoch: 2228, Loss: 0.6864511370658875, Acc: 0.78125\n",
      "Epoch: 2229, Loss: 0.4230067729949951, Acc: 0.84375\n",
      "Epoch: 2230, Loss: 0.9321527481079102, Acc: 0.75\n",
      "Epoch: 2231, Loss: 0.7796693444252014, Acc: 0.75\n",
      "Epoch: 2232, Loss: 0.45593827962875366, Acc: 0.8125\n",
      "Epoch: 2233, Loss: 0.7974351644515991, Acc: 0.71875\n",
      "Epoch: 2234, Loss: 0.6862586140632629, Acc: 0.75\n",
      "Epoch: 2235, Loss: 0.8501522541046143, Acc: 0.75\n",
      "Epoch: 2236, Loss: 0.7780187726020813, Acc: 0.78125\n",
      "Epoch: 2237, Loss: 0.8002223968505859, Acc: 0.75\n",
      "Epoch: 2238, Loss: 0.5287155508995056, Acc: 0.84375\n",
      "Epoch: 2239, Loss: 0.3936493396759033, Acc: 0.875\n",
      "Epoch: 2240, Loss: 0.4484729766845703, Acc: 0.8125\n",
      "Epoch: 2241, Loss: 0.5798409581184387, Acc: 0.78125\n",
      "Epoch: 2242, Loss: 0.49111801385879517, Acc: 0.84375\n",
      "Epoch: 2243, Loss: 0.959255039691925, Acc: 0.6875\n",
      "Epoch: 2244, Loss: 0.44764891266822815, Acc: 0.84375\n",
      "Epoch: 2245, Loss: 0.6281280517578125, Acc: 0.8125\n",
      "Epoch: 2246, Loss: 1.0947647094726562, Acc: 0.75\n",
      "Epoch: 2247, Loss: 0.5686637759208679, Acc: 0.8125\n",
      "Epoch: 2248, Loss: 0.49707645177841187, Acc: 0.8125\n",
      "Epoch: 2249, Loss: 0.9138804078102112, Acc: 0.71875\n",
      "Epoch: 2250, Loss: 0.2834356427192688, Acc: 0.9375\n",
      "Epoch: 2251, Loss: 0.6398646235466003, Acc: 0.84375\n",
      "Epoch: 2252, Loss: 0.39011073112487793, Acc: 0.90625\n",
      "Epoch: 2253, Loss: 0.42250484228134155, Acc: 0.875\n",
      "Epoch: 2254, Loss: 0.5944786071777344, Acc: 0.8125\n",
      "Epoch: 2255, Loss: 0.6224688291549683, Acc: 0.78125\n",
      "Epoch: 2256, Loss: 0.6099125742912292, Acc: 0.84375\n",
      "Epoch: 2257, Loss: 0.8527581095695496, Acc: 0.75\n",
      "Epoch: 2258, Loss: 0.36181390285491943, Acc: 0.875\n",
      "Epoch: 2259, Loss: 0.8026770353317261, Acc: 0.78125\n",
      "Epoch: 2260, Loss: 0.5301884412765503, Acc: 0.875\n",
      "Epoch: 2261, Loss: 0.6495871543884277, Acc: 0.71875\n",
      "Epoch: 2262, Loss: 0.5178240537643433, Acc: 0.8125\n",
      "Epoch: 2263, Loss: 0.5617510676383972, Acc: 0.8125\n",
      "Epoch: 2264, Loss: 0.3039737641811371, Acc: 0.96875\n",
      "Epoch: 2265, Loss: 0.24516308307647705, Acc: 0.90625\n",
      "Epoch: 2266, Loss: 0.4514507055282593, Acc: 0.84375\n",
      "Epoch: 2267, Loss: 0.7247663736343384, Acc: 0.71875\n",
      "Epoch: 2268, Loss: 0.6952797770500183, Acc: 0.75\n",
      "Epoch: 2269, Loss: 1.0215219259262085, Acc: 0.71875\n",
      "Epoch: 2270, Loss: 0.6466962695121765, Acc: 0.78125\n",
      "Epoch: 2271, Loss: 0.5197343826293945, Acc: 0.84375\n",
      "Epoch: 2272, Loss: 0.7432337403297424, Acc: 0.625\n",
      "Epoch: 2273, Loss: 0.4287157356739044, Acc: 0.875\n",
      "Epoch: 2274, Loss: 0.6484301090240479, Acc: 0.8125\n",
      "Epoch: 2275, Loss: 0.46657276153564453, Acc: 0.8125\n",
      "Epoch: 2276, Loss: 0.7837961912155151, Acc: 0.78125\n",
      "Epoch: 2277, Loss: 0.44993552565574646, Acc: 0.84375\n",
      "Epoch: 2278, Loss: 0.6822072267532349, Acc: 0.75\n",
      "Epoch: 2279, Loss: 0.6066917777061462, Acc: 0.84375\n",
      "Epoch: 2280, Loss: 1.2076777219772339, Acc: 0.65625\n",
      "Epoch: 2281, Loss: 0.413063108921051, Acc: 0.90625\n",
      "Epoch: 2282, Loss: 0.47134143114089966, Acc: 0.75\n",
      "Epoch: 2283, Loss: 0.5743517875671387, Acc: 0.84375\n",
      "Epoch: 2284, Loss: 0.6920488476753235, Acc: 0.75\n",
      "Epoch: 2285, Loss: 0.645287811756134, Acc: 0.75\n",
      "Epoch: 2286, Loss: 0.39160966873168945, Acc: 0.84375\n",
      "Epoch: 2287, Loss: 0.509335994720459, Acc: 0.84375\n",
      "Epoch: 2288, Loss: 0.618675172328949, Acc: 0.8125\n",
      "Epoch: 2289, Loss: 0.6439559459686279, Acc: 0.8125\n",
      "Epoch: 2290, Loss: 0.676994264125824, Acc: 0.75\n",
      "Epoch: 2291, Loss: 0.5989016890525818, Acc: 0.8125\n",
      "Epoch: 2292, Loss: 0.5136975646018982, Acc: 0.8125\n",
      "Epoch: 2293, Loss: 0.5531394481658936, Acc: 0.8125\n",
      "Epoch: 2294, Loss: 0.4972872734069824, Acc: 0.84375\n",
      "Epoch: 2295, Loss: 0.5391775965690613, Acc: 0.84375\n",
      "Epoch: 2296, Loss: 0.6912413835525513, Acc: 0.75\n",
      "Epoch: 2297, Loss: 0.48171526193618774, Acc: 0.875\n",
      "Epoch: 2298, Loss: 0.5103839635848999, Acc: 0.8125\n",
      "Epoch: 2299, Loss: 0.7824770212173462, Acc: 0.75\n",
      "Epoch: 2300, Loss: 0.8568301200866699, Acc: 0.75\n",
      "Epoch: 2301, Loss: 1.041599988937378, Acc: 0.6875\n",
      "Epoch: 2302, Loss: 1.193886399269104, Acc: 0.625\n",
      "Epoch: 2303, Loss: 0.558468759059906, Acc: 0.84375\n",
      "Epoch: 2304, Loss: 0.34349074959754944, Acc: 0.90625\n",
      "Epoch: 2305, Loss: 0.9464137554168701, Acc: 0.6875\n",
      "Epoch: 2306, Loss: 0.6895131468772888, Acc: 0.8125\n",
      "Epoch: 2307, Loss: 0.39939576387405396, Acc: 0.84375\n",
      "Epoch: 2308, Loss: 0.5292934775352478, Acc: 0.78125\n",
      "Epoch: 2309, Loss: 0.626788318157196, Acc: 0.78125\n",
      "Epoch: 2310, Loss: 0.6811835765838623, Acc: 0.8125\n",
      "Epoch: 2311, Loss: 0.9402177929878235, Acc: 0.6875\n",
      "Epoch: 2312, Loss: 0.6811113357543945, Acc: 0.8125\n",
      "Epoch: 2313, Loss: 0.3342753052711487, Acc: 0.90625\n",
      "Epoch: 2314, Loss: 0.8437520265579224, Acc: 0.75\n",
      "Epoch: 2315, Loss: 1.19154691696167, Acc: 0.75\n",
      "Epoch: 2316, Loss: 0.5629462003707886, Acc: 0.8125\n",
      "Epoch: 2317, Loss: 0.45500192046165466, Acc: 0.875\n",
      "Epoch: 2318, Loss: 0.6264987587928772, Acc: 0.8125\n",
      "Epoch: 2319, Loss: 0.5894973278045654, Acc: 0.84375\n",
      "Epoch: 2320, Loss: 0.6749109029769897, Acc: 0.71875\n",
      "Epoch: 2321, Loss: 0.7219582796096802, Acc: 0.71875\n",
      "Epoch: 2322, Loss: 0.8840097188949585, Acc: 0.75\n",
      "Epoch: 2323, Loss: 0.8365619778633118, Acc: 0.6875\n",
      "Epoch: 2324, Loss: 0.7498484253883362, Acc: 0.8125\n",
      "Epoch: 2325, Loss: 0.6714181900024414, Acc: 0.8125\n",
      "Epoch: 2326, Loss: 0.3581085503101349, Acc: 0.8125\n",
      "Epoch: 2327, Loss: 0.7320891618728638, Acc: 0.78125\n",
      "Epoch: 2328, Loss: 0.41293853521347046, Acc: 0.90625\n",
      "Epoch: 2329, Loss: 0.5930323600769043, Acc: 0.75\n",
      "Epoch: 2330, Loss: 0.7148585319519043, Acc: 0.78125\n",
      "Epoch: 2331, Loss: 0.7622167468070984, Acc: 0.75\n",
      "Epoch: 2332, Loss: 0.4784294366836548, Acc: 0.8125\n",
      "Epoch: 2333, Loss: 1.1567000150680542, Acc: 0.59375\n",
      "Epoch: 2334, Loss: 0.5272981524467468, Acc: 0.84375\n",
      "Epoch: 2335, Loss: 0.6887022852897644, Acc: 0.78125\n",
      "Epoch: 2336, Loss: 0.6312041878700256, Acc: 0.75\n",
      "Epoch: 2337, Loss: 0.6028544306755066, Acc: 0.75\n",
      "Epoch: 2338, Loss: 0.7097500562667847, Acc: 0.75\n",
      "Epoch: 2339, Loss: 0.5072656273841858, Acc: 0.90625\n",
      "Epoch: 2340, Loss: 0.6339811086654663, Acc: 0.78125\n",
      "Epoch: 2341, Loss: 1.0459471940994263, Acc: 0.625\n",
      "Epoch: 2342, Loss: 0.575904130935669, Acc: 0.8125\n",
      "Epoch: 2343, Loss: 0.6992020606994629, Acc: 0.8125\n",
      "Epoch: 2344, Loss: 0.5520389080047607, Acc: 0.84375\n",
      "Epoch: 2345, Loss: 0.7145043611526489, Acc: 0.78125\n",
      "Epoch: 2346, Loss: 0.48883092403411865, Acc: 0.8125\n",
      "Epoch: 2347, Loss: 0.4671388864517212, Acc: 0.875\n",
      "Epoch: 2348, Loss: 1.013168454170227, Acc: 0.6875\n",
      "Epoch: 2349, Loss: 0.5454542636871338, Acc: 0.84375\n",
      "Epoch: 2350, Loss: 0.501445472240448, Acc: 0.75\n",
      "Epoch: 2351, Loss: 0.44655123353004456, Acc: 0.78125\n",
      "Epoch: 2352, Loss: 0.4642588496208191, Acc: 0.875\n",
      "Epoch: 2353, Loss: 0.7770979404449463, Acc: 0.75\n",
      "Epoch: 2354, Loss: 0.5233830809593201, Acc: 0.84375\n",
      "Epoch: 2355, Loss: 0.7608580589294434, Acc: 0.8125\n",
      "Epoch: 2356, Loss: 0.6122410297393799, Acc: 0.71875\n",
      "Epoch: 2357, Loss: 0.472762793302536, Acc: 0.90625\n",
      "Epoch: 2358, Loss: 0.6924607753753662, Acc: 0.75\n",
      "Epoch: 2359, Loss: 0.6871795654296875, Acc: 0.8125\n",
      "Epoch: 2360, Loss: 0.40114155411720276, Acc: 0.84375\n",
      "Epoch: 2361, Loss: 0.8661577701568604, Acc: 0.71875\n",
      "Epoch: 2362, Loss: 0.7356313467025757, Acc: 0.71875\n",
      "Epoch: 2363, Loss: 0.777391254901886, Acc: 0.75\n",
      "Epoch: 2364, Loss: 0.37617942690849304, Acc: 0.84375\n",
      "Epoch: 2365, Loss: 0.44666483998298645, Acc: 0.84375\n",
      "Epoch: 2366, Loss: 0.8126582503318787, Acc: 0.71875\n",
      "Epoch: 2367, Loss: 0.6337899565696716, Acc: 0.78125\n",
      "Epoch: 2368, Loss: 0.3994996249675751, Acc: 0.875\n",
      "Epoch: 2369, Loss: 0.9276221394538879, Acc: 0.75\n",
      "Epoch: 2370, Loss: 0.650768518447876, Acc: 0.75\n",
      "Epoch: 2371, Loss: 0.6129361391067505, Acc: 0.8125\n",
      "Epoch: 2372, Loss: 0.5026482939720154, Acc: 0.8125\n",
      "Epoch: 2373, Loss: 0.33286333084106445, Acc: 0.90625\n",
      "Epoch: 2374, Loss: 0.4791663885116577, Acc: 0.84375\n",
      "Epoch: 2375, Loss: 0.45673060417175293, Acc: 0.84375\n",
      "Epoch: 2376, Loss: 0.8914127349853516, Acc: 0.6875\n",
      "Epoch: 2377, Loss: 0.35957157611846924, Acc: 0.84375\n",
      "Epoch: 2378, Loss: 0.5725827813148499, Acc: 0.75\n",
      "Epoch: 2379, Loss: 0.7207279205322266, Acc: 0.71875\n",
      "Epoch: 2380, Loss: 0.43664559721946716, Acc: 0.875\n",
      "Epoch: 2381, Loss: 0.5133697986602783, Acc: 0.84375\n",
      "Epoch: 2382, Loss: 0.3550155460834503, Acc: 0.9375\n",
      "Epoch: 2383, Loss: 0.7009469866752625, Acc: 0.8125\n",
      "Epoch: 2384, Loss: 0.5422402024269104, Acc: 0.84375\n",
      "Epoch: 2385, Loss: 0.8712764382362366, Acc: 0.65625\n",
      "Epoch: 2386, Loss: 0.2751442790031433, Acc: 0.9375\n",
      "Epoch: 2387, Loss: 0.6688427329063416, Acc: 0.75\n",
      "Epoch: 2388, Loss: 1.1210882663726807, Acc: 0.71875\n",
      "Epoch: 2389, Loss: 0.6640961766242981, Acc: 0.78125\n",
      "Epoch: 2390, Loss: 0.6607335805892944, Acc: 0.78125\n",
      "Epoch: 2391, Loss: 0.5840425491333008, Acc: 0.8125\n",
      "Epoch: 2392, Loss: 0.44302231073379517, Acc: 0.875\n",
      "Epoch: 2393, Loss: 0.4234398603439331, Acc: 0.8125\n",
      "Epoch: 2394, Loss: 0.2708558142185211, Acc: 0.90625\n",
      "Epoch: 2395, Loss: 0.7673880457878113, Acc: 0.75\n",
      "Epoch: 2396, Loss: 0.757037341594696, Acc: 0.8125\n",
      "Epoch: 2397, Loss: 0.6278903484344482, Acc: 0.71875\n",
      "Epoch: 2398, Loss: 0.3464658558368683, Acc: 0.875\n",
      "Epoch: 2399, Loss: 0.35368621349334717, Acc: 0.875\n",
      "Epoch: 2400, Loss: 0.820463240146637, Acc: 0.71875\n",
      "Epoch: 2401, Loss: 0.5541970729827881, Acc: 0.75\n",
      "Epoch: 2402, Loss: 0.5640357136726379, Acc: 0.84375\n",
      "Epoch: 2403, Loss: 0.6711361408233643, Acc: 0.78125\n",
      "Epoch: 2404, Loss: 0.5705147981643677, Acc: 0.8125\n",
      "Epoch: 2405, Loss: 0.500413179397583, Acc: 0.75\n",
      "Epoch: 2406, Loss: 0.8045697212219238, Acc: 0.78125\n",
      "Epoch: 2407, Loss: 0.8899323344230652, Acc: 0.71875\n",
      "Epoch: 2408, Loss: 0.8922860622406006, Acc: 0.6875\n",
      "Epoch: 2409, Loss: 0.7877321243286133, Acc: 0.8125\n",
      "Epoch: 2410, Loss: 0.4534512460231781, Acc: 0.8125\n",
      "Epoch: 2411, Loss: 0.6866001486778259, Acc: 0.75\n",
      "Epoch: 2412, Loss: 0.6063512563705444, Acc: 0.8125\n",
      "Epoch: 2413, Loss: 0.9812802672386169, Acc: 0.65625\n",
      "Epoch: 2414, Loss: 0.5946089029312134, Acc: 0.8125\n",
      "Epoch: 2415, Loss: 0.8542205095291138, Acc: 0.71875\n",
      "Epoch: 2416, Loss: 0.4980844557285309, Acc: 0.78125\n",
      "Epoch: 2417, Loss: 0.6429153084754944, Acc: 0.84375\n",
      "Epoch: 2418, Loss: 0.782812237739563, Acc: 0.8125\n",
      "Epoch: 2419, Loss: 1.062102198600769, Acc: 0.6875\n",
      "Epoch: 2420, Loss: 0.6421669721603394, Acc: 0.78125\n",
      "Epoch: 2421, Loss: 0.4732658267021179, Acc: 0.75\n",
      "Epoch: 2422, Loss: 0.5642933249473572, Acc: 0.75\n",
      "Epoch: 2423, Loss: 0.5463880300521851, Acc: 0.90625\n",
      "Epoch: 2424, Loss: 0.5498232245445251, Acc: 0.8125\n",
      "Epoch: 2425, Loss: 0.5988300442695618, Acc: 0.8125\n",
      "Epoch: 2426, Loss: 1.2668195962905884, Acc: 0.65625\n",
      "Epoch: 2427, Loss: 0.4130963683128357, Acc: 0.875\n",
      "Epoch: 2428, Loss: 0.5994176864624023, Acc: 0.71875\n",
      "Epoch: 2429, Loss: 0.7444132566452026, Acc: 0.78125\n",
      "Epoch: 2430, Loss: 0.8983430862426758, Acc: 0.78125\n",
      "Epoch: 2431, Loss: 0.661549985408783, Acc: 0.78125\n",
      "Epoch: 2432, Loss: 0.47861042618751526, Acc: 0.875\n",
      "Epoch: 2433, Loss: 0.9433266520500183, Acc: 0.75\n",
      "Epoch: 2434, Loss: 0.8408530950546265, Acc: 0.71875\n",
      "Epoch: 2435, Loss: 0.9331462383270264, Acc: 0.8125\n",
      "Epoch: 2436, Loss: 0.6883595585823059, Acc: 0.78125\n",
      "Epoch: 2437, Loss: 0.6991547346115112, Acc: 0.8125\n",
      "Epoch: 2438, Loss: 0.4641956388950348, Acc: 0.84375\n",
      "Epoch: 2439, Loss: 1.0094612836837769, Acc: 0.6875\n",
      "Epoch: 2440, Loss: 0.6593431830406189, Acc: 0.78125\n",
      "Epoch: 2441, Loss: 0.7386167049407959, Acc: 0.75\n",
      "Epoch: 2442, Loss: 0.6865445375442505, Acc: 0.75\n",
      "Epoch: 2443, Loss: 0.6442044973373413, Acc: 0.71875\n",
      "Epoch: 2444, Loss: 0.8905566334724426, Acc: 0.625\n",
      "Epoch: 2445, Loss: 0.5691795945167542, Acc: 0.90625\n",
      "Epoch: 2446, Loss: 0.8437800407409668, Acc: 0.71875\n",
      "Epoch: 2447, Loss: 0.7300117015838623, Acc: 0.8125\n",
      "Epoch: 2448, Loss: 0.6684765815734863, Acc: 0.8125\n",
      "Epoch: 2449, Loss: 0.583532989025116, Acc: 0.8125\n",
      "Epoch: 2450, Loss: 0.2872075140476227, Acc: 0.9375\n",
      "Epoch: 2451, Loss: 0.5311444401741028, Acc: 0.84375\n",
      "Epoch: 2452, Loss: 1.013723611831665, Acc: 0.78125\n",
      "Epoch: 2453, Loss: 0.6222605109214783, Acc: 0.75\n",
      "Epoch: 2454, Loss: 0.6578766107559204, Acc: 0.75\n",
      "Epoch: 2455, Loss: 0.7867208123207092, Acc: 0.75\n",
      "Epoch: 2456, Loss: 0.799763560295105, Acc: 0.75\n",
      "Epoch: 2457, Loss: 0.6474105715751648, Acc: 0.8125\n",
      "Epoch: 2458, Loss: 0.5069069266319275, Acc: 0.75\n",
      "Epoch: 2459, Loss: 0.3926292955875397, Acc: 0.90625\n",
      "Epoch: 2460, Loss: 0.49996352195739746, Acc: 0.875\n",
      "Epoch: 2461, Loss: 0.5738008618354797, Acc: 0.8125\n",
      "Epoch: 2462, Loss: 0.36727413535118103, Acc: 0.8125\n",
      "Epoch: 2463, Loss: 0.8045591115951538, Acc: 0.78125\n",
      "Epoch: 2464, Loss: 0.9213799834251404, Acc: 0.6875\n",
      "Epoch: 2465, Loss: 0.5378646850585938, Acc: 0.84375\n",
      "Epoch: 2466, Loss: 0.3488147258758545, Acc: 0.84375\n",
      "Epoch: 2467, Loss: 0.2679109275341034, Acc: 0.9375\n",
      "Epoch: 2468, Loss: 0.5118449330329895, Acc: 0.8125\n",
      "Epoch: 2469, Loss: 0.6182495355606079, Acc: 0.84375\n",
      "Epoch: 2470, Loss: 0.7401850819587708, Acc: 0.71875\n",
      "Epoch: 2471, Loss: 0.5492936968803406, Acc: 0.84375\n",
      "Epoch: 2472, Loss: 0.5943558216094971, Acc: 0.71875\n",
      "Epoch: 2473, Loss: 0.6508436799049377, Acc: 0.71875\n",
      "Epoch: 2474, Loss: 0.5868316292762756, Acc: 0.78125\n",
      "Epoch: 2475, Loss: 1.0559675693511963, Acc: 0.6875\n",
      "Epoch: 2476, Loss: 0.3753972053527832, Acc: 0.875\n",
      "Epoch: 2477, Loss: 0.3511066734790802, Acc: 0.875\n",
      "Epoch: 2478, Loss: 0.4173814654350281, Acc: 0.84375\n",
      "Epoch: 2479, Loss: 0.6158077716827393, Acc: 0.8125\n",
      "Epoch: 2480, Loss: 0.46872320771217346, Acc: 0.84375\n",
      "Epoch: 2481, Loss: 1.0472218990325928, Acc: 0.65625\n",
      "Epoch: 2482, Loss: 0.6094374656677246, Acc: 0.8125\n",
      "Epoch: 2483, Loss: 0.5295414328575134, Acc: 0.8125\n",
      "Epoch: 2484, Loss: 0.5057094693183899, Acc: 0.875\n",
      "Epoch: 2485, Loss: 0.7638551592826843, Acc: 0.8125\n",
      "Epoch: 2486, Loss: 1.0673482418060303, Acc: 0.6875\n",
      "Epoch: 2487, Loss: 0.7737478017807007, Acc: 0.71875\n",
      "Epoch: 2488, Loss: 0.460769385099411, Acc: 0.875\n",
      "Epoch: 2489, Loss: 0.42035579681396484, Acc: 0.875\n",
      "Epoch: 2490, Loss: 1.1162095069885254, Acc: 0.6875\n",
      "Epoch: 2491, Loss: 0.553281843662262, Acc: 0.8125\n",
      "Epoch: 2492, Loss: 0.6645209789276123, Acc: 0.75\n",
      "Epoch: 2493, Loss: 0.5813145637512207, Acc: 0.71875\n",
      "Epoch: 2494, Loss: 0.4302945137023926, Acc: 0.8125\n",
      "Epoch: 2495, Loss: 0.2635875344276428, Acc: 0.96875\n",
      "Epoch: 2496, Loss: 0.8253501653671265, Acc: 0.75\n",
      "Epoch: 2497, Loss: 0.7505151629447937, Acc: 0.78125\n",
      "Epoch: 2498, Loss: 0.9093301892280579, Acc: 0.75\n",
      "Epoch: 2499, Loss: 0.763019323348999, Acc: 0.8125\n",
      "Epoch: 2500, Loss: 0.4936806261539459, Acc: 0.8125\n",
      "Epoch: 2501, Loss: 0.6481748223304749, Acc: 0.71875\n",
      "Epoch: 2502, Loss: 0.6098008751869202, Acc: 0.8125\n",
      "Epoch: 2503, Loss: 0.501981794834137, Acc: 0.75\n",
      "Epoch: 2504, Loss: 0.5720142722129822, Acc: 0.84375\n",
      "Epoch: 2505, Loss: 0.3682977259159088, Acc: 0.84375\n",
      "Epoch: 2506, Loss: 0.48000603914260864, Acc: 0.875\n",
      "Epoch: 2507, Loss: 0.7490923404693604, Acc: 0.71875\n",
      "Epoch: 2508, Loss: 0.6419026255607605, Acc: 0.6875\n",
      "Epoch: 2509, Loss: 0.6150982975959778, Acc: 0.75\n",
      "Epoch: 2510, Loss: 0.5028130412101746, Acc: 0.78125\n",
      "Epoch: 2511, Loss: 0.5246414542198181, Acc: 0.84375\n",
      "Epoch: 2512, Loss: 1.054965615272522, Acc: 0.59375\n",
      "Epoch: 2513, Loss: 0.8259906768798828, Acc: 0.6875\n",
      "Epoch: 2514, Loss: 0.7814491391181946, Acc: 0.75\n",
      "Epoch: 2515, Loss: 0.6254963278770447, Acc: 0.8125\n",
      "Epoch: 2516, Loss: 0.6401803493499756, Acc: 0.75\n",
      "Epoch: 2517, Loss: 1.0114713907241821, Acc: 0.59375\n",
      "Epoch: 2518, Loss: 0.8735195398330688, Acc: 0.78125\n",
      "Epoch: 2519, Loss: 0.49990007281303406, Acc: 0.84375\n",
      "Epoch: 2520, Loss: 0.9878754615783691, Acc: 0.71875\n",
      "Epoch: 2521, Loss: 0.625946581363678, Acc: 0.78125\n",
      "Epoch: 2522, Loss: 0.5320780873298645, Acc: 0.78125\n",
      "Epoch: 2523, Loss: 0.2730516195297241, Acc: 0.90625\n",
      "Epoch: 2524, Loss: 0.47956526279449463, Acc: 0.84375\n",
      "Epoch: 2525, Loss: 0.3772844672203064, Acc: 0.875\n",
      "Epoch: 2526, Loss: 0.38372084498405457, Acc: 0.875\n",
      "Epoch: 2527, Loss: 0.5792652368545532, Acc: 0.8125\n",
      "Epoch: 2528, Loss: 0.6454367637634277, Acc: 0.78125\n",
      "Epoch: 2529, Loss: 0.9294854998588562, Acc: 0.6875\n",
      "Epoch: 2530, Loss: 0.49468404054641724, Acc: 0.875\n",
      "Epoch: 2531, Loss: 0.6189246773719788, Acc: 0.84375\n",
      "Epoch: 2532, Loss: 0.8313530087471008, Acc: 0.71875\n",
      "Epoch: 2533, Loss: 0.6506310105323792, Acc: 0.75\n",
      "Epoch: 2534, Loss: 0.5348784923553467, Acc: 0.84375\n",
      "Epoch: 2535, Loss: 0.7159965634346008, Acc: 0.75\n",
      "Epoch: 2536, Loss: 0.5056121945381165, Acc: 0.75\n",
      "Epoch: 2537, Loss: 0.6230586767196655, Acc: 0.78125\n",
      "Epoch: 2538, Loss: 0.5540866255760193, Acc: 0.78125\n",
      "Epoch: 2539, Loss: 0.8733288049697876, Acc: 0.65625\n",
      "Epoch: 2540, Loss: 0.557268500328064, Acc: 0.8125\n",
      "Epoch: 2541, Loss: 0.6844924688339233, Acc: 0.6875\n",
      "Epoch: 2542, Loss: 0.5033071637153625, Acc: 0.8125\n",
      "Epoch: 2543, Loss: 0.5455383062362671, Acc: 0.78125\n",
      "Epoch: 2544, Loss: 0.5536675453186035, Acc: 0.75\n",
      "Epoch: 2545, Loss: 0.4055151045322418, Acc: 0.84375\n",
      "Epoch: 2546, Loss: 0.5894029140472412, Acc: 0.84375\n",
      "Epoch: 2547, Loss: 0.33211877942085266, Acc: 0.9375\n",
      "Epoch: 2548, Loss: 0.6428318619728088, Acc: 0.75\n",
      "Epoch: 2549, Loss: 0.8346854448318481, Acc: 0.71875\n",
      "Epoch: 2550, Loss: 0.5077226758003235, Acc: 0.78125\n",
      "Epoch: 2551, Loss: 0.48979243636131287, Acc: 0.84375\n",
      "Epoch: 2552, Loss: 0.6907106041908264, Acc: 0.65625\n",
      "Epoch: 2553, Loss: 0.400368332862854, Acc: 0.875\n",
      "Epoch: 2554, Loss: 0.587067186832428, Acc: 0.8125\n",
      "Epoch: 2555, Loss: 0.6708961725234985, Acc: 0.75\n",
      "Epoch: 2556, Loss: 0.6234205961227417, Acc: 0.75\n",
      "Epoch: 2557, Loss: 0.3722461462020874, Acc: 0.90625\n",
      "Epoch: 2558, Loss: 0.5432463884353638, Acc: 0.78125\n",
      "Epoch: 2559, Loss: 0.8526869416236877, Acc: 0.75\n",
      "Epoch: 2560, Loss: 0.6342585682868958, Acc: 0.75\n",
      "Epoch: 2561, Loss: 0.5796266198158264, Acc: 0.84375\n",
      "Epoch: 2562, Loss: 0.7139959931373596, Acc: 0.8125\n",
      "Epoch: 2563, Loss: 0.5231432914733887, Acc: 0.8125\n",
      "Epoch: 2564, Loss: 0.6342513561248779, Acc: 0.84375\n",
      "Epoch: 2565, Loss: 0.4687369763851166, Acc: 0.84375\n",
      "Epoch: 2566, Loss: 0.8160004019737244, Acc: 0.75\n",
      "Epoch: 2567, Loss: 0.7845619916915894, Acc: 0.625\n",
      "Epoch: 2568, Loss: 0.8195081353187561, Acc: 0.78125\n",
      "Epoch: 2569, Loss: 0.6026763319969177, Acc: 0.78125\n",
      "Epoch: 2570, Loss: 0.6747828125953674, Acc: 0.78125\n",
      "Epoch: 2571, Loss: 0.5423073172569275, Acc: 0.75\n",
      "Epoch: 2572, Loss: 0.4999139904975891, Acc: 0.84375\n",
      "Epoch: 2573, Loss: 1.0087708234786987, Acc: 0.75\n",
      "Epoch: 2574, Loss: 0.3970769941806793, Acc: 0.875\n",
      "Epoch: 2575, Loss: 0.9418798685073853, Acc: 0.78125\n",
      "Epoch: 2576, Loss: 0.8696761727333069, Acc: 0.71875\n",
      "Epoch: 2577, Loss: 0.4217366576194763, Acc: 0.875\n",
      "Epoch: 2578, Loss: 0.5522342920303345, Acc: 0.78125\n",
      "Epoch: 2579, Loss: 0.5899807214736938, Acc: 0.84375\n",
      "Epoch: 2580, Loss: 0.3483588695526123, Acc: 0.84375\n",
      "Epoch: 2581, Loss: 0.36414846777915955, Acc: 0.84375\n",
      "Epoch: 2582, Loss: 0.6540977358818054, Acc: 0.78125\n",
      "Epoch: 2583, Loss: 0.6125397086143494, Acc: 0.84375\n",
      "Epoch: 2584, Loss: 0.5368268489837646, Acc: 0.8125\n",
      "Epoch: 2585, Loss: 0.3851291835308075, Acc: 0.84375\n",
      "Epoch: 2586, Loss: 0.7822173237800598, Acc: 0.8125\n",
      "Epoch: 2587, Loss: 0.8467363715171814, Acc: 0.71875\n",
      "Epoch: 2588, Loss: 0.46115049719810486, Acc: 0.875\n",
      "Epoch: 2589, Loss: 0.4600447118282318, Acc: 0.84375\n",
      "Epoch: 2590, Loss: 0.4955524206161499, Acc: 0.875\n",
      "Epoch: 2591, Loss: 0.46114540100097656, Acc: 0.8125\n",
      "Epoch: 2592, Loss: 0.5164569616317749, Acc: 0.78125\n",
      "Epoch: 2593, Loss: 0.4931933879852295, Acc: 0.875\n",
      "Epoch: 2594, Loss: 0.672793984413147, Acc: 0.75\n",
      "Epoch: 2595, Loss: 0.684227705001831, Acc: 0.71875\n",
      "Epoch: 2596, Loss: 0.49352315068244934, Acc: 0.84375\n",
      "Epoch: 2597, Loss: 0.45867758989334106, Acc: 0.8125\n",
      "Epoch: 2598, Loss: 0.7504335045814514, Acc: 0.71875\n",
      "Epoch: 2599, Loss: 0.5958507061004639, Acc: 0.71875\n",
      "Epoch: 2600, Loss: 0.5937800407409668, Acc: 0.75\n",
      "Epoch: 2601, Loss: 1.1869107484817505, Acc: 0.625\n",
      "Epoch: 2602, Loss: 0.36487579345703125, Acc: 0.84375\n",
      "Epoch: 2603, Loss: 0.415424644947052, Acc: 0.875\n",
      "Epoch: 2604, Loss: 1.1031808853149414, Acc: 0.625\n",
      "Epoch: 2605, Loss: 0.7503884434700012, Acc: 0.8125\n",
      "Epoch: 2606, Loss: 0.7615992426872253, Acc: 0.78125\n",
      "Epoch: 2607, Loss: 0.4418123960494995, Acc: 0.8125\n",
      "Epoch: 2608, Loss: 0.859914243221283, Acc: 0.8125\n",
      "Epoch: 2609, Loss: 0.7732613682746887, Acc: 0.78125\n",
      "Epoch: 2610, Loss: 0.5550151467323303, Acc: 0.78125\n",
      "Epoch: 2611, Loss: 1.0563809871673584, Acc: 0.71875\n",
      "Epoch: 2612, Loss: 0.4907650351524353, Acc: 0.875\n",
      "Epoch: 2613, Loss: 0.7192397713661194, Acc: 0.8125\n",
      "Epoch: 2614, Loss: 0.5922912955284119, Acc: 0.78125\n",
      "Epoch: 2615, Loss: 0.6826672554016113, Acc: 0.8125\n",
      "Epoch: 2616, Loss: 0.690457820892334, Acc: 0.84375\n",
      "Epoch: 2617, Loss: 0.608903706073761, Acc: 0.75\n",
      "Epoch: 2618, Loss: 0.8028638362884521, Acc: 0.78125\n",
      "Epoch: 2619, Loss: 0.7992933392524719, Acc: 0.6875\n",
      "Epoch: 2620, Loss: 0.6225117444992065, Acc: 0.75\n",
      "Epoch: 2621, Loss: 0.7311000227928162, Acc: 0.78125\n",
      "Epoch: 2622, Loss: 0.5073896646499634, Acc: 0.84375\n",
      "Epoch: 2623, Loss: 0.8377188444137573, Acc: 0.6875\n",
      "Epoch: 2624, Loss: 0.897844135761261, Acc: 0.6875\n",
      "Epoch: 2625, Loss: 0.4593714773654938, Acc: 0.78125\n",
      "Epoch: 2626, Loss: 0.4023992717266083, Acc: 0.84375\n",
      "Epoch: 2627, Loss: 0.5654668807983398, Acc: 0.75\n",
      "Epoch: 2628, Loss: 0.5734105110168457, Acc: 0.75\n",
      "Epoch: 2629, Loss: 0.803674578666687, Acc: 0.6875\n",
      "Epoch: 2630, Loss: 0.7577314376831055, Acc: 0.6875\n",
      "Epoch: 2631, Loss: 0.5979674458503723, Acc: 0.78125\n",
      "Epoch: 2632, Loss: 0.5240093469619751, Acc: 0.8125\n",
      "Epoch: 2633, Loss: 0.9801739454269409, Acc: 0.6875\n",
      "Epoch: 2634, Loss: 0.4541670083999634, Acc: 0.8125\n",
      "Epoch: 2635, Loss: 0.5968002676963806, Acc: 0.78125\n",
      "Epoch: 2636, Loss: 0.6762587428092957, Acc: 0.75\n",
      "Epoch: 2637, Loss: 0.578338086605072, Acc: 0.78125\n",
      "Epoch: 2638, Loss: 0.7105849981307983, Acc: 0.78125\n",
      "Epoch: 2639, Loss: 0.35069990158081055, Acc: 0.90625\n",
      "Epoch: 2640, Loss: 0.6410949230194092, Acc: 0.78125\n",
      "Epoch: 2641, Loss: 0.8198949098587036, Acc: 0.71875\n",
      "Epoch: 2642, Loss: 0.2808874249458313, Acc: 0.90625\n",
      "Epoch: 2643, Loss: 0.3786301612854004, Acc: 0.875\n",
      "Epoch: 2644, Loss: 0.68220454454422, Acc: 0.78125\n",
      "Epoch: 2645, Loss: 0.41173404455184937, Acc: 0.875\n",
      "Epoch: 2646, Loss: 0.7268882989883423, Acc: 0.84375\n",
      "Epoch: 2647, Loss: 0.5104125738143921, Acc: 0.78125\n",
      "Epoch: 2648, Loss: 0.6197691559791565, Acc: 0.78125\n",
      "Epoch: 2649, Loss: 0.67549067735672, Acc: 0.875\n",
      "Epoch: 2650, Loss: 0.7321094274520874, Acc: 0.84375\n",
      "Epoch: 2651, Loss: 0.39280208945274353, Acc: 0.875\n",
      "Epoch: 2652, Loss: 0.6097520589828491, Acc: 0.875\n",
      "Epoch: 2653, Loss: 1.054781436920166, Acc: 0.71875\n",
      "Epoch: 2654, Loss: 0.5851388573646545, Acc: 0.875\n",
      "Epoch: 2655, Loss: 0.6926308870315552, Acc: 0.75\n",
      "Epoch: 2656, Loss: 0.49384915828704834, Acc: 0.90625\n",
      "Epoch: 2657, Loss: 0.33197447657585144, Acc: 0.875\n",
      "Epoch: 2658, Loss: 0.5930750966072083, Acc: 0.78125\n",
      "Epoch: 2659, Loss: 0.43238329887390137, Acc: 0.84375\n",
      "Epoch: 2660, Loss: 0.557671070098877, Acc: 0.84375\n",
      "Epoch: 2661, Loss: 0.6912779808044434, Acc: 0.75\n",
      "Epoch: 2662, Loss: 0.5956306457519531, Acc: 0.8125\n",
      "Epoch: 2663, Loss: 0.6823649406433105, Acc: 0.8125\n",
      "Epoch: 2664, Loss: 0.4150248169898987, Acc: 0.90625\n",
      "Epoch: 2665, Loss: 0.38189321756362915, Acc: 0.90625\n",
      "Epoch: 2666, Loss: 0.6001782417297363, Acc: 0.78125\n",
      "Epoch: 2667, Loss: 0.39627310633659363, Acc: 0.84375\n",
      "Epoch: 2668, Loss: 0.47616687417030334, Acc: 0.78125\n",
      "Epoch: 2669, Loss: 0.6506726741790771, Acc: 0.75\n",
      "Epoch: 2670, Loss: 0.5166891813278198, Acc: 0.78125\n",
      "Epoch: 2671, Loss: 0.5236495137214661, Acc: 0.84375\n",
      "Epoch: 2672, Loss: 0.8283578753471375, Acc: 0.71875\n",
      "Epoch: 2673, Loss: 0.5196982622146606, Acc: 0.8125\n",
      "Epoch: 2674, Loss: 0.6471240520477295, Acc: 0.71875\n",
      "Epoch: 2675, Loss: 0.8019152283668518, Acc: 0.75\n",
      "Epoch: 2676, Loss: 0.7370055317878723, Acc: 0.78125\n",
      "Epoch: 2677, Loss: 0.332171767950058, Acc: 0.875\n",
      "Epoch: 2678, Loss: 0.2743733525276184, Acc: 0.9375\n",
      "Epoch: 2679, Loss: 0.5236873626708984, Acc: 0.78125\n",
      "Epoch: 2680, Loss: 0.8798413872718811, Acc: 0.6875\n",
      "Epoch: 2681, Loss: 0.5365111231803894, Acc: 0.84375\n",
      "Epoch: 2682, Loss: 0.7307912707328796, Acc: 0.6875\n",
      "Epoch: 2683, Loss: 0.3451029360294342, Acc: 0.84375\n",
      "Epoch: 2684, Loss: 0.34646984934806824, Acc: 0.875\n",
      "Epoch: 2685, Loss: 0.5841702818870544, Acc: 0.78125\n",
      "Epoch: 2686, Loss: 0.2759329080581665, Acc: 0.90625\n",
      "Epoch: 2687, Loss: 0.9202796816825867, Acc: 0.65625\n",
      "Epoch: 2688, Loss: 0.461725652217865, Acc: 0.78125\n",
      "Epoch: 2689, Loss: 0.8132229447364807, Acc: 0.6875\n",
      "Epoch: 2690, Loss: 0.574821949005127, Acc: 0.78125\n",
      "Epoch: 2691, Loss: 0.7174832224845886, Acc: 0.75\n",
      "Epoch: 2692, Loss: 0.7136421203613281, Acc: 0.75\n",
      "Epoch: 2693, Loss: 0.48384809494018555, Acc: 0.875\n",
      "Epoch: 2694, Loss: 0.5870599746704102, Acc: 0.75\n",
      "Epoch: 2695, Loss: 0.7691381573677063, Acc: 0.6875\n",
      "Epoch: 2696, Loss: 0.7670424580574036, Acc: 0.78125\n",
      "Epoch: 2697, Loss: 0.6106442809104919, Acc: 0.78125\n",
      "Epoch: 2698, Loss: 0.7374674081802368, Acc: 0.8125\n",
      "Epoch: 2699, Loss: 0.6063202023506165, Acc: 0.75\n",
      "Epoch: 2700, Loss: 0.3546997606754303, Acc: 0.84375\n",
      "Epoch: 2701, Loss: 0.3498839735984802, Acc: 0.875\n",
      "Epoch: 2702, Loss: 0.6214780807495117, Acc: 0.71875\n",
      "Epoch: 2703, Loss: 1.0238910913467407, Acc: 0.78125\n",
      "Epoch: 2704, Loss: 0.38363441824913025, Acc: 0.875\n",
      "Epoch: 2705, Loss: 0.7745513319969177, Acc: 0.75\n",
      "Epoch: 2706, Loss: 0.7399410009384155, Acc: 0.6875\n",
      "Epoch: 2707, Loss: 0.4369179606437683, Acc: 0.875\n",
      "Epoch: 2708, Loss: 0.6155869364738464, Acc: 0.84375\n",
      "Epoch: 2709, Loss: 0.5685803890228271, Acc: 0.84375\n",
      "Epoch: 2710, Loss: 0.3508956730365753, Acc: 0.9375\n",
      "Epoch: 2711, Loss: 0.7328299880027771, Acc: 0.78125\n",
      "Epoch: 2712, Loss: 0.6586526036262512, Acc: 0.75\n",
      "Epoch: 2713, Loss: 0.507055401802063, Acc: 0.90625\n",
      "Epoch: 2714, Loss: 0.8497579097747803, Acc: 0.84375\n",
      "Epoch: 2715, Loss: 0.6951268315315247, Acc: 0.75\n",
      "Epoch: 2716, Loss: 0.23738254606723785, Acc: 0.96875\n",
      "Epoch: 2717, Loss: 0.6133691072463989, Acc: 0.8125\n",
      "Epoch: 2718, Loss: 0.3237099349498749, Acc: 0.90625\n",
      "Epoch: 2719, Loss: 0.7462607622146606, Acc: 0.8125\n",
      "Epoch: 2720, Loss: 0.20724932849407196, Acc: 0.9375\n",
      "Epoch: 2721, Loss: 0.7235620021820068, Acc: 0.78125\n",
      "Epoch: 2722, Loss: 0.4928714334964752, Acc: 0.84375\n",
      "Epoch: 2723, Loss: 0.6456926465034485, Acc: 0.75\n",
      "Epoch: 2724, Loss: 0.7453657984733582, Acc: 0.78125\n",
      "Epoch: 2725, Loss: 0.28956103324890137, Acc: 0.9375\n",
      "Epoch: 2726, Loss: 0.7975642085075378, Acc: 0.78125\n",
      "Epoch: 2727, Loss: 0.8041033744812012, Acc: 0.78125\n",
      "Epoch: 2728, Loss: 0.5377262830734253, Acc: 0.8125\n",
      "Epoch: 2729, Loss: 0.6693194508552551, Acc: 0.78125\n",
      "Epoch: 2730, Loss: 0.491914838552475, Acc: 0.8125\n",
      "Epoch: 2731, Loss: 0.865359902381897, Acc: 0.71875\n",
      "Epoch: 2732, Loss: 0.5312104225158691, Acc: 0.71875\n",
      "Epoch: 2733, Loss: 0.6512329578399658, Acc: 0.78125\n",
      "Epoch: 2734, Loss: 0.808738112449646, Acc: 0.6875\n",
      "Epoch: 2735, Loss: 0.7666332721710205, Acc: 0.71875\n",
      "Epoch: 2736, Loss: 0.41017425060272217, Acc: 0.90625\n",
      "Epoch: 2737, Loss: 0.22494563460350037, Acc: 0.96875\n",
      "Epoch: 2738, Loss: 0.6030462384223938, Acc: 0.8125\n",
      "Epoch: 2739, Loss: 0.701236367225647, Acc: 0.8125\n",
      "Epoch: 2740, Loss: 0.8699421882629395, Acc: 0.6875\n",
      "Epoch: 2741, Loss: 0.40385720133781433, Acc: 0.875\n",
      "Epoch: 2742, Loss: 0.4458296000957489, Acc: 0.875\n",
      "Epoch: 2743, Loss: 0.31262704730033875, Acc: 0.90625\n",
      "Epoch: 2744, Loss: 0.5825687646865845, Acc: 0.8125\n",
      "Epoch: 2745, Loss: 0.4856959283351898, Acc: 0.8125\n",
      "Epoch: 2746, Loss: 0.5916694402694702, Acc: 0.84375\n",
      "Epoch: 2747, Loss: 0.5947848558425903, Acc: 0.78125\n",
      "Epoch: 2748, Loss: 0.5311302542686462, Acc: 0.71875\n",
      "Epoch: 2749, Loss: 0.4738711416721344, Acc: 0.84375\n",
      "Epoch: 2750, Loss: 0.3647708296775818, Acc: 0.875\n",
      "Epoch: 2751, Loss: 0.7453765869140625, Acc: 0.78125\n",
      "Epoch: 2752, Loss: 0.2895664572715759, Acc: 0.90625\n",
      "Epoch: 2753, Loss: 0.5812762975692749, Acc: 0.84375\n",
      "Epoch: 2754, Loss: 1.0037177801132202, Acc: 0.53125\n",
      "Epoch: 2755, Loss: 0.7190262675285339, Acc: 0.78125\n",
      "Epoch: 2756, Loss: 0.6949096322059631, Acc: 0.78125\n",
      "Epoch: 2757, Loss: 0.5812715291976929, Acc: 0.78125\n",
      "Epoch: 2758, Loss: 0.6385015249252319, Acc: 0.71875\n",
      "Epoch: 2759, Loss: 0.6935442090034485, Acc: 0.75\n",
      "Epoch: 2760, Loss: 0.4408959746360779, Acc: 0.875\n",
      "Epoch: 2761, Loss: 0.8104987144470215, Acc: 0.78125\n",
      "Epoch: 2762, Loss: 0.3793184161186218, Acc: 0.90625\n",
      "Epoch: 2763, Loss: 0.5580414533615112, Acc: 0.875\n",
      "Epoch: 2764, Loss: 0.7436987161636353, Acc: 0.71875\n",
      "Epoch: 2765, Loss: 0.31373751163482666, Acc: 0.9375\n",
      "Epoch: 2766, Loss: 0.6735658645629883, Acc: 0.78125\n",
      "Epoch: 2767, Loss: 0.42835310101509094, Acc: 0.78125\n",
      "Epoch: 2768, Loss: 0.6016731262207031, Acc: 0.8125\n",
      "Epoch: 2769, Loss: 0.7141396403312683, Acc: 0.71875\n",
      "Epoch: 2770, Loss: 0.5984953045845032, Acc: 0.84375\n",
      "Epoch: 2771, Loss: 0.4717928171157837, Acc: 0.78125\n",
      "Epoch: 2772, Loss: 0.501850962638855, Acc: 0.84375\n",
      "Epoch: 2773, Loss: 0.5775453448295593, Acc: 0.84375\n",
      "Epoch: 2774, Loss: 0.2131699174642563, Acc: 0.90625\n",
      "Epoch: 2775, Loss: 0.4900434613227844, Acc: 0.84375\n",
      "Epoch: 2776, Loss: 0.4338769316673279, Acc: 0.84375\n",
      "Epoch: 2777, Loss: 0.7015188932418823, Acc: 0.75\n",
      "Epoch: 2778, Loss: 0.7834270596504211, Acc: 0.78125\n",
      "Epoch: 2779, Loss: 0.5258815884590149, Acc: 0.8125\n",
      "Epoch: 2780, Loss: 1.0332016944885254, Acc: 0.59375\n",
      "Epoch: 2781, Loss: 0.844588041305542, Acc: 0.625\n",
      "Epoch: 2782, Loss: 0.34471622109413147, Acc: 0.90625\n",
      "Epoch: 2783, Loss: 0.6827229261398315, Acc: 0.71875\n",
      "Epoch: 2784, Loss: 0.4934493601322174, Acc: 0.8125\n",
      "Epoch: 2785, Loss: 0.4621894061565399, Acc: 0.8125\n",
      "Epoch: 2786, Loss: 0.4678332805633545, Acc: 0.875\n",
      "Epoch: 2787, Loss: 0.7746371030807495, Acc: 0.78125\n",
      "Epoch: 2788, Loss: 0.7924313545227051, Acc: 0.75\n",
      "Epoch: 2789, Loss: 0.31399399042129517, Acc: 0.875\n",
      "Epoch: 2790, Loss: 0.43141883611679077, Acc: 0.875\n",
      "Epoch: 2791, Loss: 0.5933071970939636, Acc: 0.84375\n",
      "Epoch: 2792, Loss: 0.5719360709190369, Acc: 0.78125\n",
      "Epoch: 2793, Loss: 0.4379029870033264, Acc: 0.875\n",
      "Epoch: 2794, Loss: 0.7148952484130859, Acc: 0.8125\n",
      "Epoch: 2795, Loss: 0.5577279329299927, Acc: 0.875\n",
      "Epoch: 2796, Loss: 0.64790940284729, Acc: 0.84375\n",
      "Epoch: 2797, Loss: 0.615017831325531, Acc: 0.8125\n",
      "Epoch: 2798, Loss: 0.3674898147583008, Acc: 0.84375\n",
      "Epoch: 2799, Loss: 0.4204143285751343, Acc: 0.84375\n",
      "Epoch: 2800, Loss: 1.2806661128997803, Acc: 0.5625\n",
      "Epoch: 2801, Loss: 0.40444397926330566, Acc: 0.90625\n",
      "Epoch: 2802, Loss: 0.502933144569397, Acc: 0.84375\n",
      "Epoch: 2803, Loss: 0.7298921942710876, Acc: 0.78125\n",
      "Epoch: 2804, Loss: 0.6853945255279541, Acc: 0.6875\n",
      "Epoch: 2805, Loss: 0.6601738929748535, Acc: 0.8125\n",
      "Epoch: 2806, Loss: 0.7503378391265869, Acc: 0.75\n",
      "Epoch: 2807, Loss: 0.42896732687950134, Acc: 0.9375\n",
      "Epoch: 2808, Loss: 0.6104298233985901, Acc: 0.71875\n",
      "Epoch: 2809, Loss: 0.29841065406799316, Acc: 0.90625\n",
      "Epoch: 2810, Loss: 0.631597101688385, Acc: 0.84375\n",
      "Epoch: 2811, Loss: 0.6797914505004883, Acc: 0.71875\n",
      "Epoch: 2812, Loss: 0.478346049785614, Acc: 0.875\n",
      "Epoch: 2813, Loss: 0.6697471141815186, Acc: 0.6875\n",
      "Epoch: 2814, Loss: 0.6975043416023254, Acc: 0.84375\n",
      "Epoch: 2815, Loss: 0.8394830822944641, Acc: 0.75\n",
      "Epoch: 2816, Loss: 0.3511490225791931, Acc: 0.84375\n",
      "Epoch: 2817, Loss: 0.7315546870231628, Acc: 0.78125\n",
      "Epoch: 2818, Loss: 0.8898645043373108, Acc: 0.71875\n",
      "Epoch: 2819, Loss: 0.5854085087776184, Acc: 0.75\n",
      "Epoch: 2820, Loss: 0.39228251576423645, Acc: 0.875\n",
      "Epoch: 2821, Loss: 0.5035410523414612, Acc: 0.8125\n",
      "Epoch: 2822, Loss: 0.47153347730636597, Acc: 0.84375\n",
      "Epoch: 2823, Loss: 0.6690314412117004, Acc: 0.8125\n",
      "Epoch: 2824, Loss: 0.4355277419090271, Acc: 0.875\n",
      "Epoch: 2825, Loss: 0.6236032247543335, Acc: 0.875\n",
      "Epoch: 2826, Loss: 0.9172369241714478, Acc: 0.71875\n",
      "Epoch: 2827, Loss: 0.5110125541687012, Acc: 0.78125\n",
      "Epoch: 2828, Loss: 1.0539088249206543, Acc: 0.6875\n",
      "Epoch: 2829, Loss: 0.3817906081676483, Acc: 0.875\n",
      "Epoch: 2830, Loss: 0.5233218669891357, Acc: 0.84375\n",
      "Epoch: 2831, Loss: 0.3851880729198456, Acc: 0.8125\n",
      "Epoch: 2832, Loss: 0.6076647043228149, Acc: 0.78125\n",
      "Epoch: 2833, Loss: 0.40294232964515686, Acc: 0.8125\n",
      "Epoch: 2834, Loss: 0.5922239422798157, Acc: 0.78125\n",
      "Epoch: 2835, Loss: 1.0072953701019287, Acc: 0.71875\n",
      "Epoch: 2836, Loss: 0.4734322726726532, Acc: 0.875\n",
      "Epoch: 2837, Loss: 0.6259376406669617, Acc: 0.71875\n",
      "Epoch: 2838, Loss: 0.8468756079673767, Acc: 0.6875\n",
      "Epoch: 2839, Loss: 0.6956530213356018, Acc: 0.75\n",
      "Epoch: 2840, Loss: 0.6114379167556763, Acc: 0.75\n",
      "Epoch: 2841, Loss: 0.47251754999160767, Acc: 0.875\n",
      "Epoch: 2842, Loss: 0.4419204890727997, Acc: 0.78125\n",
      "Epoch: 2843, Loss: 0.4425692558288574, Acc: 0.84375\n",
      "Epoch: 2844, Loss: 1.0304566621780396, Acc: 0.5625\n",
      "Epoch: 2845, Loss: 0.5023253560066223, Acc: 0.84375\n",
      "Epoch: 2846, Loss: 0.5055193901062012, Acc: 0.90625\n",
      "Epoch: 2847, Loss: 0.32642605900764465, Acc: 0.90625\n",
      "Epoch: 2848, Loss: 0.6651087999343872, Acc: 0.75\n",
      "Epoch: 2849, Loss: 0.49538400769233704, Acc: 0.8125\n",
      "Epoch: 2850, Loss: 0.5988064408302307, Acc: 0.78125\n",
      "Epoch: 2851, Loss: 0.29417356848716736, Acc: 0.875\n",
      "Epoch: 2852, Loss: 0.7107173800468445, Acc: 0.75\n",
      "Epoch: 2853, Loss: 0.35031890869140625, Acc: 0.90625\n",
      "Epoch: 2854, Loss: 0.6851122379302979, Acc: 0.75\n",
      "Epoch: 2855, Loss: 0.40174660086631775, Acc: 0.875\n",
      "Epoch: 2856, Loss: 0.22936908900737762, Acc: 0.90625\n",
      "Epoch: 2857, Loss: 0.5763018727302551, Acc: 0.78125\n",
      "Epoch: 2858, Loss: 0.5524860620498657, Acc: 0.75\n",
      "Epoch: 2859, Loss: 0.6975539922714233, Acc: 0.8125\n",
      "Epoch: 2860, Loss: 0.7725731134414673, Acc: 0.8125\n",
      "Epoch: 2861, Loss: 0.4244835078716278, Acc: 0.84375\n",
      "Epoch: 2862, Loss: 0.8670845031738281, Acc: 0.71875\n",
      "Epoch: 2863, Loss: 0.6891229748725891, Acc: 0.75\n",
      "Epoch: 2864, Loss: 0.48980632424354553, Acc: 0.875\n",
      "Epoch: 2865, Loss: 1.0110167264938354, Acc: 0.53125\n",
      "Epoch: 2866, Loss: 0.5163750648498535, Acc: 0.78125\n",
      "Epoch: 2867, Loss: 0.7566553950309753, Acc: 0.78125\n",
      "Epoch: 2868, Loss: 0.5117568969726562, Acc: 0.90625\n",
      "Epoch: 2869, Loss: 0.7354289293289185, Acc: 0.65625\n",
      "Epoch: 2870, Loss: 0.461128294467926, Acc: 0.875\n",
      "Epoch: 2871, Loss: 0.43640750646591187, Acc: 0.8125\n",
      "Epoch: 2872, Loss: 0.7387885451316833, Acc: 0.71875\n",
      "Epoch: 2873, Loss: 0.22471533715724945, Acc: 0.9375\n",
      "Epoch: 2874, Loss: 0.4845399856567383, Acc: 0.84375\n",
      "Epoch: 2875, Loss: 0.3743671774864197, Acc: 0.90625\n",
      "Epoch: 2876, Loss: 0.6585972309112549, Acc: 0.71875\n",
      "Epoch: 2877, Loss: 0.648613452911377, Acc: 0.84375\n",
      "Epoch: 2878, Loss: 0.46975648403167725, Acc: 0.8125\n",
      "Epoch: 2879, Loss: 0.6246381998062134, Acc: 0.8125\n",
      "Epoch: 2880, Loss: 0.6198522448539734, Acc: 0.6875\n",
      "Epoch: 2881, Loss: 0.7120025157928467, Acc: 0.75\n",
      "Epoch: 2882, Loss: 0.7790616154670715, Acc: 0.75\n",
      "Epoch: 2883, Loss: 0.5417628288269043, Acc: 0.8125\n",
      "Epoch: 2884, Loss: 0.46243762969970703, Acc: 0.8125\n",
      "Epoch: 2885, Loss: 0.3468471169471741, Acc: 0.84375\n",
      "Epoch: 2886, Loss: 0.4691879451274872, Acc: 0.8125\n",
      "Epoch: 2887, Loss: 0.5534006357192993, Acc: 0.8125\n",
      "Epoch: 2888, Loss: 0.3383606970310211, Acc: 0.90625\n",
      "Epoch: 2889, Loss: 0.4421963095664978, Acc: 0.90625\n",
      "Epoch: 2890, Loss: 0.9265327453613281, Acc: 0.65625\n",
      "Epoch: 2891, Loss: 0.28744733333587646, Acc: 0.9375\n",
      "Epoch: 2892, Loss: 0.4159439206123352, Acc: 0.84375\n",
      "Epoch: 2893, Loss: 0.8137297034263611, Acc: 0.75\n",
      "Epoch: 2894, Loss: 0.45517587661743164, Acc: 0.84375\n",
      "Epoch: 2895, Loss: 0.4819916784763336, Acc: 0.90625\n",
      "Epoch: 2896, Loss: 0.7659990787506104, Acc: 0.75\n",
      "Epoch: 2897, Loss: 0.6187762022018433, Acc: 0.84375\n",
      "Epoch: 2898, Loss: 0.5637307167053223, Acc: 0.78125\n",
      "Epoch: 2899, Loss: 0.6733715534210205, Acc: 0.71875\n",
      "Epoch: 2900, Loss: 0.552458643913269, Acc: 0.875\n",
      "Epoch: 2901, Loss: 0.5759701132774353, Acc: 0.78125\n",
      "Epoch: 2902, Loss: 0.4621839225292206, Acc: 0.875\n",
      "Epoch: 2903, Loss: 0.7013794183731079, Acc: 0.875\n",
      "Epoch: 2904, Loss: 0.3965880870819092, Acc: 0.84375\n",
      "Epoch: 2905, Loss: 0.33145931363105774, Acc: 0.9375\n",
      "Epoch: 2906, Loss: 0.3612336218357086, Acc: 0.90625\n",
      "Epoch: 2907, Loss: 0.6026018261909485, Acc: 0.8125\n",
      "Epoch: 2908, Loss: 0.3957066535949707, Acc: 0.90625\n",
      "Epoch: 2909, Loss: 0.5216509103775024, Acc: 0.8125\n",
      "Epoch: 2910, Loss: 0.6929142475128174, Acc: 0.71875\n",
      "Epoch: 2911, Loss: 0.6172782778739929, Acc: 0.78125\n",
      "Epoch: 2912, Loss: 0.4411536157131195, Acc: 0.875\n",
      "Epoch: 2913, Loss: 0.46139881014823914, Acc: 0.8125\n",
      "Epoch: 2914, Loss: 0.42688530683517456, Acc: 0.84375\n",
      "Epoch: 2915, Loss: 0.7646728754043579, Acc: 0.8125\n",
      "Epoch: 2916, Loss: 0.5794197916984558, Acc: 0.78125\n",
      "Epoch: 2917, Loss: 0.6027083992958069, Acc: 0.8125\n",
      "Epoch: 2918, Loss: 0.36399367451667786, Acc: 0.9375\n",
      "Epoch: 2919, Loss: 0.9773303270339966, Acc: 0.75\n",
      "Epoch: 2920, Loss: 1.0828791856765747, Acc: 0.6875\n",
      "Epoch: 2921, Loss: 1.0349637269973755, Acc: 0.71875\n",
      "Epoch: 2922, Loss: 0.520984947681427, Acc: 0.84375\n",
      "Epoch: 2923, Loss: 0.672798752784729, Acc: 0.875\n",
      "Epoch: 2924, Loss: 0.6642771363258362, Acc: 0.75\n",
      "Epoch: 2925, Loss: 0.5126021504402161, Acc: 0.78125\n",
      "Epoch: 2926, Loss: 0.4333450198173523, Acc: 0.8125\n",
      "Epoch: 2927, Loss: 0.7511104345321655, Acc: 0.78125\n",
      "Epoch: 2928, Loss: 0.6366743445396423, Acc: 0.8125\n",
      "Epoch: 2929, Loss: 0.9314596056938171, Acc: 0.75\n",
      "Epoch: 2930, Loss: 0.36554160714149475, Acc: 0.875\n",
      "Epoch: 2931, Loss: 0.5708734393119812, Acc: 0.8125\n",
      "Epoch: 2932, Loss: 0.8625236749649048, Acc: 0.6875\n",
      "Epoch: 2933, Loss: 0.6056015491485596, Acc: 0.8125\n",
      "Epoch: 2934, Loss: 0.498503178358078, Acc: 0.875\n",
      "Epoch: 2935, Loss: 0.7035993933677673, Acc: 0.75\n",
      "Epoch: 2936, Loss: 1.0737378597259521, Acc: 0.6875\n",
      "Epoch: 2937, Loss: 0.8456376791000366, Acc: 0.8125\n",
      "Epoch: 2938, Loss: 0.22855190932750702, Acc: 0.9375\n",
      "Epoch: 2939, Loss: 0.33932802081108093, Acc: 0.875\n",
      "Epoch: 2940, Loss: 0.5057491660118103, Acc: 0.875\n",
      "Epoch: 2941, Loss: 0.5736625790596008, Acc: 0.9375\n",
      "Epoch: 2942, Loss: 0.8033259510993958, Acc: 0.65625\n",
      "Epoch: 2943, Loss: 0.7542158961296082, Acc: 0.8125\n",
      "Epoch: 2944, Loss: 0.8296939134597778, Acc: 0.75\n",
      "Epoch: 2945, Loss: 0.5645588040351868, Acc: 0.8125\n",
      "Epoch: 2946, Loss: 0.5769953727722168, Acc: 0.84375\n",
      "Epoch: 2947, Loss: 0.540984570980072, Acc: 0.875\n",
      "Epoch: 2948, Loss: 0.6146997809410095, Acc: 0.75\n",
      "Epoch: 2949, Loss: 0.5188222527503967, Acc: 0.875\n",
      "Epoch: 2950, Loss: 0.5126199126243591, Acc: 0.75\n",
      "Epoch: 2951, Loss: 0.4884181618690491, Acc: 0.875\n",
      "Epoch: 2952, Loss: 0.33054161071777344, Acc: 0.875\n",
      "Epoch: 2953, Loss: 0.34282782673835754, Acc: 0.875\n",
      "Epoch: 2954, Loss: 0.6674328446388245, Acc: 0.71875\n",
      "Epoch: 2955, Loss: 0.7072054147720337, Acc: 0.78125\n",
      "Epoch: 2956, Loss: 0.3946686089038849, Acc: 0.90625\n",
      "Epoch: 2957, Loss: 0.652895450592041, Acc: 0.8125\n",
      "Epoch: 2958, Loss: 0.4926814138889313, Acc: 0.875\n",
      "Epoch: 2959, Loss: 0.6279930472373962, Acc: 0.8125\n",
      "Epoch: 2960, Loss: 0.409801721572876, Acc: 0.90625\n",
      "Epoch: 2961, Loss: 0.509483814239502, Acc: 0.84375\n",
      "Epoch: 2962, Loss: 0.5627220869064331, Acc: 0.84375\n",
      "Epoch: 2963, Loss: 0.7795822620391846, Acc: 0.6875\n",
      "Epoch: 2964, Loss: 0.9565596580505371, Acc: 0.71875\n",
      "Epoch: 2965, Loss: 0.5666400194168091, Acc: 0.78125\n",
      "Epoch: 2966, Loss: 0.530072033405304, Acc: 0.84375\n",
      "Epoch: 2967, Loss: 0.6341280937194824, Acc: 0.71875\n",
      "Epoch: 2968, Loss: 0.7620419263839722, Acc: 0.71875\n",
      "Epoch: 2969, Loss: 0.434793084859848, Acc: 0.84375\n",
      "Epoch: 2970, Loss: 0.28595927357673645, Acc: 0.90625\n",
      "Epoch: 2971, Loss: 0.5021411180496216, Acc: 0.84375\n",
      "Epoch: 2972, Loss: 0.8382558226585388, Acc: 0.8125\n",
      "Epoch: 2973, Loss: 0.46176743507385254, Acc: 0.875\n",
      "Epoch: 2974, Loss: 0.5123724937438965, Acc: 0.875\n",
      "Epoch: 2975, Loss: 0.3568131625652313, Acc: 0.90625\n",
      "Epoch: 2976, Loss: 0.4938896596431732, Acc: 0.78125\n",
      "Epoch: 2977, Loss: 0.4370177686214447, Acc: 0.8125\n",
      "Epoch: 2978, Loss: 0.855399489402771, Acc: 0.6875\n",
      "Epoch: 2979, Loss: 0.7154454588890076, Acc: 0.78125\n",
      "Epoch: 2980, Loss: 0.5527793169021606, Acc: 0.78125\n",
      "Epoch: 2981, Loss: 0.5292157530784607, Acc: 0.78125\n",
      "Epoch: 2982, Loss: 0.9008767604827881, Acc: 0.71875\n",
      "Epoch: 2983, Loss: 0.5653978586196899, Acc: 0.875\n",
      "Epoch: 2984, Loss: 0.5811436772346497, Acc: 0.75\n",
      "Epoch: 2985, Loss: 0.8787844181060791, Acc: 0.75\n",
      "Epoch: 2986, Loss: 0.565750002861023, Acc: 0.75\n",
      "Epoch: 2987, Loss: 0.5591422319412231, Acc: 0.8125\n",
      "Epoch: 2988, Loss: 0.5311845541000366, Acc: 0.8125\n",
      "Epoch: 2989, Loss: 0.510973334312439, Acc: 0.78125\n",
      "Epoch: 2990, Loss: 0.8019733428955078, Acc: 0.78125\n",
      "Epoch: 2991, Loss: 0.9732640385627747, Acc: 0.71875\n",
      "Epoch: 2992, Loss: 0.47368064522743225, Acc: 0.84375\n",
      "Epoch: 2993, Loss: 0.4209071695804596, Acc: 0.875\n",
      "Epoch: 2994, Loss: 0.35571160912513733, Acc: 0.84375\n",
      "Epoch: 2995, Loss: 0.5578445792198181, Acc: 0.84375\n",
      "Epoch: 2996, Loss: 0.8478580117225647, Acc: 0.75\n",
      "Epoch: 2997, Loss: 0.8823716044425964, Acc: 0.75\n",
      "Epoch: 2998, Loss: 0.37016263604164124, Acc: 0.875\n",
      "Epoch: 2999, Loss: 0.9766486883163452, Acc: 0.6875\n"
     ]
    }
   ],
   "source": [
    "# Train state predictor\n",
    "def train_state_predictor_step(encoder, state_predictor, state_embedding, optim, grid_sz, b_sz, epochs):\n",
    "    for e in epochs: \n",
    "        start_positions, end_positions, actions, grid_positions = get_batch(grid_sz, b_sz)\n",
    "        sampled_states, next_states, sampled_acts, end_positions_ = sample_s_sn_act(grid_positions, actions, b_sz)\n",
    "        s_grids_input = make_grid(sampled_states, grid_sz, b_sz).unsqueeze(1)\n",
    "        g_grids_input = make_grid(end_positions_, grid_sz, b_sz).unsqueeze(1)\n",
    "\n",
    "        targets = grid_pos_to_idx(next_states, grid_sz)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            s = encoder(s_grids_input)\n",
    "            s_idx = torch.argmax(s @ state_embedding.weight.T, dim=1)\n",
    "            s_tokens = state_embedding(s_idx)\n",
    "            g = encoder(g_grids_input)\n",
    "            g_idx = torch.argmax(g @ state_embedding.weight.T, dim=1)\n",
    "            g_tokens = state_embedding(g_idx)\n",
    "        s_next_pred = state_predictor(torch.cat((s_tokens, g_tokens), dim=1))\n",
    "        logits = s_next_pred @ state_embedding.weight.T\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # accuracy \n",
    "        acc = (torch.argmax(logits, dim=1) == targets).float().mean()\n",
    "\n",
    "        print(f'Epoch: {e}, Loss: {loss.item()}, Acc: {acc.item()}')\n",
    "optim = torch.optim.Adam(list(state_predictor.parameters()), lr=1e-3)\n",
    "train_state_predictor_step(state_encoder, state_predictor, state_embedding, optim, grid_sz, b_sz, range(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save state_predictor\n",
    "torch.save(state_predictor.state_dict(), 'state_predictor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2]) torch.Size([32, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\msmic\\Documents\\code\\rl\\rl_goal_idm\\streaming.ipynb Cell 18\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/rl/rl_goal_idm/streaming.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m, Acc: \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/rl/rl_goal_idm/streaming.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m optim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\u001b[39mlist\u001b[39m(action_predictor\u001b[39m.\u001b[39mparameters()), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/rl/rl_goal_idm/streaming.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m train_action_predictor_step(state_encoder, state_predictor, action_predictor, state_embedding, optim, grid_sz, b_sz, \u001b[39mrange\u001b[39;49m(\u001b[39m3000\u001b[39;49m))\n",
      "\u001b[1;32mc:\\Users\\msmic\\Documents\\code\\rl\\rl_goal_idm\\streaming.ipynb Cell 18\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/rl/rl_goal_idm/streaming.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     next_sim_logits \u001b[39m=\u001b[39m next_sim_states \u001b[39m@\u001b[39m state_embedding\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mT\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/rl/rl_goal_idm/streaming.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(next_sim_logits, targets)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/rl/rl_goal_idm/streaming.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/rl/rl_goal_idm/streaming.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m optim\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/rl/rl_goal_idm/streaming.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# accuracy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msmic\\Documents\\code\\rl\\carla\\rl_ad\\env\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\msmic\\Documents\\code\\rl\\carla\\rl_ad\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Train action predictor\n",
    "def train_action_predictor_step(encoder, state_predictor, action_predictor, state_embedding, optim, grid_sz, b_sz, epochs):\n",
    "    for e in epochs:\n",
    "        start_positions, end_positions, actions, grid_positions = get_batch(grid_sz, b_sz)\n",
    "        sampled_states, next_states, sampled_acts, end_positions_ = sample_s_sn_act(grid_positions, actions, b_sz)\n",
    "        s_grids_input = make_grid(sampled_states, grid_sz, b_sz).unsqueeze(1)\n",
    "        g_grids_input = make_grid(end_positions_, grid_sz, b_sz).unsqueeze(1)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            s = encoder(s_grids_input)\n",
    "            g = encoder(g_grids_input)\n",
    "            s_next_pred = state_predictor(torch.cat((s, g), dim=1))\n",
    "            s_next_pred_logits = s_next_pred @ state_embedding.weight.T\n",
    "            targets = torch.argmax(s_next_pred_logits, dim=1)\n",
    "\n",
    "        act_pred = action_predictor(torch.cat((s, s_next_pred), dim=1))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_sim_states = simulate_next_state(sampled_states, torch.argmax(act_pred,dim=1), grid_sz).long()\n",
    "            next_sim_states = encoder(make_grid(next_sim_states, grid_sz, b_sz).unsqueeze(1))\n",
    "            next_sim_logits = next_sim_states @ state_embedding.weight.T\n",
    "        \n",
    "        loss = F.cross_entropy(next_sim_logits, targets)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # accuracy\n",
    "        acc = (torch.argmax(next_sim_logits, dim=1) == targets).float().mean()\n",
    "\n",
    "        print(f'Epoch: {e}, Loss: {loss.item()}, Acc: {acc.item()}')\n",
    "\n",
    "optim = torch.optim.Adam(list(action_predictor.parameters()), lr=1e-3)\n",
    "train_action_predictor_step(state_encoder, state_predictor, action_predictor, state_embedding, optim, grid_sz, b_sz, range(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_logits = action_predictor(torch.cat((s, s), dim=1))\n",
    "acts = torch.argmax(act_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2]) torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "next_sim_states = simulate_next_state(sampled_states, acts, grid_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 4],\n",
       "         [3, 6],\n",
       "         [5, 1],\n",
       "         [2, 7],\n",
       "         [2, 3]]),\n",
       " tensor([[1., 4.],\n",
       "         [4., 6.],\n",
       "         [6., 1.],\n",
       "         [3., 7.],\n",
       "         [3., 3.]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_states[:5], next_sim_states[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "obs_data = np.load('obs_data_cart.npy')\n",
    "next_obs_data = np.load('next_obs_data_cart.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-3.79725099e-02,  2.27987677e-01,  1.60504263e-02,\n",
       "        -3.10386598e-01],\n",
       "       [-3.34127583e-02,  3.26407701e-02,  9.84269381e-03,\n",
       "        -1.26853632e-02],\n",
       "       [-3.27599421e-02,  2.27620184e-01,  9.58898570e-03,\n",
       "        -3.02246630e-01],\n",
       "       [-2.82075368e-02,  3.23628969e-02,  3.54405376e-03,\n",
       "        -6.55502686e-03],\n",
       "       [-2.75602788e-02,  2.27433845e-01,  3.41295311e-03,\n",
       "        -2.98117667e-01],\n",
       "       [-2.30116025e-02,  3.22634056e-02, -2.54940009e-03,\n",
       "        -4.36030375e-03],\n",
       "       [-2.23663338e-02,  2.27421820e-01, -2.63660611e-03,\n",
       "        -2.97846496e-01],\n",
       "       [-1.78178977e-02,  3.23375575e-02, -8.59353598e-03,\n",
       "        -5.99628314e-03],\n",
       "       [-1.71711463e-02, -1.62660107e-01, -8.71346146e-03,\n",
       "         2.83962935e-01],\n",
       "       [-2.04243492e-02,  3.25850360e-02, -3.03420308e-03,\n",
       "        -1.14553766e-02],\n",
       "       [-1.97726488e-02,  2.27750376e-01, -3.26331053e-03,\n",
       "        -3.05094093e-01],\n",
       "       [-1.52176404e-02,  4.22918677e-01, -9.36519261e-03,\n",
       "        -5.98804414e-01],\n",
       "       [-6.75926730e-03,  2.27928996e-01, -2.13412810e-02,\n",
       "        -3.09086025e-01],\n",
       "       [-2.20068707e-03,  4.23348427e-01, -2.75230017e-02,\n",
       "        -6.08422279e-01],\n",
       "       [ 6.26628147e-03,  2.28621840e-01, -3.96914482e-02,\n",
       "        -3.24533790e-01],\n",
       "       [ 1.08387182e-02,  3.40868644e-02, -4.61821221e-02,\n",
       "        -4.46273535e-02],\n",
       "       [ 1.15204556e-02, -1.60343483e-01, -4.70746681e-02,\n",
       "         2.33134493e-01],\n",
       "       [ 8.31358600e-03, -3.54762286e-01, -4.24119793e-02,\n",
       "         5.10604799e-01],\n",
       "       [ 1.21834013e-03, -1.59069359e-01, -3.21998820e-02,\n",
       "         2.04863980e-01],\n",
       "       [-1.96304685e-03,  3.64979245e-02, -2.81026028e-02,\n",
       "        -9.78000015e-02],\n",
       "       [-1.23308843e-03,  2.32011139e-01, -3.00586037e-02,\n",
       "        -3.99215102e-01],\n",
       "       [ 3.40713421e-03,  3.73282060e-02, -3.80429067e-02,\n",
       "        -1.16158515e-01],\n",
       "       [ 4.15369822e-03, -1.57228589e-01, -4.03660759e-02,\n",
       "         1.64283603e-01],\n",
       "       [ 1.00912666e-03,  3.84472609e-02, -3.70804034e-02,\n",
       "        -1.40855491e-01],\n",
       "       [ 1.77807186e-03, -1.56124547e-01, -3.98975126e-02,\n",
       "         1.39902458e-01],\n",
       "       [-1.34441897e-03, -3.50653023e-01, -3.70994657e-02,\n",
       "         4.19736207e-01],\n",
       "       [-8.35747924e-03, -1.55025572e-01, -2.87047401e-02,\n",
       "         1.15592211e-01],\n",
       "       [-1.14579909e-02,  4.04956639e-02, -2.63928957e-02,\n",
       "        -1.86006859e-01],\n",
       "       [-1.06480774e-02, -1.54238924e-01, -3.01130340e-02,\n",
       "         9.82346758e-02],\n",
       "       [-1.37328561e-02,  4.13013846e-02, -2.81483401e-02,\n",
       "        -2.03794688e-01],\n",
       "       [-1.29068280e-02, -1.53406948e-01, -3.22242342e-02,\n",
       "         7.98775852e-02],\n",
       "       [-1.59749668e-02,  4.21617702e-02, -3.06266826e-02,\n",
       "        -2.22795486e-01],\n",
       "       [-1.51317315e-02, -1.52509347e-01, -3.50825898e-02,\n",
       "         6.00714236e-02],\n",
       "       [-1.81819182e-02, -3.47111195e-01, -3.38811614e-02,\n",
       "         3.41482401e-01],\n",
       "       [-2.51241419e-02, -1.51523978e-01, -2.70515159e-02,\n",
       "         3.83107960e-02],\n",
       "       [-2.81546228e-02, -3.46247762e-01, -2.62852982e-02,\n",
       "         3.22337449e-01],\n",
       "       [-3.50795761e-02, -5.40985763e-01, -1.98385492e-02,\n",
       "         6.06616497e-01],\n",
       "       [-4.58992906e-02, -3.45592111e-01, -7.70621980e-03,\n",
       "         3.07751566e-01],\n",
       "       [-5.28111346e-02, -1.50361195e-01, -1.55118806e-03,\n",
       "         1.26483124e-02],\n",
       "       [-5.58183566e-02, -3.45460862e-01, -1.29822176e-03,\n",
       "         3.04841429e-01],\n",
       "       [-6.27275780e-02, -1.50320441e-01,  4.79860650e-03,\n",
       "         1.17493449e-02],\n",
       "       [-6.57339841e-02,  4.47323620e-02,  5.03359362e-03,\n",
       "        -2.79415697e-01],\n",
       "       [-6.48393407e-02, -1.50461033e-01, -5.54720697e-04,\n",
       "         1.48505429e-02],\n",
       "       [-6.78485557e-02, -3.45575035e-01, -2.57709878e-04,\n",
       "         3.07358384e-01],\n",
       "       [-7.47600570e-02, -1.50449395e-01,  5.88945812e-03,\n",
       "         1.45942066e-02],\n",
       "       [-7.77690485e-02,  4.45875973e-02,  6.18134206e-03,\n",
       "        -2.76224732e-01],\n",
       "       [-7.68772960e-02, -1.50621995e-01,  6.56847726e-04,\n",
       "         1.84013750e-02],\n",
       "       [-7.98897371e-02,  4.44905274e-02,  1.02487521e-03,\n",
       "        -2.74074227e-01],\n",
       "       [-7.89999217e-02, -1.50646031e-01, -4.45660949e-03,\n",
       "         1.89317614e-02]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_data[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03797251,  0.22798768,  0.01605043, -0.3103866 ],\n",
       "       [-0.03341276,  0.03264077,  0.00984269, -0.01268536],\n",
       "       [-0.03275994,  0.22762018,  0.00958899, -0.30224663],\n",
       "       ...,\n",
       "       [-0.9658    , -0.32799113,  0.02331792,  0.29227886],\n",
       "       [-0.97235984, -0.13320926,  0.0291635 ,  0.00704035],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 4)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_obs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_drive",
   "language": "python",
   "name": "rl_drive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
